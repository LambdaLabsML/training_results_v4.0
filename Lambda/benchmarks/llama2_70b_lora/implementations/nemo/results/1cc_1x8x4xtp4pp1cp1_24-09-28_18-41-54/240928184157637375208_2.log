+ echo 'Beginning trial 2 of 10'
Beginning trial 2 of 10
+ echo ':::DLPAL calvin-training-head-003:5000#local/mlperf-nvidia-llama2_70b_lora:latest 130 1 calvin-training-node-019 lambda_1cc 1cc_1x8x4xtp4pp1cp1'
:::DLPAL calvin-training-head-003:5000#local/mlperf-nvidia-llama2_70b_lora:latest 130 1 calvin-training-node-019 lambda_1cc 1cc_1x8x4xtp4pp1cp1
++ srun --ntasks=1 --container-name=llama2_70b_lora_130 mlperf-sysjson.sh
+ echo ':::SYSJSON {"submitter":"LAMBDA","division":"closed","status":"onprem","system_name":"lambda_1cc","number_of_nodes":"1","host_processors_per_node":"2","host_processor_model_name":"Intel(R) Xeon(R) Platinum 8480+","host_processor_core_count":"52","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"1.7 TB","host_storage_type":"","host_storage_capacity":"","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"8","accelerator_model_name":"NVIDIA H100 80GB HBM3","accelerator_host_interconnect":"","accelerator_frequency":"","accelerator_on-chip_memories":"","accelerator_memory_configuration":"","accelerator_memory_capacity":"81559 MiB","accelerator_interconnect":"","accelerator_interconnect_topology":"","cooling":"","hw_notes":"","framework":"PyTorch NVIDIA Release 24.04","framework_name":"","other_software_stack":{"cuda_version":"12.4.1.003","cuda_driver_version":"550.54.15","nccl_version":"2.21.5","cublas_version":"12.4.5.8","cudnn_version":"9.1.0.70","trt_version":"8.6.3.1+cuda12.2.2.009","dali_version":"1.36.0","mofed_version":"5.4-rdmacore39.0","openmpi_version":"4.1.7","kernel_version":"Linux 6.5.0-35-generic","nvidia_kernel_driver":"535.161.08"},"operating_system":"Ubuntu 22.04.4 LTS","sw_notes":""}'
:::SYSJSON {"submitter":"LAMBDA","division":"closed","status":"onprem","system_name":"lambda_1cc","number_of_nodes":"1","host_processors_per_node":"2","host_processor_model_name":"Intel(R) Xeon(R) Platinum 8480+","host_processor_core_count":"52","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"1.7 TB","host_storage_type":"","host_storage_capacity":"","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"8","accelerator_model_name":"NVIDIA H100 80GB HBM3","accelerator_host_interconnect":"","accelerator_frequency":"","accelerator_on-chip_memories":"","accelerator_memory_configuration":"","accelerator_memory_capacity":"81559 MiB","accelerator_interconnect":"","accelerator_interconnect_topology":"","cooling":"","hw_notes":"","framework":"PyTorch NVIDIA Release 24.04","framework_name":"","other_software_stack":{"cuda_version":"12.4.1.003","cuda_driver_version":"550.54.15","nccl_version":"2.21.5","cublas_version":"12.4.5.8","cudnn_version":"9.1.0.70","trt_version":"8.6.3.1+cuda12.2.2.009","dali_version":"1.36.0","mofed_version":"5.4-rdmacore39.0","openmpi_version":"4.1.7","kernel_version":"Linux 6.5.0-35-generic","nvidia_kernel_driver":"535.161.08"},"operating_system":"Ubuntu 22.04.4 LTS","sw_notes":""}
+ '[' 1 -eq 1 ']'
+ srun --ntasks=1 --mpi=pmix bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on calvin-training-node-019
vm.drop_caches = 3
+ export SEED=26875
+ SEED=26875
+ srun -l --kill-on-bad-exit=0 --mpi=pmix --ntasks=8 --ntasks-per-node=8 --container-name=llama2_70b_lora_130 --container-mounts=/home/ubuntu/ml-1cc/data/mlperf/llama2_70b_lora/data:/data:ro,/home/ubuntu/ml-1cc/data/mlperf/llama2_70b_lora/ckpt:/ckpt:ro,./results/1cc_1x8x4xtp4pp1cp1_24-09-28_18-41-54:/results:rw,/dev/infiniband/uverbs0:/dev/infiniband/uverbs0,/dev/infiniband/uverbs1:/dev/infiniband/uverbs1,/dev/infiniband/uverbs2:/dev/infiniband/uverbs2,/dev/infiniband/uverbs3:/dev/infiniband/uverbs3,/dev/infiniband/uverbs4:/dev/infiniband/uverbs4,/dev/infiniband/uverbs5:/dev/infiniband/uverbs5,/dev/infiniband/uverbs6:/dev/infiniband/uverbs6,/dev/infiniband/uverbs7:/dev/infiniband/uverbs7 --export=ALL,MASTER_PORT=29500,MASTER_ADDR=calvin-training-node-019 slurm2pytorch ./run_and_time.sh
0: STARTING TIMING RUN AT 2024-09-28 07:37:32 PM
3: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
6: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
7: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
2: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
5: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
4: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
1: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
0: num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
1: FlashAttention Installed
3: FlashAttention Installed
4: FlashAttention Installed
6: FlashAttention Installed
7: FlashAttention Installed
0: FlashAttention Installed
2: FlashAttention Installed
5: FlashAttention Installed
0: [NeMo W 2024-09-28 19:37:48 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'megatron_gpt_peft_tuning_config': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
0:       warnings.warn(msg, UserWarning)
0:     
0: [NeMo W 2024-09-28 19:37:48 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
0:     See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
0:       ret = run_job(
0:     
0: [NeMo I 2024-09-28 19:37:48 train:59] 
0:     
0:     ************** Experiment configuration ***********
0: [NeMo I 2024-09-28 19:37:49 train:60] 
0:     model:
0:       ub_tp_comm_overlap_cfg:
0:         qkv_fprop:
0:           method: ring_exchange
0:           aggregate: 0
0:         fc1_fprop:
0:           method: ring_exchange
0:           aggregate: 0
0:         proj_dgrad:
0:           method: ring_exchange
0:           aggregate: 0
0:         fc2_dgrad:
0:           method: ring_exchange
0:           aggregate: 0
0:         proj_fprop:
0:           method: pipeline
0:           num_sm: 32
0:           cga_size: 2
0:           num_splits: 4
0:           set_sm_margin: 1
0:           atomic_gemm: 1
0:         fc2_fprop:
0:           method: pipeline
0:           num_sm: 16
0:           cga_size: 2
0:           num_splits: 4
0:           set_sm_margin: 1
0:           atomic_gemm: 1
0:         qkv_dgrad:
0:           method: bulk
0:           num_sm: 4
0:           cga_size: 2
0:           set_sm_margin: 0
0:         fc1_dgrad:
0:           method: bulk
0:           num_sm: 2
0:           cga_size: 2
0:           set_sm_margin: 0
0:       mcore_gpt: true
0:       seed: 26875
0:       tensor_model_parallel_size: 4
0:       pipeline_model_parallel_size: 1
0:       context_parallel_size: 1
0:       cpu_offloading: false
0:       global_batch_size: 8
0:       micro_batch_size: 1
0:       max_position_embeddings: 8192
0:       encoder_seq_length: 8192
0:       restore_from_path: /ckpt
0:       resume_from_checkpoint: null
0:       save_nemo_on_validation_end: false
0:       sync_batch_comm: false
0:       megatron_amp_O2: true
0:       sequence_parallel: 1
0:       activations_checkpoint_granularity: null
0:       activations_checkpoint_method: null
0:       activations_checkpoint_num_layers: null
0:       activations_checkpoint_layers_per_pipeline: null
0:       answer_only_loss: true
0:       gradient_as_bucket_view: false
0:       hidden_dropout: 0.0
0:       attention_dropout: 0.0
0:       ffn_dropout: 0.0
0:       bias_activation_fusion: true
0:       bias_dropout_add_fusion: false
0:       transformer_engine: true
0:       fp8: true
0:       fp8_params: true
0:       fp8_hybrid: true
0:       fp8_amax_history_len: 32
0:       fp8_amax_compute_algo: max
0:       reduce_amax: false
0:       fp8_e4m3: false
0:       fp8_interval: 1
0:       fp8_margin: 0
0:       fp8_dot_product_attention: 1
0:       fp8_activation_input_store: 0
0:       apply_rope_fusion: true
0:       disable_parameter_transpose_cache: true
0:       ub_tp_comm_overlap: false
0:       tp_comm_overlap_ag: true
0:       tp_comm_overlap_rs: true
0:       tp_comm_overlap_rs_dgrad: false
0:       tp_comm_disable_qkv: true
0:       batch_p2p_comm: 'False'
0:       virtual_pipeline_model_parallel_size: 1
0:       sharp: false
0:       nccl_communicator_config_path: conf/nccl/custom_communicator_cta.yaml
0:       peft:
0:         peft_scheme: lora
0:         restore_from_path: null
0:         lora_tuning:
0:           adapter_dim: 16
0:           alpha: 32
0:           adapter_dropout: 0.1
0:           dropout_position: pre
0:           target_modules:
0:           - attention
0:           column_init_method: kaiming
0:           row_init_method: zero
0:           layer_selection: null
0:           weight_tying: false
0:           position_embedding_strategy: null
0:           a2a_experimental: 1
0:       data:
0:         multiprocessing_context: spawn
0:         pin_memory: true
0:         sample_weight: constant
0:         validation_drop_last: false
0:         train_ds:
0:           file_names:
0:           - /data/train.npy
0:           packed_sequence: true
0:           packed_sequence_return_cu_seqlen: false
0:           index_mapping_dir: /results/data_index/train
0:           global_batch_size: 8
0:           micro_batch_size: 1
0:           shuffle: true
0:           num_workers: 1
0:           memmap_workers: 2
0:           pin_memory: true
0:           max_seq_length: 8192
0:           min_seq_length: 1
0:           drop_last: true
0:           concat_sampling_probabilities:
0:           - 1.0
0:           label_key: output
0:           add_eos: true
0:           add_sep: false
0:           add_bos: false
0:           truncation_field: input
0:           prompt_template: '{input} {output}'
0:           truncation_method: right
0:           seed: 26875
0:         validation_ds:
0:           file_names:
0:           - /data/validation.npy
0:           packed_sequence: true
0:           packed_sequence_return_cu_seqlen: false
0:           index_mapping_dir: /results/data_index/val
0:           names: null
0:           global_batch_size: 8
0:           micro_batch_size: 1
0:           shuffle: false
0:           num_workers: 1
0:           memmap_workers: 2
0:           pin_memory: true
0:           max_seq_length: 8192
0:           min_seq_length: 1
0:           drop_last: false
0:           label_key: output
0:           add_eos: true
0:           add_sep: false
0:           add_bos: false
0:           write_predictions_to_file: false
0:           output_file_path_prefix: null
0:           truncation_field: input
0:           prompt_template: '{input} {output}'
0:           tokens_to_generate: 32
0:           truncation_method: right
0:           metric:
0:             name: loss
0:             average: null
0:             num_classes: null
0:       optim:
0:         name: fused_adam
0:         lr: 0.0005
0:         weight_decay: 0.0001
0:         betas:
0:         - 0.9
0:         - 0.999
0:         eps: 1.0e-08
0:         amsgrad: false
0:         sched:
0:           name: CosineAnnealing
0:           warmup_ratio: 0.0
0:           min_lr: 0.0
0:           constant_steps: 0
0:           monitor: val_loss
0:           reduce_on_plateau: false
0:       custom:
0:         warmup: true
0:         warmup_train_steps: 5
0:         warmup_validation_steps: 5
0:         reset_fp8_stats_after_warmup: 1
0:     name: megatron_gpt_peft_lora_tuning
0:     trainer:
0:       devices: 8
0:       num_nodes: 1
0:       accelerator: gpu
0:       precision: bf16-mixed
0:       max_steps: 2000
0:       val_check_interval: 192
0:       check_val_every_n_epoch: null
0:       log_every_n_steps: 0
0:       gradient_clip_val: 0.3
0:       gradient_clip_algorithm: norm
0:       num_sanity_val_steps: 0
0:       max_epochs: 1000
0:       limit_val_batches: 1.0
0:       limit_train_batches: 1.0
0:       limit_test_batches: 0
0:       logger: false
0:       enable_checkpointing: false
0:       use_distributed_sampler: false
0:       enable_progress_bar: false
0:     exp_manager:
0:       explicit_log_dir: null
0:       exp_dir: /results
0:       create_wandb_logger: false
0:       resume_if_exists: false
0:       resume_ignore_no_checkpoint: true
0:       create_checkpoint_callback: false
0:       log_global_rank_0_only: true
0:       create_early_stopping_callback: false
0:       create_tensorboard_logger: false
0:     
0: [NeMo W 2024-09-28 19:37:49 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/_graveyard/precision.py:49: The `MixedPrecisionPlugin` is deprecated. Use `pytorch_lightning.plugins.precision.MixedPrecision` instead.
0:     
1: [W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
6: [W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
7: [W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
3: [W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
0: GPU available: True (cuda), used: True
0: TPU available: False, using: 0 TPU cores
0: IPU available: False, using: 0 IPUs
0: HPU available: False, using: 0 HPUs
0: `Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
0: `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
0: [NeMo I 2024-09-28 19:37:49 save_restore_connector:134] Restoration will occur within pre-extracted directory : `/ckpt`.
0: [NeMo I 2024-09-28 19:37:49 save_restore_connector:134] Restoration will occur within pre-extracted directory : `/ckpt`.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: use_te_rng_tracker in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: tp_comm_disable_fc1 in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: defer_embedding_wgrad_compute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: cpu_offloading_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: cpu_offloading_activations in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: cpu_offloading_weights in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
0: [NeMo I 2024-09-28 19:37:49 megatron_init:265] Rank 0 has data parallel group : [0, 4]
0: [NeMo I 2024-09-28 19:37:49 megatron_init:271] Rank 0 has combined group of data parallel and context parallel : [0, 4]
0: [NeMo I 2024-09-28 19:37:49 megatron_init:276] All data parallel group ranks with context parallel combined: [[0, 4], [1, 5], [2, 6], [3, 7]]
0: [NeMo I 2024-09-28 19:37:49 megatron_init:279] Ranks 0 has data parallel rank: 0
0: [NeMo I 2024-09-28 19:37:49 megatron_init:287] Rank 0 has context parallel group: [0]
0: [NeMo I 2024-09-28 19:37:49 megatron_init:290] All context parallel group ranks: [[0], [1], [2], [3], [4], [5], [6], [7]]
0: [NeMo I 2024-09-28 19:37:49 megatron_init:291] Ranks 0 has context parallel rank: 0
0: [NeMo I 2024-09-28 19:37:49 megatron_init:298] Rank 0 has model parallel group: [0, 1, 2, 3]
0: [NeMo I 2024-09-28 19:37:49 megatron_init:299] All model parallel group ranks: [[0, 1, 2, 3], [4, 5, 6, 7]]
0: [NeMo I 2024-09-28 19:37:49 megatron_init:308] Rank 0 has tensor model parallel group: [0, 1, 2, 3]
0: [NeMo I 2024-09-28 19:37:49 megatron_init:312] All tensor model parallel group ranks: [[0, 1, 2, 3], [4, 5, 6, 7]]
0: [NeMo I 2024-09-28 19:37:49 megatron_init:313] Rank 0 has tensor model parallel rank: 0
0: [NeMo I 2024-09-28 19:37:49 megatron_init:333] Rank 0 has pipeline model parallel group: [0]
0: [NeMo I 2024-09-28 19:37:49 megatron_init:345] Rank 0 has embedding group: [0]
0: [NeMo I 2024-09-28 19:37:49 megatron_init:351] All pipeline model parallel group ranks: [[0], [1], [2], [3], [4], [5], [6], [7]]
0: [NeMo I 2024-09-28 19:37:49 megatron_init:352] Rank 0 has pipeline model parallel rank 0
0: [NeMo I 2024-09-28 19:37:49 megatron_init:353] All embedding group ranks: [[0], [1], [2], [3], [4], [5], [6], [7]]
0: [NeMo I 2024-09-28 19:37:49 megatron_init:354] Rank 0 has embedding rank: 0
5: [W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
4: [W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
0: 24-09-28 19:37:49 - PID:2523624 - rank:(0, 0, 0, 0) - microbatches.py:39 - INFO - setting number of micro-batches to constant 4
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: use_te_rng_tracker in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: tp_comm_disable_fc1 in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: defer_embedding_wgrad_compute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: cpu_offloading_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: cpu_offloading_activations in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: cpu_offloading_weights in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo I 2024-09-28 19:37:49 tokenizer_utils:187] Getting SentencePiece with model: /ckpt/d9a3fcd8246a432f95ed96c9011cd224_tokenizer.model
0: [NeMo I 2024-09-28 19:37:49 megatron_base_model:586] Padded vocab_size: 32256, original vocab_size: 32000, dummy tokens: 256.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: use_te_rng_tracker in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: tp_comm_disable_fc1 in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: defer_embedding_wgrad_compute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: cpu_offloading_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: cpu_offloading_activations in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: cpu_offloading_weights in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:1150] The model: CustomMegatronGPTSFTModel() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:499] apply_query_key_layer_scaling is only enabled when using FP16, setting it to False and setting NVTE_APPLY_QK_LAYER_SCALING=0
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:558] The model: CustomMegatronGPTSFTModel() does not have field.name: activation_func_fp8_input_store in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:558] The model: CustomMegatronGPTSFTModel() does not have field.name: num_moe_experts in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:558] The model: CustomMegatronGPTSFTModel() does not have field.name: window_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:558] The model: CustomMegatronGPTSFTModel() does not have field.name: qk_layernorm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:558] The model: CustomMegatronGPTSFTModel() does not have field.name: test_mode in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:558] The model: CustomMegatronGPTSFTModel() does not have field.name: memory_efficient_layer_norm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:558] The model: CustomMegatronGPTSFTModel() does not have field.name: fp8_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:558] The model: CustomMegatronGPTSFTModel() does not have field.name: fp8_multi_head_attention in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:558] The model: CustomMegatronGPTSFTModel() does not have field.name: moe_router_load_balancing_type in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:558] The model: CustomMegatronGPTSFTModel() does not have field.name: moe_router_topk in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:558] The model: CustomMegatronGPTSFTModel() does not have field.name: moe_grouped_gemm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:558] The model: CustomMegatronGPTSFTModel() does not have field.name: moe_aux_loss_coeff in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:558] The model: CustomMegatronGPTSFTModel() does not have field.name: moe_z_loss_coeff in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:558] The model: CustomMegatronGPTSFTModel() does not have field.name: moe_input_jitter_eps in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:558] The model: CustomMegatronGPTSFTModel() does not have field.name: moe_token_dropping in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:558] The model: CustomMegatronGPTSFTModel() does not have field.name: moe_token_dispatcher_type in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:558] The model: CustomMegatronGPTSFTModel() does not have field.name: moe_per_layer_logging in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:558] The model: CustomMegatronGPTSFTModel() does not have field.name: clone_scatter_output_in_embedding in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:558] The model: CustomMegatronGPTSFTModel() does not have field.name: enable_cuda_graph in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-09-28 19:37:49 megatron_base_model:558] The model: CustomMegatronGPTSFTModel() does not have field.name: rotary_percent in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
2: [W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
1: Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/8
3: Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/8
6: Initializing distributed: GLOBAL_RANK: 6, MEMBER: 7/8
7: Initializing distributed: GLOBAL_RANK: 7, MEMBER: 8/8
0: Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/8
5: Initializing distributed: GLOBAL_RANK: 5, MEMBER: 6/8
2: Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/8
4: Initializing distributed: GLOBAL_RANK: 4, MEMBER: 5/8
0: ----------------------------------------------------------------------------------------------------
0: distributed_backend=nccl
0: All distributed processes registered. Starting with 8 processes
0: ----------------------------------------------------------------------------------------------------
0: 
0: [NeMo W 2024-09-28 19:37:51 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py:1507: UserWarning: pg_options._timeout was specified, but timeout kwarg has a default value that will always override it. 
0:       warnings.warn(
0:     
0: [NeMo I 2024-09-28 19:37:51 nlp_overrides:1127] Restoration will occur within pre-extracted directory : `/ckpt`.
0: NCCL version 2.21.5+cuda12.4
0: Loading distributed checkpoint with TensorStoreLoadShardedStrategy
0: [NeMo I 2024-09-28 19:46:39 nlp_overrides:1156] Model CustomMegatronGPTSFTModel was successfully restored from /ckpt.
0: [NeMo W 2024-09-28 19:46:39 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/model_summary/model_summary.py:454: A layer with UninitializedParameter was found. Thus, the total number of parameters detected may be inaccurate.
0:     
0: [NeMo I 2024-09-28 19:46:39 nlp_adapter_mixins:203] Before adding PEFT params:
0:       | Name  | Type          | Params
0:     ----------------------------------------
0:     0 | model | Float16Module | 133 M 
0:     ----------------------------------------
0:     0         Trainable params
0:     133 M     Non-trainable params
0:     133 M     Total params
0:     533.758   Total estimated model params size (MB)
0: [NeMo I 2024-09-28 19:46:47 nlp_adapter_mixins:208] After adding PEFT params:
0:       | Name  | Type          | Params
0:     ----------------------------------------
0:     0 | model | Float16Module | 144 M 
0:     ----------------------------------------
0:     11.1 M    Trainable params
0:     133 M     Non-trainable params
0:     144 M     Total params
0:     578.322   Total estimated model params size (MB)
0: [NeMo W 2024-09-28 19:46:47 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/configuration_validator.py:181: You have overridden `CustomMegatronGPTSFTModel.configure_sharded_model` which is deprecated. Please override the `configure_model` hook instead. Instantiation with the newer hook will be created on the device right away and have the right data type depending on the precision setting in the Trainer.
0:     
0: [NeMo I 2024-09-28 19:46:47 megatron_gpt_sft_model:804] Building GPT SFT validation datasets.
0: [NeMo I 2024-09-28 19:46:47 megatron_gpt_sft_model:807] Length of val dataset: 173
0: [NeMo I 2024-09-28 19:46:47 megatron_gpt_sft_model:814] Building GPT SFT traing datasets.
0: make: Entering directory '/workspace/ft-llm/NeMo/nemo/collections/nlp/data/language_modeling/megatron'
0: make: Nothing to be done for 'default'.
0: make: Leaving directory '/workspace/ft-llm/NeMo/nemo/collections/nlp/data/language_modeling/megatron'
0: > building indices for blendable datasets ...
0:  > sample ratios:
0:    dataset 0, input: 1, achieved: 1
0: [NeMo I 2024-09-28 19:46:49 blendable_dataset:67] > elapsed time for building blendable dataset indices: 0.54 (sec)
0: [NeMo I 2024-09-28 19:46:49 megatron_gpt_sft_model:816] Length of train dataset: 16080
0: [NeMo I 2024-09-28 19:46:49 megatron_gpt_sft_model:821] Building dataloader with consumed samples: 0
0: [NeMo I 2024-09-28 19:46:49 megatron_gpt_sft_model:821] Building dataloader with consumed samples: 0
1: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
3: LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
6: LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
7: LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
0: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
2: LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
4: LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
5: LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
0: [NeMo W 2024-09-28 19:46:49 megatron_base_model:1191] Ignoring `trainer.max_epochs` when computing `max_steps` because `trainer.max_steps` is already set to 2000.
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_dense_attention_adapter
0: [NeMo I 2024-09-28 19:46:49 adapter_mixins:435] Unfrozen adapter : lora_kqv_adapter
0: [NeMo I 2024-09-28 19:46:49 nlp_adapter_mixins:269] Optimizer groups set:
0:       | Name  | Type          | Params
0:     ----------------------------------------
0:     0 | model | Float16Module | 144 M 
0:     ----------------------------------------
0:     11.1 M    Trainable params
0:     133 M     Non-trainable params
0:     144 M     Total params
0:     578.322   Total estimated model params size (MB)
0: [NeMo I 2024-09-28 19:46:49 modelPT:724] Optimizer config = FusedAdam (
0:     Parameter Group 0
0:         betas: [0.9, 0.999]
0:         bias_correction: True
0:         eps: 1e-08
0:         lr: 0.0005
0:         weight_decay: 0.0001
0:     )
0: [NeMo I 2024-09-28 19:46:49 lr_scheduler:923] Scheduler "<nemo.core.optim.lr_scheduler.CosineAnnealing object at 0x743ef447ab00>" 
0:     will be used during training (effective maximum steps = 2000) - 
0:     Parameters : 
0:     (warmup_ratio: 0.0
0:     min_lr: 0.0
0:     constant_steps: 0
0:     max_steps: 2000
0:     )
0: [NeMo I 2024-09-28 19:46:49 lr_scheduler:923] Scheduler "<nemo.core.optim.lr_scheduler.CosineAnnealing object at 0x743ef41db190>" 
0:     will be used during training (effective maximum steps = 2000) - 
0:     Parameters : 
0:     (warmup_ratio: 0.0
0:     min_lr: 0.0
0:     constant_steps: 0
0:     max_steps: 2000
0:     )
0: 
0:   | Name  | Type          | Params
0: ----------------------------------------
0: 0 | model | Float16Module | 144 M 
0: ----------------------------------------
0: 11.1 M    Trainable params
0: 133 M     Non-trainable params
0: 144 M     Total params
0: 578.322   Total estimated model params size (MB)
0: :::MLLOG {"namespace": "", "time_ms": 1727552809380, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 206}}
0: :::MLLOG {"namespace": "", "time_ms": 1727552809381, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 207}}
0: :::MLLOG {"namespace": "", "time_ms": 1727552809382, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "llama2_70b_lora", "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 208}}
0: :::MLLOG {"namespace": "", "time_ms": 1727552809382, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "SUBMISSION_ORG_PLACEHOLDER", "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 208}}
0: :::MLLOG {"namespace": "", "time_ms": 1727552809382, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 208}}
0: :::MLLOG {"namespace": "", "time_ms": 1727552809382, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 208}}
0: :::MLLOG {"namespace": "", "time_ms": 1727552809382, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "1xSUBMISSION_PLATFORM_PLACEHOLDER", "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 208}}
0: :::MLLOG {"namespace": "", "time_ms": 1727552809382, "event_type": "POINT_IN_TIME", "key": "seed", "value": 26875, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 209}}
0: :::MLLOG {"namespace": "", "time_ms": 1727552809382, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 8, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 215}}
0: :::MLLOG {"namespace": "", "time_ms": 1727552810116, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 3901, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 220}}
0: :::MLLOG {"namespace": "", "time_ms": 1727552810141, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 173, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 224}}
0: :::MLLOG {"namespace": "", "time_ms": 1727552810141, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_factor", "value": 0.0, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 228}}
0: :::MLLOG {"namespace": "", "time_ms": 1727552810141, "event_type": "POINT_IN_TIME", "key": "opt_adamw_weight_decay", "value": 0.0001, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 232}}
0: :::MLLOG {"namespace": "", "time_ms": 1727552810141, "event_type": "POINT_IN_TIME", "key": "opt_gradient_clip_norm", "value": 0.3, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 236}}
0: :::MLLOG {"namespace": "", "time_ms": 1727552810141, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 4, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 241}}
0: :::MLLOG {"namespace": "", "time_ms": 1727552810142, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_training_steps", "value": 2000, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 242}}
0: :::MLLOG {"namespace": "", "time_ms": 1727552810142, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.0005, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 243}}
0: :::MLLOG {"namespace": "", "time_ms": 1727552810142, "event_type": "POINT_IN_TIME", "key": "lora_rank", "value": 16, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 244}}
0: :::MLLOG {"namespace": "", "time_ms": 1727552810142, "event_type": "POINT_IN_TIME", "key": "lora_alpha", "value": 32, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 245}}
0: SLURM auto-requeueing enabled. Setting signal handlers.
1: SLURM auto-requeueing enabled. Setting signal handlers.
3: SLURM auto-requeueing enabled. Setting signal handlers.
2: SLURM auto-requeueing enabled. Setting signal handlers.
4: SLURM auto-requeueing enabled. Setting signal handlers.
5: SLURM auto-requeueing enabled. Setting signal handlers.
6: SLURM auto-requeueing enabled. Setting signal handlers.
7: SLURM auto-requeueing enabled. Setting signal handlers.
0: [NeMo W 2024-09-28 19:46:50 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/utilities.py:149: Found `dataloader_iter` argument in the `training_step`. Note that the support for this signature is experimental and the behavior is subject to change.
0:     
4: NCCL version 2.21.5+cuda12.4
1: NCCL version 2.21.5+cuda12.4
2: NCCL version 2.21.5+cuda12.4
3: NCCL version 2.21.5+cuda12.4
0: [NeMo I 2024-09-28 19:48:08 custom_callbacks:40] Finished training warmup: 62.4886908531189s. Starting validation warmup
0: [NeMo I 2024-09-28 19:48:18 custom_callbacks:54] Time spent in run_training_warmup: 73.00687837600708s
0: [NeMo I 2024-09-28 19:48:18 custom_callbacks:59] Forcing FP8 stats reinitialization
0: :::MLLOG {"namespace": "", "time_ms": 1727552898582, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 145}}
0: :::MLLOG {"namespace": "", "time_ms": 1727552898582, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 145}}
0: :::MLLOG {"namespace": "", "time_ms": 1727552898582, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 146, "samples_count": 0}}
0: [NeMo W 2024-09-28 20:01:52 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/utilities.py:149: Found `dataloader_iter` argument in the `validation_step`. Note that the support for this signature is experimental and the behavior is subject to change.
0:     
0: :::MLLOG {"namespace": "", "time_ms": 1727553727302, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 1.8884410882774463}, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 161, "step": 1536}}
0: :::MLLOG {"namespace": "", "time_ms": 1727553727302, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 112, "samples_count": 1536}}
0: :::MLLOG {"namespace": "", "time_ms": 1727553727302, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 117, "samples_count": 1536}}
0: [NeMo W 2024-09-28 20:02:07 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/apex/transformer/pipeline_parallel/utils.py:81: UserWarning: This function is only for unittest
0:       warnings.warn("This function is only for unittest")
0:     
0: :::MLLOG {"namespace": "", "time_ms": 1727553772853, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9378436207771301, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 181, "samples_count": 1536}}
0: :::MLLOG {"namespace": "", "time_ms": 1727553772853, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 186, "samples_count": 1536}}
0: :::MLLOG {"namespace": "", "time_ms": 1727553772853, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 129, "samples_count": 1536}}
0: :::MLLOG {"namespace": "", "time_ms": 1727553972983, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 1.9190589948969508}, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 161, "step": 1920}}
0: :::MLLOG {"namespace": "", "time_ms": 1727553972984, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 112, "samples_count": 1920}}
0: :::MLLOG {"namespace": "", "time_ms": 1727553972984, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 117, "samples_count": 1920}}
0: :::MLLOG {"namespace": "", "time_ms": 1727554018375, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9344254732131958, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 181, "samples_count": 1920}}
0: :::MLLOG {"namespace": "", "time_ms": 1727554018375, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 186, "samples_count": 1920}}
0: :::MLLOG {"namespace": "", "time_ms": 1727554018375, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 129, "samples_count": 1920}}
0: :::MLLOG {"namespace": "", "time_ms": 1727554218411, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 1.9199675542592416}, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 161, "step": 2304}}
0: :::MLLOG {"namespace": "", "time_ms": 1727554218411, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 112, "samples_count": 2304}}
0: :::MLLOG {"namespace": "", "time_ms": 1727554218412, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 117, "samples_count": 2304}}
0: :::MLLOG {"namespace": "", "time_ms": 1727554263983, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9364862442016602, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 181, "samples_count": 2304}}
0: :::MLLOG {"namespace": "", "time_ms": 1727554263983, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 186, "samples_count": 2304}}
0: :::MLLOG {"namespace": "", "time_ms": 1727554263983, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 129, "samples_count": 2304}}
0: :::MLLOG {"namespace": "", "time_ms": 1727554463432, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 1.925611877195871}, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 161, "step": 2688}}
0: :::MLLOG {"namespace": "", "time_ms": 1727554463432, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 112, "samples_count": 2688}}
0: :::MLLOG {"namespace": "", "time_ms": 1727554463433, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 117, "samples_count": 2688}}
0: :::MLLOG {"namespace": "", "time_ms": 1727554508736, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9294804334640503, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 181, "samples_count": 2688}}
0: :::MLLOG {"namespace": "", "time_ms": 1727554508736, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 186, "samples_count": 2688}}
0: :::MLLOG {"namespace": "", "time_ms": 1727554508737, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 129, "samples_count": 2688}}
0: :::MLLOG {"namespace": "", "time_ms": 1727554708666, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 1.9209871550749535}, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 161, "step": 3072}}
0: :::MLLOG {"namespace": "", "time_ms": 1727554708667, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 112, "samples_count": 3072}}
0: :::MLLOG {"namespace": "", "time_ms": 1727554708667, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 117, "samples_count": 3072}}
0: :::MLLOG {"namespace": "", "time_ms": 1727554753432, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9258503317832947, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 181, "samples_count": 3072}}
0: :::MLLOG {"namespace": "", "time_ms": 1727554753432, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 186, "samples_count": 3072}}
0: :::MLLOG {"namespace": "", "time_ms": 1727554753432, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 129, "samples_count": 3072}}
0: :::MLLOG {"namespace": "", "time_ms": 1727554952858, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 1.9258378848012274}, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 161, "step": 3456}}
0: :::MLLOG {"namespace": "", "time_ms": 1727554952859, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 112, "samples_count": 3456}}
0: :::MLLOG {"namespace": "", "time_ms": 1727554952859, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 117, "samples_count": 3456}}
0: :::MLLOG {"namespace": "", "time_ms": 1727554997354, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9252089262008667, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 181, "samples_count": 3456}}
0: :::MLLOG {"namespace": "", "time_ms": 1727554997354, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 186, "samples_count": 3456}}
0: :::MLLOG {"namespace": "", "time_ms": 1727554997354, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 129, "samples_count": 3456}}
0: :::MLLOG {"namespace": "", "time_ms": 1727555196446, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 1.9290726648175256}, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 161, "step": 3840}}
0: :::MLLOG {"namespace": "", "time_ms": 1727555196446, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 112, "samples_count": 3840}}
0: :::MLLOG {"namespace": "", "time_ms": 1727555196446, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 117, "samples_count": 3840}}
0: :::MLLOG {"namespace": "", "time_ms": 1727555241697, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.926353931427002, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 181, "samples_count": 3840}}
0: :::MLLOG {"namespace": "", "time_ms": 1727555241697, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 186, "samples_count": 3840}}
0: :::MLLOG {"namespace": "", "time_ms": 1727555241697, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 129, "samples_count": 3840}}
0: :::MLLOG {"namespace": "", "time_ms": 1727555440886, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 1.9281389816392902}, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 161, "step": 4224}}
0: :::MLLOG {"namespace": "", "time_ms": 1727555440886, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 112, "samples_count": 4224}}
0: :::MLLOG {"namespace": "", "time_ms": 1727555440886, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 117, "samples_count": 4224}}
0: :::MLLOG {"namespace": "", "time_ms": 1727555487595, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.926324188709259, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 181, "samples_count": 4224}}
0: :::MLLOG {"namespace": "", "time_ms": 1727555487596, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 186, "samples_count": 4224}}
0: :::MLLOG {"namespace": "", "time_ms": 1727555487596, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 129, "samples_count": 4224}}
0: :::MLLOG {"namespace": "", "time_ms": 1727555688568, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 1.9110214018940912}, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 161, "step": 4608}}
0: :::MLLOG {"namespace": "", "time_ms": 1727555688568, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 112, "samples_count": 4608}}
0: :::MLLOG {"namespace": "", "time_ms": 1727555688568, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/ft-llm/custom_callbacks.py", "lineno": 117, "samples_count": 4608}}
0: /workspace/ft-llm/run_and_time.sh: line 68: 2523624 Killed                  ${LOGGER:-} ${CMD[@]} train.py
0: FlashAttention Installed
0: FlashAttention Installed
0: /usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 23 leaked semaphore objects to clean up at shutdown
0:   warnings.warn('resource_tracker: There appear to be %d '
0: slurmstepd: error: Detected 1 oom_kill event in StepId=130.13. Some of the step tasks have been OOM Killed.
srun: error: calvin-training-node-019: task 0: Out Of Memory
4: [rank4]:[E ProcessGroupNCCL.cpp:563] [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=3054764, OpType=ALLREDUCE, NumelIn=67108864, NumelOut=67108864, Timeout(ms)=1800000) ran for 1800000 milliseconds before timing out.
4: [rank4]:[E ProcessGroupNCCL.cpp:563] [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=3119, OpType=ALLREDUCE, NumelIn=2, NumelOut=2, Timeout(ms)=1800000) ran for 1800007 milliseconds before timing out.
6: [rank6]:[E ProcessGroupNCCL.cpp:563] [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=3054764, OpType=ALLREDUCE, NumelIn=67108864, NumelOut=67108864, Timeout(ms)=1800000) ran for 1800009 milliseconds before timing out.
5: [rank5]:[E ProcessGroupNCCL.cpp:563] [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=3054764, OpType=ALLREDUCE, NumelIn=67108864, NumelOut=67108864, Timeout(ms)=1800000) ran for 1800016 milliseconds before timing out.
4: [rank4]:[E ProcessGroupNCCL.cpp:1537] [PG 1 Rank 1] Timeout at NCCL work: 3119, last enqueued NCCL work: 3119, last completed NCCL work: 3118.
4: [rank4]:[E ProcessGroupNCCL.cpp:577] [Rank 0] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
4: [rank4]:[E ProcessGroupNCCL.cpp:583] [Rank 0] To avoid data inconsistency, we are taking the entire process down.
6: [rank6]:[E ProcessGroupNCCL.cpp:1537] [PG 5 Rank 2] Timeout at NCCL work: 3054764, last enqueued NCCL work: 3054883, last completed NCCL work: 3054763.
6: [rank6]:[E ProcessGroupNCCL.cpp:577] [Rank 2] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
6: [rank6]:[E ProcessGroupNCCL.cpp:583] [Rank 2] To avoid data inconsistency, we are taking the entire process down.
4: [rank4]:[E ProcessGroupNCCL.cpp:1414] [PG 1 Rank 1] Process group watchdog thread terminated with exception: [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=3119, OpType=ALLREDUCE, NumelIn=2, NumelOut=2, Timeout(ms)=1800000) ran for 1800007 milliseconds before timing out.
4: Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:565 (most recent call first):
4: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7248bea81e89 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
4: frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1e1 (0x72485ae06121 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
4: frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x1a0 (0x72485ae0d4e0 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
4: frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x10f (0x72485ae0e3ff in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
4: frame #4: <unknown function> + 0xdc253 (0x7248be4dc253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
4: frame #5: <unknown function> + 0x94ac3 (0x7248ca294ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
4: frame #6: <unknown function> + 0x126850 (0x7248ca326850 in /usr/lib/x86_64-linux-gnu/libc.so.6)
4: 
4: [rank4]:[E ProcessGroupNCCL.cpp:1537] [PG 5 Rank 0] Timeout at NCCL work: 3054764, last enqueued NCCL work: 3054883, last completed NCCL work: 3054763.
4: [rank4]:[E ProcessGroupNCCL.cpp:577] [Rank 0] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
6: [rank6]:[E ProcessGroupNCCL.cpp:1414] [PG 5 Rank 2] Process group watchdog thread terminated with exception: [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=3054764, OpType=ALLREDUCE, NumelIn=67108864, NumelOut=67108864, Timeout(ms)=1800000) ran for 1800009 milliseconds before timing out.
6: Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:565 (most recent call first):
6: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7422e5198e89 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
6: frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1e1 (0x742281406121 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
6: frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x1a0 (0x74228140d4e0 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
6: frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x10f (0x74228140e3ff in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
6: frame #4: <unknown function> + 0xdc253 (0x7422e4adc253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
6: frame #5: <unknown function> + 0x94ac3 (0x7422f0a94ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
6: frame #6: <unknown function> + 0x126850 (0x7422f0b26850 in /usr/lib/x86_64-linux-gnu/libc.so.6)
6: 
4: [rank4]:[E ProcessGroupNCCL.cpp:583] [Rank 0] To avoid data inconsistency, we are taking the entire process down.
4: [rank4]:[E ProcessGroupNCCL.cpp:1414] [PG 5 Rank 0] Process group watchdog thread terminated with exception: [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=3054764, OpType=ALLREDUCE, NumelIn=67108864, NumelOut=67108864, Timeout(ms)=1800000) ran for 1800000 milliseconds before timing out.
4: Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:565 (most recent call first):
4: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7248bea81e89 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
4: frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1e1 (0x72485ae06121 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
4: frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x1a0 (0x72485ae0d4e0 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
4: frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x10f (0x72485ae0e3ff in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
4: frame #4: <unknown function> + 0xdc253 (0x7248be4dc253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
4: frame #5: <unknown function> + 0x94ac3 (0x7248ca294ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
4: frame #6: <unknown function> + 0x126850 (0x7248ca326850 in /usr/lib/x86_64-linux-gnu/libc.so.6)
4: 
5: [rank5]:[E ProcessGroupNCCL.cpp:1537] [PG 5 Rank 1] Timeout at NCCL work: 3054764, last enqueued NCCL work: 3054883, last completed NCCL work: 3054763.
5: [rank5]:[E ProcessGroupNCCL.cpp:577] [Rank 1] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
5: [rank5]:[E ProcessGroupNCCL.cpp:583] [Rank 1] To avoid data inconsistency, we are taking the entire process down.
5: [rank5]:[E ProcessGroupNCCL.cpp:1414] [PG 5 Rank 1] Process group watchdog thread terminated with exception: [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=3054764, OpType=ALLREDUCE, NumelIn=67108864, NumelOut=67108864, Timeout(ms)=1800000) ran for 1800016 milliseconds before timing out.
5: Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:565 (most recent call first):
5: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7545b2b98e89 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
5: frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1e1 (0x75454ee06121 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
5: frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x1a0 (0x75454ee0d4e0 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
5: frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x10f (0x75454ee0e3ff in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
5: frame #4: <unknown function> + 0xdc253 (0x7545b24dc253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
5: frame #5: <unknown function> + 0x94ac3 (0x7545be494ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
5: frame #6: <unknown function> + 0x126850 (0x7545be526850 in /usr/lib/x86_64-linux-gnu/libc.so.6)
5: 
4: terminate called after throwing an instance of 'c10::DistBackendError'
4:   what():  [PG 1 Rank 1] Process group watchdog thread terminated with exception: [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=3119, OpType=ALLREDUCE, NumelIn=2, NumelOut=2, Timeout(ms)=1800000) ran for 1800007 milliseconds before timing out.
4: Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:565 (most recent call first):
4: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7248bea81e89 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
4: frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1e1 (0x72485ae06121 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
4: frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x1a0 (0x72485ae0d4e0 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
4: frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x10f (0x72485ae0e3ff in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
4: frame #4: <unknown function> + 0xdc253 (0x7248be4dc253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
4: frame #5: <unknown function> + 0x94ac3 (0x7248ca294ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
4: frame #6: <unknown function> + 0x126850 (0x7248ca326850 in /usr/lib/x86_64-linux-gnu/libc.so.6)
4: 
4: Exception raised from ncclCommWatchdog at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1418 (most recent call first):
4: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7248bea81e89 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
4: frame #1: <unknown function> + 0x103534e (0x72485ae3534e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
4: frame #2: <unknown function> + 0xcb0e25 (0x72485aab0e25 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
4: frame #3: <unknown function> + 0xdc253 (0x7248be4dc253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
4: frame #4: <unknown function> + 0x94ac3 (0x7248ca294ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
4: frame #5: <unknown function> + 0x126850 (0x7248ca326850 in /usr/lib/x86_64-linux-gnu/libc.so.6)
4: 
6: terminate called after throwing an instance of 'c10::DistBackendError'
6:   what():  [PG 5 Rank 2] Process group watchdog thread terminated with exception: [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=3054764, OpType=ALLREDUCE, NumelIn=67108864, NumelOut=67108864, Timeout(ms)=1800000) ran for 1800009 milliseconds before timing out.
6: Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:565 (most recent call first):
6: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7422e5198e89 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
6: frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1e1 (0x742281406121 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
6: frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x1a0 (0x74228140d4e0 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
6: frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x10f (0x74228140e3ff in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
6: frame #4: <unknown function> + 0xdc253 (0x7422e4adc253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
6: frame #5: <unknown function> + 0x94ac3 (0x7422f0a94ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
6: frame #6: <unknown function> + 0x126850 (0x7422f0b26850 in /usr/lib/x86_64-linux-gnu/libc.so.6)
6: 
6: Exception raised from ncclCommWatchdog at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1418 (most recent call first):
6: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7422e5198e89 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
6: frame #1: <unknown function> + 0x103534e (0x74228143534e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
6: frame #2: <unknown function> + 0xcb0e25 (0x7422810b0e25 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
6: frame #3: <unknown function> + 0xdc253 (0x7422e4adc253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
6: frame #4: <unknown function> + 0x94ac3 (0x7422f0a94ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
6: frame #5: <unknown function> + 0x126850 (0x7422f0b26850 in /usr/lib/x86_64-linux-gnu/libc.so.6)
6: 
5: terminate called after throwing an instance of 'c10::DistBackendError'
5:   what():  [PG 5 Rank 1] Process group watchdog thread terminated with exception: [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=3054764, OpType=ALLREDUCE, NumelIn=67108864, NumelOut=67108864, Timeout(ms)=1800000) ran for 1800016 milliseconds before timing out.
5: Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:565 (most recent call first):
5: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7545b2b98e89 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
5: frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1e1 (0x75454ee06121 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
5: frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x1a0 (0x75454ee0d4e0 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
5: frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x10f (0x75454ee0e3ff in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
5: frame #4: <unknown function> + 0xdc253 (0x7545b24dc253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
5: frame #5: <unknown function> + 0x94ac3 (0x7545be494ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
5: frame #6: <unknown function> + 0x126850 (0x7545be526850 in /usr/lib/x86_64-linux-gnu/libc.so.6)
5: 
5: Exception raised from ncclCommWatchdog at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1418 (most recent call first):
5: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7545b2b98e89 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
5: frame #1: <unknown function> + 0x103534e (0x75454ee3534e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
5: frame #2: <unknown function> + 0xcb0e25 (0x75454eab0e25 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
5: frame #3: <unknown function> + 0xdc253 (0x7545b24dc253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
5: frame #4: <unknown function> + 0x94ac3 (0x7545be494ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
5: frame #5: <unknown function> + 0x126850 (0x7545be526850 in /usr/lib/x86_64-linux-gnu/libc.so.6)
5: 
7: [rank7]:[E ProcessGroupNCCL.cpp:563] [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=3054764, OpType=ALLREDUCE, NumelIn=67108864, NumelOut=67108864, Timeout(ms)=1800000) ran for 1800020 milliseconds before timing out.
7: [rank7]:[E ProcessGroupNCCL.cpp:1537] [PG 5 Rank 3] Timeout at NCCL work: 3054764, last enqueued NCCL work: 3054883, last completed NCCL work: 3054763.
7: [rank7]:[E ProcessGroupNCCL.cpp:577] [Rank 3] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
7: [rank7]:[E ProcessGroupNCCL.cpp:583] [Rank 3] To avoid data inconsistency, we are taking the entire process down.
7: [rank7]:[E ProcessGroupNCCL.cpp:1414] [PG 5 Rank 3] Process group watchdog thread terminated with exception: [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=3054764, OpType=ALLREDUCE, NumelIn=67108864, NumelOut=67108864, Timeout(ms)=1800000) ran for 1800020 milliseconds before timing out.
7: Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:565 (most recent call first):
7: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x76fb36f98e89 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
7: frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1e1 (0x76fad3206121 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
7: frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x1a0 (0x76fad320d4e0 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
7: frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x10f (0x76fad320e3ff in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
7: frame #4: <unknown function> + 0xdc253 (0x76fb368dc253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
7: frame #5: <unknown function> + 0x94ac3 (0x76fb42894ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
7: frame #6: <unknown function> + 0x126850 (0x76fb42926850 in /usr/lib/x86_64-linux-gnu/libc.so.6)
7: 
7: terminate called after throwing an instance of 'c10::DistBackendError'
7:   what():  [PG 5 Rank 3] Process group watchdog thread terminated with exception: [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=3054764, OpType=ALLREDUCE, NumelIn=67108864, NumelOut=67108864, Timeout(ms)=1800000) ran for 1800020 milliseconds before timing out.
7: Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:565 (most recent call first):
7: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x76fb36f98e89 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
7: frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1e1 (0x76fad3206121 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
7: frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x1a0 (0x76fad320d4e0 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
7: frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x10f (0x76fad320e3ff in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
7: frame #4: <unknown function> + 0xdc253 (0x76fb368dc253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
7: frame #5: <unknown function> + 0x94ac3 (0x76fb42894ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
7: frame #6: <unknown function> + 0x126850 (0x76fb42926850 in /usr/lib/x86_64-linux-gnu/libc.so.6)
7: 
7: Exception raised from ncclCommWatchdog at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1418 (most recent call first):
7: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x76fb36f98e89 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
7: frame #1: <unknown function> + 0x103534e (0x76fad323534e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
7: frame #2: <unknown function> + 0xcb0e25 (0x76fad2eb0e25 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
7: frame #3: <unknown function> + 0xdc253 (0x76fb368dc253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
7: frame #4: <unknown function> + 0x94ac3 (0x76fb42894ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
7: frame #5: <unknown function> + 0x126850 (0x76fb42926850 in /usr/lib/x86_64-linux-gnu/libc.so.6)
7: 
2: [rank2]:[E ProcessGroupNCCL.cpp:563] [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=3054761, OpType=ALLREDUCE, NumelIn=8192, NumelOut=8192, Timeout(ms)=1800000) ran for 1800069 milliseconds before timing out.
1: [rank1]:[E ProcessGroupNCCL.cpp:563] [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=3054761, OpType=ALLREDUCE, NumelIn=8192, NumelOut=8192, Timeout(ms)=1800000) ran for 1800071 milliseconds before timing out.
2: [rank2]:[E ProcessGroupNCCL.cpp:1537] [PG 5 Rank 2] Timeout at NCCL work: 3054761, last enqueued NCCL work: 3054763, last completed NCCL work: 3054760.
2: [rank2]:[E ProcessGroupNCCL.cpp:577] [Rank 2] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
2: [rank2]:[E ProcessGroupNCCL.cpp:583] [Rank 2] To avoid data inconsistency, we are taking the entire process down.
2: [rank2]:[E ProcessGroupNCCL.cpp:1414] [PG 5 Rank 2] Process group watchdog thread terminated with exception: [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=3054761, OpType=ALLREDUCE, NumelIn=8192, NumelOut=8192, Timeout(ms)=1800000) ran for 1800069 milliseconds before timing out.
2: Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:565 (most recent call first):
2: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7134fdb98e89 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
2: frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1e1 (0x713499e06121 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
2: frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x1a0 (0x713499e0d4e0 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
2: frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x10f (0x713499e0e3ff in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
2: frame #4: <unknown function> + 0xdc253 (0x7134fd4dc253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
2: frame #5: <unknown function> + 0x94ac3 (0x713509494ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
2: frame #6: <unknown function> + 0x126850 (0x713509526850 in /usr/lib/x86_64-linux-gnu/libc.so.6)
2: 
2: terminate called after throwing an instance of 'c10::DistBackendError'
2:   what():  [PG 5 Rank 2] Process group watchdog thread terminated with exception: [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=3054761, OpType=ALLREDUCE, NumelIn=8192, NumelOut=8192, Timeout(ms)=1800000) ran for 1800069 milliseconds before timing out.
2: Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:565 (most recent call first):
2: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7134fdb98e89 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
2: frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1e1 (0x713499e06121 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
2: frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x1a0 (0x713499e0d4e0 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
2: frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x10f (0x713499e0e3ff in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
2: frame #4: <unknown function> + 0xdc253 (0x7134fd4dc253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
2: frame #5: <unknown function> + 0x94ac3 (0x713509494ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
2: frame #6: <unknown function> + 0x126850 (0x713509526850 in /usr/lib/x86_64-linux-gnu/libc.so.6)
2: 
2: Exception raised from ncclCommWatchdog at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1418 (most recent call first):
2: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7134fdb98e89 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
2: frame #1: <unknown function> + 0x103534e (0x713499e3534e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
2: frame #2: <unknown function> + 0xcb0e25 (0x713499ab0e25 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
2: frame #3: <unknown function> + 0xdc253 (0x7134fd4dc253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
2: frame #4: <unknown function> + 0x94ac3 (0x713509494ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
2: frame #5: <unknown function> + 0x126850 (0x713509526850 in /usr/lib/x86_64-linux-gnu/libc.so.6)
2: 
1: [rank1]:[E ProcessGroupNCCL.cpp:1537] [PG 5 Rank 1] Timeout at NCCL work: 3054761, last enqueued NCCL work: 3054763, last completed NCCL work: 3054760.
1: [rank1]:[E ProcessGroupNCCL.cpp:577] [Rank 1] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
1: [rank1]:[E ProcessGroupNCCL.cpp:583] [Rank 1] To avoid data inconsistency, we are taking the entire process down.
1: [rank1]:[E ProcessGroupNCCL.cpp:1414] [PG 5 Rank 1] Process group watchdog thread terminated with exception: [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=3054761, OpType=ALLREDUCE, NumelIn=8192, NumelOut=8192, Timeout(ms)=1800000) ran for 1800071 milliseconds before timing out.
1: Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:565 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x72bf6bb98e89 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
1: frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1e1 (0x72bf07e06121 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x1a0 (0x72bf07e0d4e0 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x10f (0x72bf07e0e3ff in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #4: <unknown function> + 0xdc253 (0x72bf6b4dc253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #5: <unknown function> + 0x94ac3 (0x72bf77494ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
1: frame #6: <unknown function> + 0x126850 (0x72bf77526850 in /usr/lib/x86_64-linux-gnu/libc.so.6)
1: 
1: terminate called after throwing an instance of 'c10::DistBackendError'
1:   what():  [PG 5 Rank 1] Process group watchdog thread terminated with exception: [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=3054761, OpType=ALLREDUCE, NumelIn=8192, NumelOut=8192, Timeout(ms)=1800000) ran for 1800071 milliseconds before timing out.
1: Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:565 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x72bf6bb98e89 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
1: frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1e1 (0x72bf07e06121 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x1a0 (0x72bf07e0d4e0 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x10f (0x72bf07e0e3ff in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #4: <unknown function> + 0xdc253 (0x72bf6b4dc253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #5: <unknown function> + 0x94ac3 (0x72bf77494ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
1: frame #6: <unknown function> + 0x126850 (0x72bf77526850 in /usr/lib/x86_64-linux-gnu/libc.so.6)
1: 
1: Exception raised from ncclCommWatchdog at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1418 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x72bf6bb98e89 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x103534e (0x72bf07e3534e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #2: <unknown function> + 0xcb0e25 (0x72bf07ab0e25 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #3: <unknown function> + 0xdc253 (0x72bf6b4dc253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #4: <unknown function> + 0x94ac3 (0x72bf77494ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
1: frame #5: <unknown function> + 0x126850 (0x72bf77526850 in /usr/lib/x86_64-linux-gnu/libc.so.6)
1: 
3: [rank3]:[E ProcessGroupNCCL.cpp:563] [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=3054761, OpType=ALLREDUCE, NumelIn=8192, NumelOut=8192, Timeout(ms)=1800000) ran for 1800095 milliseconds before timing out.
3: [rank3]:[E ProcessGroupNCCL.cpp:1537] [PG 5 Rank 3] Timeout at NCCL work: 3054761, last enqueued NCCL work: 3054763, last completed NCCL work: 3054760.
3: [rank3]:[E ProcessGroupNCCL.cpp:577] [Rank 3] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
3: [rank3]:[E ProcessGroupNCCL.cpp:583] [Rank 3] To avoid data inconsistency, we are taking the entire process down.
3: [rank3]:[E ProcessGroupNCCL.cpp:1414] [PG 5 Rank 3] Process group watchdog thread terminated with exception: [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=3054761, OpType=ALLREDUCE, NumelIn=8192, NumelOut=8192, Timeout(ms)=1800000) ran for 1800095 milliseconds before timing out.
3: Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:565 (most recent call first):
3: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x719430a81e89 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
3: frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1e1 (0x7193cce06121 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
3: frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x1a0 (0x7193cce0d4e0 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
3: frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x10f (0x7193cce0e3ff in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
3: frame #4: <unknown function> + 0xdc253 (0x7194304dc253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
3: frame #5: <unknown function> + 0x94ac3 (0x71943c294ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
3: frame #6: <unknown function> + 0x126850 (0x71943c326850 in /usr/lib/x86_64-linux-gnu/libc.so.6)
3: 
3: terminate called after throwing an instance of 'c10::DistBackendError'
3:   what():  [PG 5 Rank 3] Process group watchdog thread terminated with exception: [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=3054761, OpType=ALLREDUCE, NumelIn=8192, NumelOut=8192, Timeout(ms)=1800000) ran for 1800095 milliseconds before timing out.
3: Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:565 (most recent call first):
3: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x719430a81e89 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
3: frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1e1 (0x7193cce06121 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
3: frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x1a0 (0x7193cce0d4e0 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
3: frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x10f (0x7193cce0e3ff in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
3: frame #4: <unknown function> + 0xdc253 (0x7194304dc253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
3: frame #5: <unknown function> + 0x94ac3 (0x71943c294ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
3: frame #6: <unknown function> + 0x126850 (0x71943c326850 in /usr/lib/x86_64-linux-gnu/libc.so.6)
3: 
3: Exception raised from ncclCommWatchdog at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1418 (most recent call first):
3: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x719430a81e89 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
3: frame #1: <unknown function> + 0x103534e (0x7193cce3534e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
3: frame #2: <unknown function> + 0xcb0e25 (0x7193ccab0e25 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
3: frame #3: <unknown function> + 0xdc253 (0x7194304dc253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
3: frame #4: <unknown function> + 0x94ac3 (0x71943c294ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
3: frame #5: <unknown function> + 0x126850 (0x71943c326850 in /usr/lib/x86_64-linux-gnu/libc.so.6)
3: 
5: FlashAttention Installed
3: FlashAttention Installed
7: FlashAttention Installed
6: FlashAttention Installed
4: FlashAttention Installed
1: FlashAttention Installed
5: FlashAttention Installed
1: FlashAttention Installed
4: FlashAttention Installed
6: FlashAttention Installed
3: FlashAttention Installed
7: FlashAttention Installed
5: /usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 23 leaked semaphore objects to clean up at shutdown
5:   warnings.warn('resource_tracker: There appear to be %d '
4: /usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 23 leaked semaphore objects to clean up at shutdown
4:   warnings.warn('resource_tracker: There appear to be %d '
7: /usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 23 leaked semaphore objects to clean up at shutdown
7:   warnings.warn('resource_tracker: There appear to be %d '
6: /usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 23 leaked semaphore objects to clean up at shutdown
6:   warnings.warn('resource_tracker: There appear to be %d '
1: /usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 23 leaked semaphore objects to clean up at shutdown
1:   warnings.warn('resource_tracker: There appear to be %d '
3: /usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 23 leaked semaphore objects to clean up at shutdown
3:   warnings.warn('resource_tracker: There appear to be %d '
4: /workspace/ft-llm/run_and_time.sh: line 68: 2523565 Aborted                 (core dumped) ${LOGGER:-} ${CMD[@]} train.py
5: /workspace/ft-llm/run_and_time.sh: line 68: 2523590 Aborted                 (core dumped) ${LOGGER:-} ${CMD[@]} train.py
7: /workspace/ft-llm/run_and_time.sh: line 68: 2523566 Aborted                 (core dumped) ${LOGGER:-} ${CMD[@]} train.py
6: /workspace/ft-llm/run_and_time.sh: line 68: 2523518 Aborted                 (core dumped) ${LOGGER:-} ${CMD[@]} train.py
1: /workspace/ft-llm/run_and_time.sh: line 68: 2523606 Aborted                 (core dumped) ${LOGGER:-} ${CMD[@]} train.py
3: /workspace/ft-llm/run_and_time.sh: line 68: 2523517 Aborted                 (core dumped) ${LOGGER:-} ${CMD[@]} train.py
2: /workspace/ft-llm/run_and_time.sh: line 68: 2523542 Aborted                 (core dumped) ${LOGGER:-} ${CMD[@]} train.py
