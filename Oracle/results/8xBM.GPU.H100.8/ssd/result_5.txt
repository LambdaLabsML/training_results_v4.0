+ echo 'Beginning trial 5 of 5'
Beginning trial 5 of 5
+ echo ':::DLPAL /nfs/scratch/sd/ssd/images/sd+mlperf-nvidia+ssd.sqsh 728 8 compute-hpc-node-[25,73,96,147,157,186,194,199] BM.GPU.H100.8 Cluster DGXH100_008x08x004'
:::DLPAL /nfs/scratch/sd/ssd/images/sd+mlperf-nvidia+ssd.sqsh 728 8 compute-hpc-node-[25,73,96,147,157,186,194,199] BM.GPU.H100.8 Cluster DGXH100_008x08x004
++ srun --ntasks=1 --container-name=single_stage_detector_728 mlperf-sysjson.sh
srun: warning: can't run 1 processes on 8 nodes, setting nnodes to 1
+ echo ':::SYSJSON {"submitter":"Oracle","division":"closed","status":"cloud","system_name":"BM.GPU.H100.8","number_of_nodes":"8","host_processors_per_node":"2","host_processor_model_name":"Intel(R) Xeon(R) Platinum 8480+","host_processor_core_count":"56","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"2.0 TB","host_storage_type":"","host_storage_capacity":"","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"8","accelerator_model_name":"NVIDIA H100 80GB HBM3","accelerator_host_interconnect":"","accelerator_frequency":"","accelerator_on-chip_memories":"","accelerator_memory_configuration":"","accelerator_memory_capacity":"81559 MiB","accelerator_interconnect":"","accelerator_interconnect_topology":"","cooling":"","hw_notes":"","framework":"PyTorch NVIDIA Release 24.04","framework_name":"","other_software_stack":{"cuda_version":"12.4.1.003","cuda_driver_version":"550.54.15","nccl_version":"2.21.5","cublas_version":"12.4.5.8","cudnn_version":"9.1.0.70","trt_version":"8.6.3.1+cuda12.2.2.009","dali_version":"1.36.0","mofed_version":"5.4-rdmacore39.0","openmpi_version":"4.1.7","kernel_version":"Linux 6.5.0-1018-oracle","nvidia_kernel_driver":"535.161.07"},"operating_system":"Ubuntu 22.04.4 LTS","sw_notes":""}'
:::SYSJSON {"submitter":"Oracle","division":"closed","status":"cloud","system_name":"BM.GPU.H100.8","number_of_nodes":"8","host_processors_per_node":"2","host_processor_model_name":"Intel(R) Xeon(R) Platinum 8480+","host_processor_core_count":"56","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"2.0 TB","host_storage_type":"","host_storage_capacity":"","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"8","accelerator_model_name":"NVIDIA H100 80GB HBM3","accelerator_host_interconnect":"","accelerator_frequency":"","accelerator_on-chip_memories":"","accelerator_memory_configuration":"","accelerator_memory_capacity":"81559 MiB","accelerator_interconnect":"","accelerator_interconnect_topology":"","cooling":"","hw_notes":"","framework":"PyTorch NVIDIA Release 24.04","framework_name":"","other_software_stack":{"cuda_version":"12.4.1.003","cuda_driver_version":"550.54.15","nccl_version":"2.21.5","cublas_version":"12.4.5.8","cudnn_version":"9.1.0.70","trt_version":"8.6.3.1+cuda12.2.2.009","dali_version":"1.36.0","mofed_version":"5.4-rdmacore39.0","openmpi_version":"4.1.7","kernel_version":"Linux 6.5.0-1018-oracle","nvidia_kernel_driver":"535.161.07"},"operating_system":"Ubuntu 22.04.4 LTS","sw_notes":""}
+ srun -N1 -n1 --container-name=single_stage_detector_728 python -c ''
+ '[' 1 -eq 1 ']'
+ srun --ntasks=8 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on compute-hpc-node-73
Clearing cache on compute-hpc-node-194
Clearing cache on compute-hpc-node-199
Clearing cache on compute-hpc-node-147
Clearing cache on compute-hpc-node-25
Clearing cache on compute-hpc-node-96
Clearing cache on compute-hpc-node-157
Clearing cache on compute-hpc-node-186
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=8 --container-name=single_stage_detector_728 python -c '
from mlperf_logger import mllogger
mllogger.event(key=mllogger.constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1715175598877, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1715175598891, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1715175598906, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1715175598929, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1715175598937, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1715175598983, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1715175598991, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1715175599028, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
+ sleep 30
+ srun --ntasks=64 --ntasks-per-node=8 --container-name=single_stage_detector_728 --container-mounts=/mnt/localdisk/sd/ssd/ssd/datasets/datasets:/datasets/open-images-v6,/nfs/scratch/sd/ssd/logs:/results,/mnt/localdisk/sd/ssd/ssd/weights:/root/.cache/torch,/usr/mpi/gcc/openmpi-4.1.7a1/bin:/usr/mpi/gcc/openmpi-4.1.7a1/bin,/nfs/cluster:/nfs/cluster --container-workdir=/workspace/ssd --container-env=MASTER_PORT,MASTER_ADDR slurm2pytorch ./run_and_time.sh
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 1: LOCAL_RANK 1, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 1, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 4: LOCAL_RANK 4, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 4, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 5: LOCAL_RANK 5, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 5, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 2: LOCAL_RANK 2, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 2, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 6: LOCAL_RANK 6, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 6, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 0: LOCAL_RANK 0, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 0, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 7: LOCAL_RANK 7, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 7, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 3: LOCAL_RANK 3, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 3, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
RANK 18: LOCAL_RANK 2, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 18, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 20: LOCAL_RANK 4, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 20, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 17: LOCAL_RANK 1, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 17, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 16: LOCAL_RANK 0, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 16, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 19: LOCAL_RANK 3, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 19, SLURM_LOCALID 3, OMP_NUM_THREADS 1
RANK 22: LOCAL_RANK 6, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 22, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 21: LOCAL_RANK 5, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 21, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
RANK 23: LOCAL_RANK 7, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 23, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
RANK 56: LOCAL_RANK 0, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 56, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 57: LOCAL_RANK 1, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 57, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 61: LOCAL_RANK 5, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 61, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 62: LOCAL_RANK 6, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 62, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 63: LOCAL_RANK 7, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 63, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 60: LOCAL_RANK 4, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 60, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 58: LOCAL_RANK 2, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 58, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
RANK 59: LOCAL_RANK 3, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 59, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
RANK 37: LOCAL_RANK 5, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 37, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 35: LOCAL_RANK 3, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 35, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 38: LOCAL_RANK 6, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 38, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 39: LOCAL_RANK 7, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 39, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 33: LOCAL_RANK 1, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 33, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 36: LOCAL_RANK 4, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 36, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 34: LOCAL_RANK 2, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 34, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 32: LOCAL_RANK 0, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 32, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
RANK 8: LOCAL_RANK 0, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 8, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 12: LOCAL_RANK 4, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 12, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 10: LOCAL_RANK 2, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 10, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 15: LOCAL_RANK 7, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 15, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 11: LOCAL_RANK 3, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 11, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 14: LOCAL_RANK 6, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 14, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 9: LOCAL_RANK 1, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 9, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
RANK 13: LOCAL_RANK 5, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 13, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
RANK 29: LOCAL_RANK 5, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 29, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 27: LOCAL_RANK 3, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 27, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 30: LOCAL_RANK 6, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 30, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 25: LOCAL_RANK 1, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 25, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 26: LOCAL_RANK 2, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 26, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 31: LOCAL_RANK 7, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 31, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 24: LOCAL_RANK 0, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 24, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 28: LOCAL_RANK 4, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 28, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
RANK 42: LOCAL_RANK 2, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 42, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 40: LOCAL_RANK 0, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 40, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 47: LOCAL_RANK 7, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 47, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 45: LOCAL_RANK 5, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 45, SLURM_LOCALID 5, OMP_NUM_THREADS 1
RANK 46: LOCAL_RANK 6, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 46, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 41: LOCAL_RANK 1, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 41, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 44: LOCAL_RANK 4, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 44, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 43: LOCAL_RANK 3, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 43, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
RANK 55: LOCAL_RANK 7, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 55, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 51: LOCAL_RANK 3, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 51, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 48: LOCAL_RANK 0, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 48, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
RANK 52: LOCAL_RANK 4, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 52, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 49: LOCAL_RANK 1, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 49, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 54: LOCAL_RANK 6, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 54, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 50: LOCAL_RANK 2, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 50, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-08 01:40:30 PM
RANK 53: LOCAL_RANK 5, MASTER_ADDR compute-hpc-node-25, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 728, SLURM_NTASKS 64, SLURM_PROCID 53, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
| distributed init (rank 48): env://
| distributed init (rank 16): env://
| distributed init (rank 8): env://
| distributed init (rank 56): env://
| distributed init (rank 40): env://
| distributed init (rank 32): env://
| distributed init (rank 24): env://
| distributed init (rank 0): env://
| distributed init (rank 17): env://
| distributed init (rank 19): env://
| distributed init (rank 21): env://
| distributed init (rank 22): env://
| distributed init (rank 18): env://
| distributed init (rank 20): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 61): env://
| distributed init (rank 63): env://
| distributed init (rank 58): env://
| distributed init (rank 23): env://
| distributed init (rank 59): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 57): env://
| distributed init (rank 62): env://
| distributed init (rank 60): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 27): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 28): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 31): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 30): env://
| distributed init (rank 26): env://
| distributed init (rank 25): env://
| distributed init (rank 29): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 14): env://
| distributed init (rank 10): env://
| distributed init (rank 9): env://
| distributed init (rank 13): env://
| distributed init (rank 15): env://
| distributed init (rank 44): env://
| distributed init (rank 42): env://
| distributed init (rank 46): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 43): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 47): env://
| distributed init (rank 11): env://
| distributed init (rank 12): env://
| distributed init (rank 2): env://
| distributed init (rank 54): env://
| distributed init (rank 49): env://
| distributed init (rank 50): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 55): env://
| distributed init (rank 41): env://
| distributed init (rank 45): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 53): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 52): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 51): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 36): env://
| distributed init (rank 1): env://
| distributed init (rank 34): env://
| distributed init (rank 7): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 3): env://
| distributed init (rank 33): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 39): env://
| distributed init (rank 37): env://
| distributed init (rank 38): env://
| distributed init (rank 5): env://
| distributed init (rank 4): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 6): env://
| distributed init (rank 35): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
NCCL version 2.21.5+cuda12.4
:::MLLOG {"namespace": "", "time_ms": 1715175643255, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "ssd", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 350}}
:::MLLOG {"namespace": "", "time_ms": 1715175643255, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "SUBMISSION_ORG_PLACEHOLDER", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 350}}
:::MLLOG {"namespace": "", "time_ms": 1715175643255, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 350}}
:::MLLOG {"namespace": "", "time_ms": 1715175643255, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 350}}
:::MLLOG {"namespace": "", "time_ms": 1715175643255, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "8xSUBMISSION_PLATFORM_PLACEHOLDER", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 350}}
:::MLLOG {"namespace": "", "time_ms": 1715175643256, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 351}}
:::MLLOG {"namespace": "", "time_ms": 1715175643259, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342660, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643288, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342666, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643288, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342663, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643288, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342661, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643288, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342659, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643288, "event_type": "POINT_IN_TIME", "key": "local_batch_size", "value": 4, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 369}}
:::MLLOG {"namespace": "", "time_ms": 1715175643288, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342665, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643288, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342664, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643288, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 256, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 370}}
:::MLLOG {"namespace": "", "time_ms": 1715175643288, "event_type": "POINT_IN_TIME", "key": "epoch_count", "value": 6, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 371}}
:::MLLOG {"namespace": "", "time_ms": 1715175643288, "event_type": "POINT_IN_TIME", "key": "first_epoch_num", "value": 0, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 372}}
:::MLLOG {"namespace": "", "time_ms": 1715175643288, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342662, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
Namespace(backbone='resnext50_32x4d', trainable_backbone_layers=3, sync_bn=False, data_layout='channels_last', amp=True, async_coco=True, async_coco_check_freq=20, num_eval_ranks=64, dataset='openimages-mlperf', dataset_path='/datasets/open-images-v6', num_classes=None, train_data_path=None, train_annotations_file=None, val_data_path=None, val_annotations_file=None, image_size=[800, 800], data_augmentation='hflip', epochs=6, max_iters_per_epoch=None, max_eval_iters_per_epoch=None, start_epoch=0, output_dir=None, target_map=0.34, resume='', pretrained=False, batch_size=4, eval_batch_size=32, lr=0.0001, warmup_epochs=1, warmup_factor=0.001, workers=4, print_freq=20, eval_print_freq=20, test_only=False, seed=1825342659, device='cuda', cocoeval='nvidia', coco_threads=8, world_size=64, dist_url='env://', frozen_bn_opt=True, frozen_bn_fp16=True, jit=True, cuda_graphs=True, cuda_graphs_eval=False, cls_head_pad=True, reg_head_pad=True, cuda_graphs_syn=True, model_warmup_epochs=16, master_weights=True, dali=True, dali_matched_idxs=True, dali_eval=True, dali_eval_cache=False, dali_prefetch_queue_depth=2, dali_cpu_decode=False, dali_pinned_memory_size=268435456, dali_cmn=0, dali_cmn_hint=0, dali_decoder_hint_height=7360, dali_decoder_hint_width=7360, dali_decoder_hw_load=0.65, dali_input_batch_multiplier=1, dali_eval_cmn_hint=0, dali_eval_decoder_hint_height=0, dali_eval_decoder_hint_width=0, dali_eval_decoder_hw_load=0.65, dali_eval_input_batch_multiplier=1, dali_sync=False, dali_resize_first=False, apex_adam=True, apex_focal_loss=True, apex_backbone_fusion=True, apex_head_fusion=True, broadcast_buffers=False, fp16_allreduce=False, ddp_bucket_sz=25, ddp_first_bucket_sz=None, no_gradient_as_bucket_view=False, max_boxes=1000, cudnn_bench=False, deterministic=False, not_graphed_prologues=False, metric_loss=False, syn_dataset=False, sync_after_graph_replay=False, allreduce_barrier=False, skip_eval=False, cuda_profiler=False, cuda_profiler_eval=False, cuda_profiler_start=-1, cuda_profiler_stop=-1, power_benchmark=False, power_sustain_time=600, rank=0, gpu=0, distributed=True, dist_backend='nccl', ranks=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63], num_train_ranks=64, train_ranks=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63], eval_ranks=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63], train_rank=0, eval_rank=0)
Getting dataset information
Creating model
:::MLLOG {"namespace": "", "time_ms": 1715175643290, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342708, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643290, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342709, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643290, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342710, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643290, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342711, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643290, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342713, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643290, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342714, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643292, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342712, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643292, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342707, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643292, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342676, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643292, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342678, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643292, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342679, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643292, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342675, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643292, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342680, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643292, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342681, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643292, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342682, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643292, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342677, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643295, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342669, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643295, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342671, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643295, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342674, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643296, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342672, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643295, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342667, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643296, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342670, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643297, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342683, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643297, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342686, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643297, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342690, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643297, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342684, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643297, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342685, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643297, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342687, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643297, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342689, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643297, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342688, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643297, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342673, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643297, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342668, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643298, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342699, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643298, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342702, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643298, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342703, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643298, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342704, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643298, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342706, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643298, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342700, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643298, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342705, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643298, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342701, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643299, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342715, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643299, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342721, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643299, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342722, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643299, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342716, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643299, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342717, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643299, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342718, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643299, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342719, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643299, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342720, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643302, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342693, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643302, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342697, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643302, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342694, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643302, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342695, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643302, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342696, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643302, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342698, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643302, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342691, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643302, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1825342692, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715175643298, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 209, "tensor": "module.backbone.fpn.extra_blocks.p6.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643317, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 211, "tensor": "module.backbone.fpn.extra_blocks.p6.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643317, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 209, "tensor": "module.backbone.fpn.extra_blocks.p7.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643320, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 211, "tensor": "module.backbone.fpn.extra_blocks.p7.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643453, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643454, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643454, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643454, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643455, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643455, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643455, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643455, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643455, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643455, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643456, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643456, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643456, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643456, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643457, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643458, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643458, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643458, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643459, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643460, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643460, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643461, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.3.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643461, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.3.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643461, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.3.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643462, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643463, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643464, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643466, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643468, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643471, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643471, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643473, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643476, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643476, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643479, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.3.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643481, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.3.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643481, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.3.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643484, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.4.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643486, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.4.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643486, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.4.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643489, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.5.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643491, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.5.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643492, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.5.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643494, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643499, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643500, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643509, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643518, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643527, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643528, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643537, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643547, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643548, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643647, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.inner_blocks.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643648, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.inner_blocks.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643648, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.inner_blocks.1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643649, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.inner_blocks.1.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643649, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.inner_blocks.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643651, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.inner_blocks.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643652, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.layer_blocks.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643654, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.layer_blocks.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643654, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.layer_blocks.1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643657, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.layer_blocks.1.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643657, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.layer_blocks.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643659, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.layer_blocks.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643671, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643674, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643675, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643677, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643677, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.4.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643680, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.4.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643680, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.6.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643682, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.6.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643710, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 148, "tensor": "module.head.classification_head.cls_logits.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643733, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 150, "tensor": "module.head.classification_head.cls_logits.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643744, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 317, "tensor": "module.head.regression_head.bbox_reg.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643745, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 319, "tensor": "module.head.regression_head.bbox_reg.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643745, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 324, "tensor": "module.head.regression_head.conv.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643747, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 326, "tensor": "module.head.regression_head.conv.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643748, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 324, "tensor": "module.head.regression_head.conv.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643750, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 326, "tensor": "module.head.regression_head.conv.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643750, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 324, "tensor": "module.head.regression_head.conv.4.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643753, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 326, "tensor": "module.head.regression_head.conv.4.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643753, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 324, "tensor": "module.head.regression_head.conv.6.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715175643756, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 326, "tensor": "module.head.regression_head.conv.6.bias"}}
Casting convolutional layers to half
[rank12]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank11]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank10]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank9]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank13]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank0]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank14]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank4]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank1]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank7]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank6]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank2]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank3]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank5]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank8]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank22]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank20]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank18]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank21]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank19]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank16]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank39]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank23]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank36]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank33]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank38]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank37]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank35]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank17]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank34]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank53]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank29]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank50]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank57]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank31]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank27]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank28]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank49]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank61]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank30]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank24]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank51]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank26]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank25]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank63]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank56]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank58]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank54]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank55]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank59]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank48]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank32]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank15]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank42]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank52]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank62]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank60]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank40]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank45]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank44]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank46]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank47]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank43]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank41]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
:::MLLOG {"namespace": "", "time_ms": 1715175643862, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "adam", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 448}}
:::MLLOG {"namespace": "", "time_ms": 1715175643863, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.0001, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 449}}
:::MLLOG {"namespace": "", "time_ms": 1715175643863, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 450}}
:::MLLOG {"namespace": "", "time_ms": 1715175643863, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_epochs", "value": 1, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 451}}
:::MLLOG {"namespace": "", "time_ms": 1715175643863, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_factor", "value": 0.001, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 452}}
:::MLLOG {"namespace": "", "time_ms": 1715175643863, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 453}}
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Model eval warmup
Time: 48.04653263092041 sec
Creating Dali training dataloader
Creating Dali eval dataloader
CUDA graph capture for training
CUDA graphs: data preprocessing complete
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
CUDA graphs: warmup iterations complete
CUDA graphs: capture complete
CUDA graph capture for training complete
:::MLLOG {"namespace": "", "time_ms": 1715175712846, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 573}}
:::MLLOG {"namespace": "", "time_ms": 1715175712847, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 577}}
:::MLLOG {"namespace": "", "time_ms": 1715175712848, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 4572, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 625}}
:::MLLOG {"namespace": "", "time_ms": 1715175712848, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 13, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 628}}
Running ...
:::MLLOG {"namespace": "", "time_ms": 1715175712849, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 0, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 0}}
Epoch: [0]  [   0/4572]  eta: 0:01:27    time: 0.0192  data: 0.0002  max mem: 13772
Epoch: [0]  [  20/4572]  eta: 0:01:32    time: 0.0203  data: 0.0181  max mem: 13772
Epoch: [0]  [  40/4572]  eta: 0:01:31    time: 0.0201  data: 0.0179  max mem: 13772
Epoch: [0]  [  60/4572]  eta: 0:01:31    time: 0.0201  data: 0.0179  max mem: 13772
Epoch: [0]  [  80/4572]  eta: 0:01:30    time: 0.0205  data: 0.0182  max mem: 13772
Epoch: [0]  [ 100/4572]  eta: 0:01:30    time: 0.0200  data: 0.0178  max mem: 13772
Epoch: [0]  [ 120/4572]  eta: 0:01:29    time: 0.0198  data: 0.0170  max mem: 13772
Epoch: [0]  [ 140/4572]  eta: 0:01:29    time: 0.0200  data: 0.0177  max mem: 13772
Epoch: [0]  [ 160/4572]  eta: 0:01:28    time: 0.0203  data: 0.0176  max mem: 13772
Epoch: [0]  [ 180/4572]  eta: 0:01:28    time: 0.0201  data: 0.0175  max mem: 13772
Epoch: [0]  [ 200/4572]  eta: 0:01:27    time: 0.0197  data: 0.0175  max mem: 13772
Epoch: [0]  [ 220/4572]  eta: 0:01:27    time: 0.0197  data: 0.0174  max mem: 13772
Epoch: [0]  [ 240/4572]  eta: 0:01:26    time: 0.0197  data: 0.0175  max mem: 13772
Epoch: [0]  [ 260/4572]  eta: 0:01:26    time: 0.0198  data: 0.0177  max mem: 13772
Epoch: [0]  [ 280/4572]  eta: 0:01:25    time: 0.0198  data: 0.0171  max mem: 13772
Epoch: [0]  [ 300/4572]  eta: 0:01:25    time: 0.0199  data: 0.0173  max mem: 13772
Epoch: [0]  [ 320/4572]  eta: 0:01:24    time: 0.0196  data: 0.0170  max mem: 13772
Epoch: [0]  [ 340/4572]  eta: 0:01:24    time: 0.0197  data: 0.0176  max mem: 13772
Epoch: [0]  [ 360/4572]  eta: 0:01:23    time: 0.0197  data: 0.0170  max mem: 13772
Epoch: [0]  [ 380/4572]  eta: 0:01:23    time: 0.0198  data: 0.0176  max mem: 13772
Epoch: [0]  [ 400/4572]  eta: 0:01:23    time: 0.0199  data: 0.0177  max mem: 13772
Epoch: [0]  [ 420/4572]  eta: 0:01:22    time: 0.0197  data: 0.0170  max mem: 13772
Epoch: [0]  [ 440/4572]  eta: 0:01:22    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [0]  [ 460/4572]  eta: 0:01:21    time: 0.0198  data: 0.0171  max mem: 13772
Epoch: [0]  [ 480/4572]  eta: 0:01:21    time: 0.0196  data: 0.0174  max mem: 13772
Epoch: [0]  [ 500/4572]  eta: 0:01:20    time: 0.0199  data: 0.0167  max mem: 13772
Epoch: [0]  [ 520/4572]  eta: 0:01:20    time: 0.0201  data: 0.0179  max mem: 13772
Epoch: [0]  [ 540/4572]  eta: 0:01:20    time: 0.0197  data: 0.0170  max mem: 13772
Epoch: [0]  [ 560/4572]  eta: 0:01:19    time: 0.0199  data: 0.0172  max mem: 13772
Epoch: [0]  [ 580/4572]  eta: 0:01:19    time: 0.0196  data: 0.0174  max mem: 13772
Epoch: [0]  [ 600/4572]  eta: 0:01:18    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [0]  [ 620/4572]  eta: 0:01:18    time: 0.0196  data: 0.0167  max mem: 13772
Epoch: [0]  [ 640/4572]  eta: 0:01:18    time: 0.0200  data: 0.0172  max mem: 13772
Epoch: [0]  [ 660/4572]  eta: 0:01:17    time: 0.0196  data: 0.0167  max mem: 13772
Epoch: [0]  [ 680/4572]  eta: 0:01:17    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [0]  [ 700/4572]  eta: 0:01:16    time: 0.0197  data: 0.0168  max mem: 13772
Epoch: [0]  [ 720/4572]  eta: 0:01:16    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [0]  [ 740/4572]  eta: 0:01:16    time: 0.0205  data: 0.0182  max mem: 13772
Epoch: [0]  [ 760/4572]  eta: 0:01:15    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [0]  [ 780/4572]  eta: 0:01:15    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [0]  [ 800/4572]  eta: 0:01:14    time: 0.0198  data: 0.0170  max mem: 13772
Epoch: [0]  [ 820/4572]  eta: 0:01:14    time: 0.0198  data: 0.0170  max mem: 13772
Epoch: [0]  [ 840/4572]  eta: 0:01:14    time: 0.0196  data: 0.0167  max mem: 13772
Epoch: [0]  [ 860/4572]  eta: 0:01:13    time: 0.0196  data: 0.0167  max mem: 13772
Epoch: [0]  [ 880/4572]  eta: 0:01:13    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [0]  [ 900/4572]  eta: 0:01:12    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [0]  [ 920/4572]  eta: 0:01:12    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [0]  [ 940/4572]  eta: 0:01:11    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [0]  [ 960/4572]  eta: 0:01:11    time: 0.0200  data: 0.0177  max mem: 13772
Epoch: [0]  [ 980/4572]  eta: 0:01:11    time: 0.0197  data: 0.0168  max mem: 13772
Epoch: [0]  [1000/4572]  eta: 0:01:10    time: 0.0196  data: 0.0167  max mem: 13772
Epoch: [0]  [1020/4572]  eta: 0:01:10    time: 0.0197  data: 0.0174  max mem: 13772
Epoch: [0]  [1040/4572]  eta: 0:01:09    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [0]  [1060/4572]  eta: 0:01:09    time: 0.0199  data: 0.0170  max mem: 13772
Epoch: [0]  [1080/4572]  eta: 0:01:09    time: 0.0200  data: 0.0172  max mem: 13772
Epoch: [0]  [1100/4572]  eta: 0:01:08    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [0]  [1120/4572]  eta: 0:01:08    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [0]  [1140/4572]  eta: 0:01:07    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [0]  [1160/4572]  eta: 0:01:07    time: 0.0199  data: 0.0168  max mem: 13772
Epoch: [0]  [1180/4572]  eta: 0:01:07    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [0]  [1200/4572]  eta: 0:01:06    time: 0.0198  data: 0.0175  max mem: 13772
Epoch: [0]  [1220/4572]  eta: 0:01:06    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [0]  [1240/4572]  eta: 0:01:05    time: 0.0197  data: 0.0174  max mem: 13772
Epoch: [0]  [1260/4572]  eta: 0:01:05    time: 0.0201  data: 0.0167  max mem: 13772
Epoch: [0]  [1280/4572]  eta: 0:01:05    time: 0.0199  data: 0.0170  max mem: 13772
Epoch: [0]  [1300/4572]  eta: 0:01:04    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [0]  [1320/4572]  eta: 0:01:04    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [0]  [1340/4572]  eta: 0:01:03    time: 0.0196  data: 0.0174  max mem: 13772
Epoch: [0]  [1360/4572]  eta: 0:01:03    time: 0.0197  data: 0.0168  max mem: 13772
Epoch: [0]  [1380/4572]  eta: 0:01:03    time: 0.0197  data: 0.0174  max mem: 13772
Epoch: [0]  [1400/4572]  eta: 0:01:02    time: 0.0198  data: 0.0170  max mem: 13772
Epoch: [0]  [1420/4572]  eta: 0:01:02    time: 0.0200  data: 0.0173  max mem: 13772
Epoch: [0]  [1440/4572]  eta: 0:01:01    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [0]  [1460/4572]  eta: 0:01:01    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [0]  [1480/4572]  eta: 0:01:01    time: 0.0198  data: 0.0169  max mem: 13772
Epoch: [0]  [1500/4572]  eta: 0:01:00    time: 0.0204  data: 0.0175  max mem: 13772
Epoch: [0]  [1520/4572]  eta: 0:01:00    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [0]  [1540/4572]  eta: 0:01:00    time: 0.0200  data: 0.0177  max mem: 13772
Epoch: [0]  [1560/4572]  eta: 0:00:59    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [0]  [1580/4572]  eta: 0:00:59    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [0]  [1600/4572]  eta: 0:00:58    time: 0.0196  data: 0.0172  max mem: 13772
Epoch: [0]  [1620/4572]  eta: 0:00:58    time: 0.0195  data: 0.0173  max mem: 13772
Epoch: [0]  [1640/4572]  eta: 0:00:58    time: 0.0198  data: 0.0170  max mem: 13772
Epoch: [0]  [1660/4572]  eta: 0:00:57    time: 0.0198  data: 0.0170  max mem: 13772
Epoch: [0]  [1680/4572]  eta: 0:00:57    time: 0.0198  data: 0.0170  max mem: 13772
Epoch: [0]  [1700/4572]  eta: 0:00:56    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [0]  [1720/4572]  eta: 0:00:56    time: 0.0198  data: 0.0169  max mem: 13772
Epoch: [0]  [1740/4572]  eta: 0:00:56    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [0]  [1760/4572]  eta: 0:00:55    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [0]  [1780/4572]  eta: 0:00:55    time: 0.0196  data: 0.0167  max mem: 13772
Epoch: [0]  [1800/4572]  eta: 0:00:54    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [0]  [1820/4572]  eta: 0:00:54    time: 0.0196  data: 0.0167  max mem: 13772
Epoch: [0]  [1840/4572]  eta: 0:00:54    time: 0.0203  data: 0.0175  max mem: 13772
Epoch: [0]  [1860/4572]  eta: 0:00:53    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [0]  [1880/4572]  eta: 0:00:53    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [0]  [1900/4572]  eta: 0:00:52    time: 0.0204  data: 0.0176  max mem: 13772
Epoch: [0]  [1920/4572]  eta: 0:00:52    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [0]  [1940/4572]  eta: 0:00:52    time: 0.0198  data: 0.0175  max mem: 13772
Epoch: [0]  [1960/4572]  eta: 0:00:51    time: 0.0198  data: 0.0168  max mem: 13772
Epoch: [0]  [1980/4572]  eta: 0:00:51    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [0]  [2000/4572]  eta: 0:00:50    time: 0.0196  data: 0.0167  max mem: 13772
Epoch: [0]  [2020/4572]  eta: 0:00:50    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [0]  [2040/4572]  eta: 0:00:50    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [0]  [2060/4572]  eta: 0:00:49    time: 0.0201  data: 0.0179  max mem: 13772
Epoch: [0]  [2080/4572]  eta: 0:00:49    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [0]  [2100/4572]  eta: 0:00:48    time: 0.0204  data: 0.0176  max mem: 13772
Epoch: [0]  [2120/4572]  eta: 0:00:48    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [0]  [2140/4572]  eta: 0:00:48    time: 0.0202  data: 0.0173  max mem: 13772
Epoch: [0]  [2160/4572]  eta: 0:00:47    time: 0.0203  data: 0.0175  max mem: 13772
Epoch: [0]  [2180/4572]  eta: 0:00:47    time: 0.0204  data: 0.0176  max mem: 13772
Epoch: [0]  [2200/4572]  eta: 0:00:46    time: 0.0197  data: 0.0170  max mem: 13772
Epoch: [0]  [2220/4572]  eta: 0:00:46    time: 0.0198  data: 0.0170  max mem: 13772
Epoch: [0]  [2240/4572]  eta: 0:00:46    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [0]  [2260/4572]  eta: 0:00:45    time: 0.0196  data: 0.0167  max mem: 13772
Epoch: [0]  [2280/4572]  eta: 0:00:45    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [0]  [2300/4572]  eta: 0:00:44    time: 0.0200  data: 0.0177  max mem: 13772
Epoch: [0]  [2320/4572]  eta: 0:00:44    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [0]  [2340/4572]  eta: 0:00:44    time: 0.0202  data: 0.0173  max mem: 13772
Epoch: [0]  [2360/4572]  eta: 0:00:43    time: 0.0199  data: 0.0171  max mem: 13772
Epoch: [0]  [2380/4572]  eta: 0:00:43    time: 0.0204  data: 0.0176  max mem: 13772
Epoch: [0]  [2400/4572]  eta: 0:00:42    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [0]  [2420/4572]  eta: 0:00:42    time: 0.0196  data: 0.0167  max mem: 13772
Epoch: [0]  [2440/4572]  eta: 0:00:42    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [0]  [2460/4572]  eta: 0:00:41    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [0]  [2480/4572]  eta: 0:00:41    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [0]  [2500/4572]  eta: 0:00:40    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [0]  [2520/4572]  eta: 0:00:40    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [0]  [2540/4572]  eta: 0:00:40    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [0]  [2560/4572]  eta: 0:00:39    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [0]  [2580/4572]  eta: 0:00:39    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [0]  [2600/4572]  eta: 0:00:39    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [0]  [2620/4572]  eta: 0:00:38    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [0]  [2640/4572]  eta: 0:00:38    time: 0.0196  data: 0.0167  max mem: 13772
Epoch: [0]  [2660/4572]  eta: 0:00:37    time: 0.0202  data: 0.0174  max mem: 13772
Epoch: [0]  [2680/4572]  eta: 0:00:37    time: 0.0201  data: 0.0172  max mem: 13772
Epoch: [0]  [2700/4572]  eta: 0:00:37    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [0]  [2720/4572]  eta: 0:00:36    time: 0.0200  data: 0.0169  max mem: 13772
Epoch: [0]  [2740/4572]  eta: 0:00:36    time: 0.0201  data: 0.0178  max mem: 13772
Epoch: [0]  [2760/4572]  eta: 0:00:35    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [0]  [2780/4572]  eta: 0:00:35    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [0]  [2800/4572]  eta: 0:00:35    time: 0.0196  data: 0.0167  max mem: 13772
Epoch: [0]  [2820/4572]  eta: 0:00:34    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [0]  [2840/4572]  eta: 0:00:34    time: 0.0199  data: 0.0171  max mem: 13772
Epoch: [0]  [2860/4572]  eta: 0:00:33    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [0]  [2880/4572]  eta: 0:00:33    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [0]  [2900/4572]  eta: 0:00:33    time: 0.0198  data: 0.0175  max mem: 13772
Epoch: [0]  [2920/4572]  eta: 0:00:32    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [0]  [2940/4572]  eta: 0:00:32    time: 0.0196  data: 0.0167  max mem: 13772
Epoch: [0]  [2960/4572]  eta: 0:00:31    time: 0.0195  data: 0.0173  max mem: 13772
Epoch: [0]  [2980/4572]  eta: 0:00:31    time: 0.0198  data: 0.0170  max mem: 13772
Epoch: [0]  [3000/4572]  eta: 0:00:31    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [0]  [3020/4572]  eta: 0:00:30    time: 0.0196  data: 0.0172  max mem: 13772
Epoch: [0]  [3040/4572]  eta: 0:00:30    time: 0.0199  data: 0.0171  max mem: 13772
Epoch: [0]  [3060/4572]  eta: 0:00:29    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [0]  [3080/4572]  eta: 0:00:29    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [0]  [3100/4572]  eta: 0:00:29    time: 0.0199  data: 0.0171  max mem: 13772
Epoch: [0]  [3120/4572]  eta: 0:00:28    time: 0.0198  data: 0.0170  max mem: 13772
Epoch: [0]  [3140/4572]  eta: 0:00:28    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [0]  [3160/4572]  eta: 0:00:27    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [0]  [3180/4572]  eta: 0:00:27    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [0]  [3200/4572]  eta: 0:00:27    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [0]  [3220/4572]  eta: 0:00:26    time: 0.0201  data: 0.0172  max mem: 13772
Epoch: [0]  [3240/4572]  eta: 0:00:26    time: 0.0198  data: 0.0170  max mem: 13772
Epoch: [0]  [3260/4572]  eta: 0:00:25    time: 0.0203  data: 0.0167  max mem: 13772
Epoch: [0]  [3280/4572]  eta: 0:00:25    time: 0.0196  data: 0.0167  max mem: 13772
Epoch: [0]  [3300/4572]  eta: 0:00:25    time: 0.0200  data: 0.0167  max mem: 13772
Epoch: [0]  [3320/4572]  eta: 0:00:24    time: 0.0199  data: 0.0171  max mem: 13772
Epoch: [0]  [3340/4572]  eta: 0:00:24    time: 0.0196  data: 0.0167  max mem: 13772
Epoch: [0]  [3360/4572]  eta: 0:00:23    time: 0.0199  data: 0.0176  max mem: 13772
Epoch: [0]  [3380/4572]  eta: 0:00:23    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [0]  [3400/4572]  eta: 0:00:23    time: 0.0203  data: 0.0174  max mem: 13772
Epoch: [0]  [3420/4572]  eta: 0:00:22    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [0]  [3440/4572]  eta: 0:00:22    time: 0.0196  data: 0.0167  max mem: 13772
Epoch: [0]  [3460/4572]  eta: 0:00:21    time: 0.0199  data: 0.0171  max mem: 13772
Epoch: [0]  [3480/4572]  eta: 0:00:21    time: 0.0197  data: 0.0174  max mem: 13772
Epoch: [0]  [3500/4572]  eta: 0:00:21    time: 0.0196  data: 0.0167  max mem: 13772
Epoch: [0]  [3520/4572]  eta: 0:00:20    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [0]  [3540/4572]  eta: 0:00:20    time: 0.0199  data: 0.0171  max mem: 13772
Epoch: [0]  [3560/4572]  eta: 0:00:20    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [0]  [3580/4572]  eta: 0:00:19    time: 0.0197  data: 0.0170  max mem: 13772
Epoch: [0]  [3600/4572]  eta: 0:00:19    time: 0.0197  data: 0.0175  max mem: 13772
Epoch: [0]  [3620/4572]  eta: 0:00:18    time: 0.0202  data: 0.0180  max mem: 13772
Epoch: [0]  [3640/4572]  eta: 0:00:18    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [0]  [3660/4572]  eta: 0:00:18    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [0]  [3680/4572]  eta: 0:00:17    time: 0.0203  data: 0.0176  max mem: 13772
Epoch: [0]  [3700/4572]  eta: 0:00:17    time: 0.0200  data: 0.0177  max mem: 13772
Epoch: [0]  [3720/4572]  eta: 0:00:16    time: 0.0207  data: 0.0178  max mem: 13772
Epoch: [0]  [3740/4572]  eta: 0:00:16    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [0]  [3760/4572]  eta: 0:00:16    time: 0.0196  data: 0.0167  max mem: 13772
Epoch: [0]  [3780/4572]  eta: 0:00:15    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [0]  [3800/4572]  eta: 0:00:15    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [0]  [3820/4572]  eta: 0:00:14    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [0]  [3840/4572]  eta: 0:00:14    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [0]  [3860/4572]  eta: 0:00:14    time: 0.0199  data: 0.0171  max mem: 13772
Epoch: [0]  [3880/4572]  eta: 0:00:13    time: 0.0198  data: 0.0169  max mem: 13772
Epoch: [0]  [3900/4572]  eta: 0:00:13    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [0]  [3920/4572]  eta: 0:00:12    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [0]  [3940/4572]  eta: 0:00:12    time: 0.0198  data: 0.0170  max mem: 13772
Epoch: [0]  [3960/4572]  eta: 0:00:12    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [0]  [3980/4572]  eta: 0:00:11    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [0]  [4000/4572]  eta: 0:00:11    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [0]  [4020/4572]  eta: 0:00:10    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [0]  [4040/4572]  eta: 0:00:10    time: 0.0199  data: 0.0171  max mem: 13772
Epoch: [0]  [4060/4572]  eta: 0:00:10    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [0]  [4080/4572]  eta: 0:00:09    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [0]  [4100/4572]  eta: 0:00:09    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [0]  [4120/4572]  eta: 0:00:08    time: 0.0199  data: 0.0171  max mem: 13772
Epoch: [0]  [4140/4572]  eta: 0:00:08    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [0]  [4160/4572]  eta: 0:00:08    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [0]  [4180/4572]  eta: 0:00:07    time: 0.0200  data: 0.0168  max mem: 13772
Epoch: [0]  [4200/4572]  eta: 0:00:07    time: 0.0202  data: 0.0175  max mem: 13772
Epoch: [0]  [4220/4572]  eta: 0:00:06    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [0]  [4240/4572]  eta: 0:00:06    time: 0.0198  data: 0.0175  max mem: 13772
Epoch: [0]  [4260/4572]  eta: 0:00:06    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [0]  [4280/4572]  eta: 0:00:05    time: 0.0197  data: 0.0168  max mem: 13772
Epoch: [0]  [4300/4572]  eta: 0:00:05    time: 0.0197  data: 0.0168  max mem: 13772
Epoch: [0]  [4320/4572]  eta: 0:00:04    time: 0.0197  data: 0.0174  max mem: 13772
Epoch: [0]  [4340/4572]  eta: 0:00:04    time: 0.0196  data: 0.0167  max mem: 13772
Epoch: [0]  [4360/4572]  eta: 0:00:04    time: 0.0196  data: 0.0167  max mem: 13772
Epoch: [0]  [4380/4572]  eta: 0:00:03    time: 0.0198  data: 0.0169  max mem: 13772
Epoch: [0]  [4400/4572]  eta: 0:00:03    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [0]  [4420/4572]  eta: 0:00:03    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [0]  [4440/4572]  eta: 0:00:02    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [0]  [4460/4572]  eta: 0:00:02    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [0]  [4480/4572]  eta: 0:00:01    time: 0.0196  data: 0.0172  max mem: 13772
Epoch: [0]  [4500/4572]  eta: 0:00:01    time: 0.0203  data: 0.0175  max mem: 13772
Epoch: [0]  [4520/4572]  eta: 0:00:01    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [0]  [4540/4572]  eta: 0:00:00    time: 0.0204  data: 0.0176  max mem: 13772
Epoch: [0]  [4560/4572]  eta: 0:00:00    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [0]  [4571/4572]  eta: 0:00:00    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [0] Total time: 0:01:30 (0.0198 s / it)
:::MLLOG {"namespace": "", "time_ms": 1715175803379, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 0, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 0}}
:::MLLOG {"namespace": "", "time_ms": 1715175803379, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 202.16484278571627}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 1}}
:::MLLOG {"namespace": "", "time_ms": 1715175803379, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 344, "epoch_num": 1}}
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
Test:  [ 0/13]  eta: 0:00:06  model_time: 0.4601 (0.4601)  evaluator_time: 0.0053 (0.0053)  time: 0.4673  data: 0.0005  max mem: 13772
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
Test:  [12/13]  eta: 0:00:00  model_time: 0.3560 (0.3402)  evaluator_time: 0.0049 (0.0047)  time: 0.3460  data: 0.0008  max mem: 13772
Test: Total time: 0:00:04 (0.3461 s / it)
Averaged stats: model_time: 0.3560 (0.3464)  evaluator_time: 0.0049 (0.0049)
:::MLLOG {"namespace": "", "time_ms": 1715175808747, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 1}}
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
Epoch: [1]  [   0/4571]  eta: 0:01:36    time: 0.0211  data: 0.0009  max mem: 13772
Epoch: [1]  [  20/4571]  eta: 0:01:29    time: 0.0195  data: 0.0173  max mem: 13772
Epoch: [1]  [  40/4571]  eta: 0:01:29    time: 0.0199  data: 0.0173  max mem: 13772
Epoch: [1]  [  60/4571]  eta: 0:01:28    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [1]  [  80/4571]  eta: 0:01:28    time: 0.0196  data: 0.0170  max mem: 13772
Epoch: [1]  [ 100/4571]  eta: 0:01:28    time: 0.0199  data: 0.0178  max mem: 13772
Epoch: [1]  [ 120/4571]  eta: 0:01:27    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [1]  [ 140/4571]  eta: 0:01:27    time: 0.0203  data: 0.0168  max mem: 13772
Epoch: [1]  [ 160/4571]  eta: 0:01:27    time: 0.0206  data: 0.0178  max mem: 13772
Epoch: [1]  [ 180/4571]  eta: 0:01:27    time: 0.0199  data: 0.0170  max mem: 13772
Epoch: [1]  [ 200/4571]  eta: 0:01:26    time: 0.0196  data: 0.0167  max mem: 13772
Epoch: [1]  [ 220/4571]  eta: 0:01:26    time: 0.0199  data: 0.0175  max mem: 13772
Epoch: [1]  [ 240/4571]  eta: 0:01:26    time: 0.0199  data: 0.0171  max mem: 13772
Epoch: [1]  [ 260/4571]  eta: 0:01:25    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [1]  [ 280/4571]  eta: 0:01:25    time: 0.0198  data: 0.0169  max mem: 13772
Epoch: [1]  [ 300/4571]  eta: 0:01:24    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [1]  [ 320/4571]  eta: 0:01:24    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [1]  [ 340/4571]  eta: 0:01:23    time: 0.0201  data: 0.0173  max mem: 13772
Epoch: [1]  [ 360/4571]  eta: 0:01:23    time: 0.0198  data: 0.0169  max mem: 13772
Epoch: [1]  [ 380/4571]  eta: 0:01:23    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [1]  [ 400/4571]  eta: 0:01:22    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [1]  [ 420/4571]  eta: 0:01:22    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [1]  [ 440/4571]  eta: 0:01:21    time: 0.0197  data: 0.0168  max mem: 13772
Epoch: [1]  [ 460/4571]  eta: 0:01:21    time: 0.0196  data: 0.0171  max mem: 13772
Epoch: [1]  [ 480/4571]  eta: 0:01:20    time: 0.0196  data: 0.0170  max mem: 13772
Epoch: [1]  [ 500/4571]  eta: 0:01:20    time: 0.0196  data: 0.0171  max mem: 13772
Epoch: [1]  [ 520/4571]  eta: 0:01:20    time: 0.0204  data: 0.0171  max mem: 13772
Epoch: [1]  [ 540/4571]  eta: 0:01:19    time: 0.0198  data: 0.0167  max mem: 13772
Epoch: [1]  [ 560/4571]  eta: 0:01:19    time: 0.0197  data: 0.0168  max mem: 13772
Epoch: [1]  [ 580/4571]  eta: 0:01:18    time: 0.0196  data: 0.0167  max mem: 13772
:::MLLOG {"namespace": "", "time_ms": 1715175820500, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.19981625947880954, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 437, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1715175820500, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 438, "epoch_num": 1}}
Epoch: [1]  [ 600/4571]  eta: 0:01:18    time: 0.0201  data: 0.0173  max mem: 13772
Epoch: [1]  [ 620/4571]  eta: 0:01:18    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [1]  [ 640/4571]  eta: 0:01:17    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [1]  [ 660/4571]  eta: 0:01:17    time: 0.0200  data: 0.0172  max mem: 13772
Epoch: [1]  [ 680/4571]  eta: 0:01:16    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [1]  [ 700/4571]  eta: 0:01:16    time: 0.0197  data: 0.0168  max mem: 13772
Epoch: [1]  [ 720/4571]  eta: 0:01:16    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [1]  [ 740/4571]  eta: 0:01:15    time: 0.0199  data: 0.0170  max mem: 13772
Epoch: [1]  [ 760/4571]  eta: 0:01:15    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [1]  [ 780/4571]  eta: 0:01:14    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [1]  [ 800/4571]  eta: 0:01:14    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [1]  [ 820/4571]  eta: 0:01:14    time: 0.0198  data: 0.0170  max mem: 13772
Epoch: [1]  [ 840/4571]  eta: 0:01:13    time: 0.0203  data: 0.0176  max mem: 13772
Epoch: [1]  [ 860/4571]  eta: 0:01:13    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [1]  [ 880/4571]  eta: 0:01:12    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [1]  [ 900/4571]  eta: 0:01:12    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [1]  [ 920/4571]  eta: 0:01:12    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [1]  [ 940/4571]  eta: 0:01:11    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [1]  [ 960/4571]  eta: 0:01:11    time: 0.0198  data: 0.0170  max mem: 13772
Epoch: [1]  [ 980/4571]  eta: 0:01:10    time: 0.0198  data: 0.0167  max mem: 13772
Epoch: [1]  [1000/4571]  eta: 0:01:10    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [1]  [1020/4571]  eta: 0:01:10    time: 0.0198  data: 0.0169  max mem: 13772
Epoch: [1]  [1040/4571]  eta: 0:01:09    time: 0.0196  data: 0.0167  max mem: 13772
Epoch: [1]  [1060/4571]  eta: 0:01:09    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [1]  [1080/4571]  eta: 0:01:08    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [1]  [1100/4571]  eta: 0:01:08    time: 0.0197  data: 0.0174  max mem: 13772
Epoch: [1]  [1120/4571]  eta: 0:01:08    time: 0.0195  data: 0.0173  max mem: 13772
Epoch: [1]  [1140/4571]  eta: 0:01:07    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [1]  [1160/4571]  eta: 0:01:07    time: 0.0196  data: 0.0165  max mem: 13772
Epoch: [1]  [1180/4571]  eta: 0:01:06    time: 0.0201  data: 0.0177  max mem: 13772
Epoch: [1]  [1200/4571]  eta: 0:01:06    time: 0.0196  data: 0.0167  max mem: 13772
Epoch: [1]  [1220/4571]  eta: 0:01:06    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [1]  [1240/4571]  eta: 0:01:05    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [1]  [1260/4571]  eta: 0:01:05    time: 0.0199  data: 0.0176  max mem: 13772
Epoch: [1]  [1280/4571]  eta: 0:01:04    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [1]  [1300/4571]  eta: 0:01:04    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [1]  [1320/4571]  eta: 0:01:04    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [1]  [1340/4571]  eta: 0:01:03    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [1]  [1360/4571]  eta: 0:01:03    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [1]  [1380/4571]  eta: 0:01:02    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [1]  [1400/4571]  eta: 0:01:02    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [1]  [1420/4571]  eta: 0:01:02    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [1]  [1440/4571]  eta: 0:01:01    time: 0.0199  data: 0.0170  max mem: 13772
Epoch: [1]  [1460/4571]  eta: 0:01:01    time: 0.0203  data: 0.0175  max mem: 13772
Epoch: [1]  [1480/4571]  eta: 0:01:00    time: 0.0195  data: 0.0165  max mem: 13772
Epoch: [1]  [1500/4571]  eta: 0:01:00    time: 0.0198  data: 0.0175  max mem: 13772
Epoch: [1]  [1520/4571]  eta: 0:01:00    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [1]  [1540/4571]  eta: 0:00:59    time: 0.0196  data: 0.0174  max mem: 13772
Epoch: [1]  [1560/4571]  eta: 0:00:59    time: 0.0196  data: 0.0172  max mem: 13772
Epoch: [1]  [1580/4571]  eta: 0:00:58    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [1]  [1600/4571]  eta: 0:00:58    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [1]  [1620/4571]  eta: 0:00:58    time: 0.0196  data: 0.0172  max mem: 13772
Epoch: [1]  [1640/4571]  eta: 0:00:57    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [1]  [1660/4571]  eta: 0:00:57    time: 0.0200  data: 0.0172  max mem: 13772
Epoch: [1]  [1680/4571]  eta: 0:00:57    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [1]  [1700/4571]  eta: 0:00:56    time: 0.0197  data: 0.0168  max mem: 13772
Epoch: [1]  [1720/4571]  eta: 0:00:56    time: 0.0198  data: 0.0170  max mem: 13772
Epoch: [1]  [1740/4571]  eta: 0:00:55    time: 0.0199  data: 0.0171  max mem: 13772
Epoch: [1]  [1760/4571]  eta: 0:00:55    time: 0.0196  data: 0.0167  max mem: 13772
Epoch: [1]  [1780/4571]  eta: 0:00:55    time: 0.0196  data: 0.0172  max mem: 13772
Epoch: [1]  [1800/4571]  eta: 0:00:54    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [1]  [1820/4571]  eta: 0:00:54    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [1]  [1840/4571]  eta: 0:00:53    time: 0.0196  data: 0.0165  max mem: 13772
Epoch: [1]  [1860/4571]  eta: 0:00:53    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [1]  [1880/4571]  eta: 0:00:53    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [1]  [1900/4571]  eta: 0:00:52    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [1]  [1920/4571]  eta: 0:00:52    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [1]  [1940/4571]  eta: 0:00:51    time: 0.0199  data: 0.0171  max mem: 13772
Epoch: [1]  [1960/4571]  eta: 0:00:51    time: 0.0198  data: 0.0169  max mem: 13772
Epoch: [1]  [1980/4571]  eta: 0:00:51    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [1]  [2000/4571]  eta: 0:00:50    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [1]  [2020/4571]  eta: 0:00:50    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [1]  [2040/4571]  eta: 0:00:49    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [1]  [2060/4571]  eta: 0:00:49    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [1]  [2080/4571]  eta: 0:00:49    time: 0.0196  data: 0.0174  max mem: 13772
Epoch: [1]  [2100/4571]  eta: 0:00:48    time: 0.0198  data: 0.0176  max mem: 13772
Epoch: [1]  [2120/4571]  eta: 0:00:48    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [1]  [2140/4571]  eta: 0:00:47    time: 0.0199  data: 0.0168  max mem: 13772
Epoch: [1]  [2160/4571]  eta: 0:00:47    time: 0.0196  data: 0.0174  max mem: 13772
Epoch: [1]  [2180/4571]  eta: 0:00:47    time: 0.0202  data: 0.0170  max mem: 13772
Epoch: [1]  [2200/4571]  eta: 0:00:46    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [1]  [2220/4571]  eta: 0:00:46    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [1]  [2240/4571]  eta: 0:00:45    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [1]  [2260/4571]  eta: 0:00:45    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [1]  [2280/4571]  eta: 0:00:45    time: 0.0196  data: 0.0174  max mem: 13772
Epoch: [1]  [2300/4571]  eta: 0:00:44    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [1]  [2320/4571]  eta: 0:00:44    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [1]  [2340/4571]  eta: 0:00:43    time: 0.0196  data: 0.0174  max mem: 13772
Epoch: [1]  [2360/4571]  eta: 0:00:43    time: 0.0199  data: 0.0170  max mem: 13772
Epoch: [1]  [2380/4571]  eta: 0:00:43    time: 0.0196  data: 0.0174  max mem: 13772
Epoch: [1]  [2400/4571]  eta: 0:00:42    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [1]  [2420/4571]  eta: 0:00:42    time: 0.0196  data: 0.0174  max mem: 13772
Epoch: [1]  [2440/4571]  eta: 0:00:41    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [1]  [2460/4571]  eta: 0:00:41    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [1]  [2480/4571]  eta: 0:00:41    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [1]  [2500/4571]  eta: 0:00:40    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [1]  [2520/4571]  eta: 0:00:40    time: 0.0195  data: 0.0173  max mem: 13772
Epoch: [1]  [2540/4571]  eta: 0:00:40    time: 0.0199  data: 0.0171  max mem: 13772
Epoch: [1]  [2560/4571]  eta: 0:00:39    time: 0.0196  data: 0.0167  max mem: 13772
Epoch: [1]  [2580/4571]  eta: 0:00:39    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [1]  [2600/4571]  eta: 0:00:38    time: 0.0199  data: 0.0171  max mem: 13772
Epoch: [1]  [2620/4571]  eta: 0:00:38    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [1]  [2640/4571]  eta: 0:00:38    time: 0.0204  data: 0.0176  max mem: 13772
Epoch: [1]  [2660/4571]  eta: 0:00:37    time: 0.0198  data: 0.0170  max mem: 13772
Epoch: [1]  [2680/4571]  eta: 0:00:37    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [1]  [2700/4571]  eta: 0:00:36    time: 0.0203  data: 0.0176  max mem: 13772
Epoch: [1]  [2720/4571]  eta: 0:00:36    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [1]  [2740/4571]  eta: 0:00:36    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [1]  [2760/4571]  eta: 0:00:35    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [1]  [2780/4571]  eta: 0:00:35    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [1]  [2800/4571]  eta: 0:00:34    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [1]  [2820/4571]  eta: 0:00:34    time: 0.0202  data: 0.0174  max mem: 13772
Epoch: [1]  [2840/4571]  eta: 0:00:34    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [1]  [2860/4571]  eta: 0:00:33    time: 0.0204  data: 0.0173  max mem: 13772
Epoch: [1]  [2880/4571]  eta: 0:00:33    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [1]  [2900/4571]  eta: 0:00:32    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [1]  [2920/4571]  eta: 0:00:32    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [1]  [2940/4571]  eta: 0:00:32    time: 0.0199  data: 0.0172  max mem: 13772
Epoch: [1]  [2960/4571]  eta: 0:00:31    time: 0.0199  data: 0.0176  max mem: 13772
Epoch: [1]  [2980/4571]  eta: 0:00:31    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [1]  [3000/4571]  eta: 0:00:30    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [1]  [3020/4571]  eta: 0:00:30    time: 0.0197  data: 0.0170  max mem: 13772
Epoch: [1]  [3040/4571]  eta: 0:00:30    time: 0.0204  data: 0.0181  max mem: 13772
Epoch: [1]  [3060/4571]  eta: 0:00:29    time: 0.0198  data: 0.0170  max mem: 13772
Epoch: [1]  [3080/4571]  eta: 0:00:29    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [1]  [3100/4571]  eta: 0:00:28    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [1]  [3120/4571]  eta: 0:00:28    time: 0.0206  data: 0.0184  max mem: 13772
Epoch: [1]  [3140/4571]  eta: 0:00:28    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [1]  [3160/4571]  eta: 0:00:27    time: 0.0199  data: 0.0170  max mem: 13772
Epoch: [1]  [3180/4571]  eta: 0:00:27    time: 0.0196  data: 0.0167  max mem: 13772
Epoch: [1]  [3200/4571]  eta: 0:00:27    time: 0.0199  data: 0.0171  max mem: 13772
Epoch: [1]  [3220/4571]  eta: 0:00:26    time: 0.0197  data: 0.0168  max mem: 13772
Epoch: [1]  [3240/4571]  eta: 0:00:26    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [1]  [3260/4571]  eta: 0:00:25    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [1]  [3280/4571]  eta: 0:00:25    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [1]  [3300/4571]  eta: 0:00:25    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [1]  [3320/4571]  eta: 0:00:24    time: 0.0199  data: 0.0178  max mem: 13772
Epoch: [1]  [3340/4571]  eta: 0:00:24    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [1]  [3360/4571]  eta: 0:00:23    time: 0.0199  data: 0.0172  max mem: 13772
Epoch: [1]  [3380/4571]  eta: 0:00:23    time: 0.0201  data: 0.0172  max mem: 13772
Epoch: [1]  [3400/4571]  eta: 0:00:23    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [1]  [3420/4571]  eta: 0:00:22    time: 0.0200  data: 0.0173  max mem: 13772
Epoch: [1]  [3440/4571]  eta: 0:00:22    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [1]  [3460/4571]  eta: 0:00:21    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [1]  [3480/4571]  eta: 0:00:21    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [1]  [3500/4571]  eta: 0:00:21    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [1]  [3520/4571]  eta: 0:00:20    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [1]  [3540/4571]  eta: 0:00:20    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [1]  [3560/4571]  eta: 0:00:19    time: 0.0201  data: 0.0173  max mem: 13772
Epoch: [1]  [3580/4571]  eta: 0:00:19    time: 0.0198  data: 0.0170  max mem: 13772
Epoch: [1]  [3600/4571]  eta: 0:00:19    time: 0.0197  data: 0.0170  max mem: 13772
Epoch: [1]  [3620/4571]  eta: 0:00:18    time: 0.0197  data: 0.0168  max mem: 13772
Epoch: [1]  [3640/4571]  eta: 0:00:18    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [1]  [3660/4571]  eta: 0:00:17    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [1]  [3680/4571]  eta: 0:00:17    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [1]  [3700/4571]  eta: 0:00:17    time: 0.0196  data: 0.0174  max mem: 13772
Epoch: [1]  [3720/4571]  eta: 0:00:16    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [1]  [3740/4571]  eta: 0:00:16    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [1]  [3760/4571]  eta: 0:00:15    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [1]  [3780/4571]  eta: 0:00:15    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [1]  [3800/4571]  eta: 0:00:15    time: 0.0197  data: 0.0170  max mem: 13772
Epoch: [1]  [3820/4571]  eta: 0:00:14    time: 0.0199  data: 0.0171  max mem: 13772
Epoch: [1]  [3840/4571]  eta: 0:00:14    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [1]  [3860/4571]  eta: 0:00:14    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [1]  [3880/4571]  eta: 0:00:13    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [1]  [3900/4571]  eta: 0:00:13    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [1]  [3920/4571]  eta: 0:00:12    time: 0.0199  data: 0.0172  max mem: 13772
Epoch: [1]  [3940/4571]  eta: 0:00:12    time: 0.0196  data: 0.0167  max mem: 13772
Epoch: [1]  [3960/4571]  eta: 0:00:12    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [1]  [3980/4571]  eta: 0:00:11    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [1]  [4000/4571]  eta: 0:00:11    time: 0.0198  data: 0.0175  max mem: 13772
Epoch: [1]  [4020/4571]  eta: 0:00:10    time: 0.0195  data: 0.0174  max mem: 13772
Epoch: [1]  [4040/4571]  eta: 0:00:10    time: 0.0198  data: 0.0170  max mem: 13772
Epoch: [1]  [4060/4571]  eta: 0:00:10    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [1]  [4080/4571]  eta: 0:00:09    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [1]  [4100/4571]  eta: 0:00:09    time: 0.0203  data: 0.0176  max mem: 13772
Epoch: [1]  [4120/4571]  eta: 0:00:08    time: 0.0196  data: 0.0165  max mem: 13772
Epoch: [1]  [4140/4571]  eta: 0:00:08    time: 0.0202  data: 0.0173  max mem: 13772
Epoch: [1]  [4160/4571]  eta: 0:00:08    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [1]  [4180/4571]  eta: 0:00:07    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [1]  [4200/4571]  eta: 0:00:07    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [1]  [4220/4571]  eta: 0:00:06    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [1]  [4240/4571]  eta: 0:00:06    time: 0.0200  data: 0.0172  max mem: 13772
Epoch: [1]  [4260/4571]  eta: 0:00:06    time: 0.0201  data: 0.0173  max mem: 13772
Epoch: [1]  [4280/4571]  eta: 0:00:05    time: 0.0200  data: 0.0172  max mem: 13772
Epoch: [1]  [4300/4571]  eta: 0:00:05    time: 0.0199  data: 0.0176  max mem: 13772
Epoch: [1]  [4320/4571]  eta: 0:00:04    time: 0.0195  data: 0.0173  max mem: 13772
Epoch: [1]  [4340/4571]  eta: 0:00:04    time: 0.0196  data: 0.0174  max mem: 13772
Epoch: [1]  [4360/4571]  eta: 0:00:04    time: 0.0196  data: 0.0174  max mem: 13772
Epoch: [1]  [4380/4571]  eta: 0:00:03    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [1]  [4400/4571]  eta: 0:00:03    time: 0.0198  data: 0.0171  max mem: 13772
Epoch: [1]  [4420/4571]  eta: 0:00:02    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [1]  [4440/4571]  eta: 0:00:02    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [1]  [4460/4571]  eta: 0:00:02    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [1]  [4480/4571]  eta: 0:00:01    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [1]  [4500/4571]  eta: 0:00:01    time: 0.0195  data: 0.0173  max mem: 13772
Epoch: [1]  [4520/4571]  eta: 0:00:01    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [1]  [4540/4571]  eta: 0:00:00    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [1]  [4560/4571]  eta: 0:00:00    time: 0.0198  data: 0.0170  max mem: 13772
Epoch: [1]  [4570/4571]  eta: 0:00:00    time: 0.0202  data: 0.0174  max mem: 13772
Epoch: [1] Total time: 0:01:30 (0.0197 s / it)
:::MLLOG {"namespace": "", "time_ms": 1715175899004, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1715175899004, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 202.7208457506656}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 2}}
:::MLLOG {"namespace": "", "time_ms": 1715175899004, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 344, "epoch_num": 2}}
Test:  [ 0/13]  eta: 0:00:03  model_time: 0.2756 (0.2756)  evaluator_time: 0.0031 (0.0031)  time: 0.2797  data: 0.0009  max mem: 13772
Test:  [12/13]  eta: 0:00:00  model_time: 0.2756 (0.2575)  evaluator_time: 0.0033 (0.0033)  time: 0.2618  data: 0.0008  max mem: 13772
Test: Total time: 0:00:03 (0.2618 s / it)
Averaged stats: model_time: 0.2756 (0.2637)  evaluator_time: 0.0033 (0.0037)
:::MLLOG {"namespace": "", "time_ms": 1715175903023, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 2}}
Epoch: [2]  [   0/4572]  eta: 0:01:34    time: 0.0207  data: 0.0009  max mem: 13772
Epoch: [2]  [  20/4572]  eta: 0:01:29    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [2]  [  40/4572]  eta: 0:01:28    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [2]  [  60/4572]  eta: 0:01:28    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [2]  [  80/4572]  eta: 0:01:27    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [2]  [ 100/4572]  eta: 0:01:27    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [2]  [ 120/4572]  eta: 0:01:27    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [2]  [ 140/4572]  eta: 0:01:26    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [2]  [ 160/4572]  eta: 0:01:26    time: 0.0195  data: 0.0164  max mem: 13772
Epoch: [2]  [ 180/4572]  eta: 0:01:25    time: 0.0195  data: 0.0170  max mem: 13772
Epoch: [2]  [ 200/4572]  eta: 0:01:25    time: 0.0196  data: 0.0171  max mem: 13772
Epoch: [2]  [ 220/4572]  eta: 0:01:25    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [2]  [ 240/4572]  eta: 0:01:24    time: 0.0196  data: 0.0174  max mem: 13772
Epoch: [2]  [ 260/4572]  eta: 0:01:24    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [2]  [ 280/4572]  eta: 0:01:23    time: 0.0196  data: 0.0168  max mem: 13772
:::MLLOG {"namespace": "", "time_ms": 1715175908625, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.2814369623919742, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 437, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1715175908626, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 438, "epoch_num": 2}}
Epoch: [2]  [ 300/4572]  eta: 0:01:23    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [2]  [ 320/4572]  eta: 0:01:23    time: 0.0199  data: 0.0177  max mem: 13772
Epoch: [2]  [ 340/4572]  eta: 0:01:22    time: 0.0197  data: 0.0170  max mem: 13772
Epoch: [2]  [ 360/4572]  eta: 0:01:22    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [2]  [ 380/4572]  eta: 0:01:22    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [2]  [ 400/4572]  eta: 0:01:21    time: 0.0199  data: 0.0176  max mem: 13772
Epoch: [2]  [ 420/4572]  eta: 0:01:21    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [2]  [ 440/4572]  eta: 0:01:20    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [2]  [ 460/4572]  eta: 0:01:20    time: 0.0199  data: 0.0172  max mem: 13772
Epoch: [2]  [ 480/4572]  eta: 0:01:20    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [2]  [ 500/4572]  eta: 0:01:19    time: 0.0198  data: 0.0171  max mem: 13772
Epoch: [2]  [ 520/4572]  eta: 0:01:19    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [2]  [ 540/4572]  eta: 0:01:19    time: 0.0205  data: 0.0177  max mem: 13772
Epoch: [2]  [ 560/4572]  eta: 0:01:18    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [2]  [ 580/4572]  eta: 0:01:18    time: 0.0199  data: 0.0177  max mem: 13772
Epoch: [2]  [ 600/4572]  eta: 0:01:18    time: 0.0199  data: 0.0171  max mem: 13772
Epoch: [2]  [ 620/4572]  eta: 0:01:17    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [2]  [ 640/4572]  eta: 0:01:17    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [2]  [ 660/4572]  eta: 0:01:16    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [2]  [ 680/4572]  eta: 0:01:16    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [2]  [ 700/4572]  eta: 0:01:16    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [2]  [ 720/4572]  eta: 0:01:15    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [2]  [ 740/4572]  eta: 0:01:15    time: 0.0195  data: 0.0173  max mem: 13772
Epoch: [2]  [ 760/4572]  eta: 0:01:14    time: 0.0206  data: 0.0185  max mem: 13772
Epoch: [2]  [ 780/4572]  eta: 0:01:14    time: 0.0199  data: 0.0172  max mem: 13772
Epoch: [2]  [ 800/4572]  eta: 0:01:14    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [2]  [ 820/4572]  eta: 0:01:13    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [2]  [ 840/4572]  eta: 0:01:13    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [2]  [ 860/4572]  eta: 0:01:12    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [2]  [ 880/4572]  eta: 0:01:12    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [2]  [ 900/4572]  eta: 0:01:12    time: 0.0203  data: 0.0175  max mem: 13772
Epoch: [2]  [ 920/4572]  eta: 0:01:11    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [2]  [ 940/4572]  eta: 0:01:11    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [2]  [ 960/4572]  eta: 0:01:11    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [2]  [ 980/4572]  eta: 0:01:10    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [2]  [1000/4572]  eta: 0:01:10    time: 0.0205  data: 0.0174  max mem: 13772
Epoch: [2]  [1020/4572]  eta: 0:01:09    time: 0.0198  data: 0.0177  max mem: 13772
Epoch: [2]  [1040/4572]  eta: 0:01:09    time: 0.0199  data: 0.0170  max mem: 13772
Epoch: [2]  [1060/4572]  eta: 0:01:09    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [2]  [1080/4572]  eta: 0:01:08    time: 0.0201  data: 0.0173  max mem: 13772
Epoch: [2]  [1100/4572]  eta: 0:01:08    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [2]  [1120/4572]  eta: 0:01:07    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [2]  [1140/4572]  eta: 0:01:07    time: 0.0199  data: 0.0171  max mem: 13772
Epoch: [2]  [1160/4572]  eta: 0:01:07    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [2]  [1180/4572]  eta: 0:01:06    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [2]  [1200/4572]  eta: 0:01:06    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [2]  [1220/4572]  eta: 0:01:05    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [2]  [1240/4572]  eta: 0:01:05    time: 0.0199  data: 0.0171  max mem: 13772
Epoch: [2]  [1260/4572]  eta: 0:01:05    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [2]  [1280/4572]  eta: 0:01:04    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [2]  [1300/4572]  eta: 0:01:04    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [2]  [1320/4572]  eta: 0:01:04    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [2]  [1340/4572]  eta: 0:01:03    time: 0.0202  data: 0.0169  max mem: 13772
Epoch: [2]  [1360/4572]  eta: 0:01:03    time: 0.0199  data: 0.0171  max mem: 13772
Epoch: [2]  [1380/4572]  eta: 0:01:02    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [2]  [1400/4572]  eta: 0:01:02    time: 0.0197  data: 0.0170  max mem: 13772
Epoch: [2]  [1420/4572]  eta: 0:01:02    time: 0.0198  data: 0.0171  max mem: 13772
Epoch: [2]  [1440/4572]  eta: 0:01:01    time: 0.0197  data: 0.0176  max mem: 13772
Epoch: [2]  [1460/4572]  eta: 0:01:01    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [2]  [1480/4572]  eta: 0:01:00    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [2]  [1500/4572]  eta: 0:01:00    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [2]  [1520/4572]  eta: 0:01:00    time: 0.0203  data: 0.0176  max mem: 13772
Epoch: [2]  [1540/4572]  eta: 0:00:59    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [2]  [1560/4572]  eta: 0:00:59    time: 0.0195  data: 0.0173  max mem: 13772
Epoch: [2]  [1580/4572]  eta: 0:00:58    time: 0.0205  data: 0.0177  max mem: 13772
Epoch: [2]  [1600/4572]  eta: 0:00:58    time: 0.0196  data: 0.0174  max mem: 13772
Epoch: [2]  [1620/4572]  eta: 0:00:58    time: 0.0199  data: 0.0168  max mem: 13772
Epoch: [2]  [1640/4572]  eta: 0:00:57    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [2]  [1660/4572]  eta: 0:00:57    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [2]  [1680/4572]  eta: 0:00:56    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [2]  [1700/4572]  eta: 0:00:56    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [2]  [1720/4572]  eta: 0:00:56    time: 0.0198  data: 0.0170  max mem: 13772
Epoch: [2]  [1740/4572]  eta: 0:00:55    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [2]  [1760/4572]  eta: 0:00:55    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [2]  [1780/4572]  eta: 0:00:54    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [2]  [1800/4572]  eta: 0:00:54    time: 0.0195  data: 0.0173  max mem: 13772
Epoch: [2]  [1820/4572]  eta: 0:00:54    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [2]  [1840/4572]  eta: 0:00:53    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [2]  [1860/4572]  eta: 0:00:53    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [2]  [1880/4572]  eta: 0:00:52    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [2]  [1900/4572]  eta: 0:00:52    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [2]  [1920/4572]  eta: 0:00:52    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [2]  [1940/4572]  eta: 0:00:51    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [2]  [1960/4572]  eta: 0:00:51    time: 0.0200  data: 0.0170  max mem: 13772
Epoch: [2]  [1980/4572]  eta: 0:00:51    time: 0.0207  data: 0.0180  max mem: 13772
Epoch: [2]  [2000/4572]  eta: 0:00:50    time: 0.0198  data: 0.0171  max mem: 13772
Epoch: [2]  [2020/4572]  eta: 0:00:50    time: 0.0197  data: 0.0175  max mem: 13772
Epoch: [2]  [2040/4572]  eta: 0:00:49    time: 0.0195  data: 0.0173  max mem: 13772
Epoch: [2]  [2060/4572]  eta: 0:00:49    time: 0.0197  data: 0.0170  max mem: 13772
Epoch: [2]  [2080/4572]  eta: 0:00:49    time: 0.0202  data: 0.0175  max mem: 13772
Epoch: [2]  [2100/4572]  eta: 0:00:48    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [2]  [2120/4572]  eta: 0:00:48    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [2]  [2140/4572]  eta: 0:00:47    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [2]  [2160/4572]  eta: 0:00:47    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [2]  [2180/4572]  eta: 0:00:47    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [2]  [2200/4572]  eta: 0:00:46    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [2]  [2220/4572]  eta: 0:00:46    time: 0.0197  data: 0.0170  max mem: 13772
Epoch: [2]  [2240/4572]  eta: 0:00:45    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [2]  [2260/4572]  eta: 0:00:45    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [2]  [2280/4572]  eta: 0:00:45    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [2]  [2300/4572]  eta: 0:00:44    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [2]  [2320/4572]  eta: 0:00:44    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [2]  [2340/4572]  eta: 0:00:44    time: 0.0231  data: 0.0204  max mem: 13772
Epoch: [2]  [2360/4572]  eta: 0:00:43    time: 0.0201  data: 0.0174  max mem: 13772
Epoch: [2]  [2380/4572]  eta: 0:00:43    time: 0.0201  data: 0.0173  max mem: 13772
Epoch: [2]  [2400/4572]  eta: 0:00:42    time: 0.0195  data: 0.0173  max mem: 13772
Epoch: [2]  [2420/4572]  eta: 0:00:42    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [2]  [2440/4572]  eta: 0:00:42    time: 0.0201  data: 0.0173  max mem: 13772
Epoch: [2]  [2460/4572]  eta: 0:00:41    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [2]  [2480/4572]  eta: 0:00:41    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [2]  [2500/4572]  eta: 0:00:40    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [2]  [2520/4572]  eta: 0:00:40    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [2]  [2540/4572]  eta: 0:00:40    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [2]  [2560/4572]  eta: 0:00:39    time: 0.0200  data: 0.0173  max mem: 13772
Epoch: [2]  [2580/4572]  eta: 0:00:39    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [2]  [2600/4572]  eta: 0:00:38    time: 0.0197  data: 0.0170  max mem: 13772
Epoch: [2]  [2620/4572]  eta: 0:00:38    time: 0.0199  data: 0.0172  max mem: 13772
Epoch: [2]  [2640/4572]  eta: 0:00:38    time: 0.0198  data: 0.0170  max mem: 13772
Epoch: [2]  [2660/4572]  eta: 0:00:37    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [2]  [2680/4572]  eta: 0:00:37    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [2]  [2700/4572]  eta: 0:00:36    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [2]  [2720/4572]  eta: 0:00:36    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [2]  [2740/4572]  eta: 0:00:36    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [2]  [2760/4572]  eta: 0:00:35    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [2]  [2780/4572]  eta: 0:00:35    time: 0.0195  data: 0.0173  max mem: 13772
Epoch: [2]  [2800/4572]  eta: 0:00:34    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [2]  [2820/4572]  eta: 0:00:34    time: 0.0200  data: 0.0171  max mem: 13772
Epoch: [2]  [2840/4572]  eta: 0:00:34    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [2]  [2860/4572]  eta: 0:00:33    time: 0.0202  data: 0.0175  max mem: 13772
Epoch: [2]  [2880/4572]  eta: 0:00:33    time: 0.0236  data: 0.0208  max mem: 13772
Epoch: [2]  [2900/4572]  eta: 0:00:33    time: 0.0198  data: 0.0171  max mem: 13772
Epoch: [2]  [2920/4572]  eta: 0:00:32    time: 0.0200  data: 0.0172  max mem: 13772
Epoch: [2]  [2940/4572]  eta: 0:00:32    time: 0.0197  data: 0.0170  max mem: 13772
Epoch: [2]  [2960/4572]  eta: 0:00:31    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [2]  [2980/4572]  eta: 0:00:31    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [2]  [3000/4572]  eta: 0:00:31    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [2]  [3020/4572]  eta: 0:00:30    time: 0.0199  data: 0.0168  max mem: 13772
Epoch: [2]  [3040/4572]  eta: 0:00:30    time: 0.0197  data: 0.0168  max mem: 13772
Epoch: [2]  [3060/4572]  eta: 0:00:29    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [2]  [3080/4572]  eta: 0:00:29    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [2]  [3100/4572]  eta: 0:00:29    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [2]  [3120/4572]  eta: 0:00:28    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [2]  [3140/4572]  eta: 0:00:28    time: 0.0231  data: 0.0203  max mem: 13772
Epoch: [2]  [3160/4572]  eta: 0:00:27    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [2]  [3180/4572]  eta: 0:00:27    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [2]  [3200/4572]  eta: 0:00:27    time: 0.0203  data: 0.0175  max mem: 13772
Epoch: [2]  [3220/4572]  eta: 0:00:26    time: 0.0207  data: 0.0180  max mem: 13772
Epoch: [2]  [3240/4572]  eta: 0:00:26    time: 0.0196  data: 0.0167  max mem: 13772
Epoch: [2]  [3260/4572]  eta: 0:00:25    time: 0.0245  data: 0.0212  max mem: 13772
Epoch: [2]  [3280/4572]  eta: 0:00:25    time: 0.0197  data: 0.0170  max mem: 13772
Epoch: [2]  [3300/4572]  eta: 0:00:25    time: 0.0197  data: 0.0175  max mem: 13772
Epoch: [2]  [3320/4572]  eta: 0:00:24    time: 0.0197  data: 0.0170  max mem: 13772
Epoch: [2]  [3340/4572]  eta: 0:00:24    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [2]  [3360/4572]  eta: 0:00:23    time: 0.0203  data: 0.0175  max mem: 13772
Epoch: [2]  [3380/4572]  eta: 0:00:23    time: 0.0199  data: 0.0171  max mem: 13772
Epoch: [2]  [3400/4572]  eta: 0:00:23    time: 0.0195  data: 0.0173  max mem: 13772
Epoch: [2]  [3420/4572]  eta: 0:00:22    time: 0.0200  data: 0.0172  max mem: 13772
Epoch: [2]  [3440/4572]  eta: 0:00:22    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [2]  [3460/4572]  eta: 0:00:22    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [2]  [3480/4572]  eta: 0:00:21    time: 0.0195  data: 0.0173  max mem: 13772
Epoch: [2]  [3500/4572]  eta: 0:00:21    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [2]  [3520/4572]  eta: 0:00:20    time: 0.0198  data: 0.0170  max mem: 13772
Epoch: [2]  [3540/4572]  eta: 0:00:20    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [2]  [3560/4572]  eta: 0:00:20    time: 0.0198  data: 0.0171  max mem: 13772
Epoch: [2]  [3580/4572]  eta: 0:00:19    time: 0.0196  data: 0.0167  max mem: 13772
Epoch: [2]  [3600/4572]  eta: 0:00:19    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [2]  [3620/4572]  eta: 0:00:18    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [2]  [3640/4572]  eta: 0:00:18    time: 0.0225  data: 0.0197  max mem: 13772
Epoch: [2]  [3660/4572]  eta: 0:00:18    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [2]  [3680/4572]  eta: 0:00:17    time: 0.0227  data: 0.0200  max mem: 13772
Epoch: [2]  [3700/4572]  eta: 0:00:17    time: 0.0199  data: 0.0172  max mem: 13772
Epoch: [2]  [3720/4572]  eta: 0:00:16    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [2]  [3740/4572]  eta: 0:00:16    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [2]  [3760/4572]  eta: 0:00:16    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [2]  [3780/4572]  eta: 0:00:15    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [2]  [3800/4572]  eta: 0:00:15    time: 0.0199  data: 0.0176  max mem: 13772
Epoch: [2]  [3820/4572]  eta: 0:00:14    time: 0.0228  data: 0.0200  max mem: 13772
Epoch: [2]  [3840/4572]  eta: 0:00:14    time: 0.0197  data: 0.0174  max mem: 13772
Epoch: [2]  [3860/4572]  eta: 0:00:14    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [2]  [3880/4572]  eta: 0:00:13    time: 0.0199  data: 0.0171  max mem: 13772
Epoch: [2]  [3900/4572]  eta: 0:00:13    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [2]  [3920/4572]  eta: 0:00:12    time: 0.0196  data: 0.0174  max mem: 13772
Epoch: [2]  [3940/4572]  eta: 0:00:12    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [2]  [3960/4572]  eta: 0:00:12    time: 0.0231  data: 0.0209  max mem: 13772
Epoch: [2]  [3980/4572]  eta: 0:00:11    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [2]  [4000/4572]  eta: 0:00:11    time: 0.0196  data: 0.0170  max mem: 13772
Epoch: [2]  [4020/4572]  eta: 0:00:10    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [2]  [4040/4572]  eta: 0:00:10    time: 0.0197  data: 0.0168  max mem: 13772
Epoch: [2]  [4060/4572]  eta: 0:00:10    time: 0.0199  data: 0.0172  max mem: 13772
Epoch: [2]  [4080/4572]  eta: 0:00:09    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [2]  [4100/4572]  eta: 0:00:09    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [2]  [4120/4572]  eta: 0:00:08    time: 0.0200  data: 0.0172  max mem: 13772
Epoch: [2]  [4140/4572]  eta: 0:00:08    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [2]  [4160/4572]  eta: 0:00:08    time: 0.0198  data: 0.0170  max mem: 13772
Epoch: [2]  [4180/4572]  eta: 0:00:07    time: 0.0198  data: 0.0171  max mem: 13772
Epoch: [2]  [4200/4572]  eta: 0:00:07    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [2]  [4220/4572]  eta: 0:00:06    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [2]  [4240/4572]  eta: 0:00:06    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [2]  [4260/4572]  eta: 0:00:06    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [2]  [4280/4572]  eta: 0:00:05    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [2]  [4300/4572]  eta: 0:00:05    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [2]  [4320/4572]  eta: 0:00:04    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [2]  [4340/4572]  eta: 0:00:04    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [2]  [4360/4572]  eta: 0:00:04    time: 0.0197  data: 0.0170  max mem: 13772
Epoch: [2]  [4380/4572]  eta: 0:00:03    time: 0.0200  data: 0.0178  max mem: 13772
Epoch: [2]  [4400/4572]  eta: 0:00:03    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [2]  [4420/4572]  eta: 0:00:03    time: 0.0200  data: 0.0178  max mem: 13772
Epoch: [2]  [4440/4572]  eta: 0:00:02    time: 0.0197  data: 0.0173  max mem: 13772
Epoch: [2]  [4460/4572]  eta: 0:00:02    time: 0.0202  data: 0.0168  max mem: 13772
Epoch: [2]  [4480/4572]  eta: 0:00:01    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [2]  [4500/4572]  eta: 0:00:01    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [2]  [4520/4572]  eta: 0:00:01    time: 0.0197  data: 0.0174  max mem: 13772
Epoch: [2]  [4540/4572]  eta: 0:00:00    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [2]  [4560/4572]  eta: 0:00:00    time: 0.0197  data: 0.0170  max mem: 13772
Epoch: [2]  [4571/4572]  eta: 0:00:00    time: 0.0203  data: 0.0175  max mem: 13772
Epoch: [2] Total time: 0:01:30 (0.0198 s / it)
:::MLLOG {"namespace": "", "time_ms": 1715175993766, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1715175993766, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 201.69570678989678}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 3}}
:::MLLOG {"namespace": "", "time_ms": 1715175993766, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 344, "epoch_num": 3}}
Test:  [ 0/13]  eta: 0:00:03  model_time: 0.2670 (0.2670)  evaluator_time: 0.0031 (0.0031)  time: 0.2711  data: 0.0009  max mem: 13772
Test:  [12/13]  eta: 0:00:00  model_time: 0.2741 (0.2537)  evaluator_time: 0.0036 (0.0104)  time: 0.2651  data: 0.0008  max mem: 13772
Test: Total time: 0:00:03 (0.2651 s / it)
Averaged stats: model_time: 0.2741 (0.2576)  evaluator_time: 0.0036 (0.0082)
:::MLLOG {"namespace": "", "time_ms": 1715175997697, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 3}}
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
Epoch: [3]  [   0/4571]  eta: 0:01:34    time: 0.0207  data: 0.0009  max mem: 13772
Epoch: [3]  [  20/4571]  eta: 0:01:29    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [3]  [  40/4571]  eta: 0:01:29    time: 0.0199  data: 0.0171  max mem: 13772
Epoch: [3]  [  60/4571]  eta: 0:01:28    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [3]  [  80/4571]  eta: 0:01:28    time: 0.0199  data: 0.0177  max mem: 13772
Epoch: [3]  [ 100/4571]  eta: 0:01:28    time: 0.0205  data: 0.0178  max mem: 13772
Epoch: [3]  [ 120/4571]  eta: 0:01:28    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [3]  [ 140/4571]  eta: 0:01:27    time: 0.0198  data: 0.0169  max mem: 13772
Epoch: [3]  [ 160/4571]  eta: 0:01:27    time: 0.0200  data: 0.0175  max mem: 13772
Epoch: [3]  [ 180/4571]  eta: 0:01:28    time: 0.0227  data: 0.0202  max mem: 13772
Epoch: [3]  [ 200/4571]  eta: 0:01:27    time: 0.0195  data: 0.0166  max mem: 13772
Epoch: [3]  [ 220/4571]  eta: 0:01:27    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [3]  [ 240/4571]  eta: 0:01:26    time: 0.0195  data: 0.0168  max mem: 13772
:::MLLOG {"namespace": "", "time_ms": 1715176002863, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.323220881157511, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 437, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1715176002864, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 438, "epoch_num": 3}}
Epoch: [3]  [ 260/4571]  eta: 0:01:26    time: 0.0197  data: 0.0170  max mem: 13772
Epoch: [3]  [ 280/4571]  eta: 0:01:25    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [3]  [ 300/4571]  eta: 0:01:25    time: 0.0197  data: 0.0174  max mem: 13772
Epoch: [3]  [ 320/4571]  eta: 0:01:24    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [3]  [ 340/4571]  eta: 0:01:24    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [3]  [ 360/4571]  eta: 0:01:23    time: 0.0201  data: 0.0173  max mem: 13772
Epoch: [3]  [ 380/4571]  eta: 0:01:23    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [3]  [ 400/4571]  eta: 0:01:22    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [3]  [ 420/4571]  eta: 0:01:22    time: 0.0203  data: 0.0175  max mem: 13772
Epoch: [3]  [ 440/4571]  eta: 0:01:22    time: 0.0203  data: 0.0175  max mem: 13772
Epoch: [3]  [ 460/4571]  eta: 0:01:21    time: 0.0199  data: 0.0176  max mem: 13772
Epoch: [3]  [ 480/4571]  eta: 0:01:21    time: 0.0195  data: 0.0173  max mem: 13772
Epoch: [3]  [ 500/4571]  eta: 0:01:20    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [3]  [ 520/4571]  eta: 0:01:20    time: 0.0197  data: 0.0170  max mem: 13772
Epoch: [3]  [ 540/4571]  eta: 0:01:20    time: 0.0198  data: 0.0171  max mem: 13772
Epoch: [3]  [ 560/4571]  eta: 0:01:19    time: 0.0194  data: 0.0167  max mem: 13772
Epoch: [3]  [ 580/4571]  eta: 0:01:19    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [3]  [ 600/4571]  eta: 0:01:18    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [3]  [ 620/4571]  eta: 0:01:18    time: 0.0198  data: 0.0170  max mem: 13772
Epoch: [3]  [ 640/4571]  eta: 0:01:17    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [3]  [ 660/4571]  eta: 0:01:18    time: 0.0244  data: 0.0222  max mem: 13772
Epoch: [3]  [ 680/4571]  eta: 0:01:17    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [3]  [ 700/4571]  eta: 0:01:17    time: 0.0197  data: 0.0170  max mem: 13772
Epoch: [3]  [ 720/4571]  eta: 0:01:16    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [3]  [ 740/4571]  eta: 0:01:16    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [3]  [ 760/4571]  eta: 0:01:15    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [3]  [ 780/4571]  eta: 0:01:15    time: 0.0196  data: 0.0165  max mem: 13772
Epoch: [3]  [ 800/4571]  eta: 0:01:15    time: 0.0202  data: 0.0174  max mem: 13772
Epoch: [3]  [ 820/4571]  eta: 0:01:14    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [3]  [ 840/4571]  eta: 0:01:14    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [3]  [ 860/4571]  eta: 0:01:14    time: 0.0236  data: 0.0208  max mem: 13772
Epoch: [3]  [ 880/4571]  eta: 0:01:13    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [3]  [ 900/4571]  eta: 0:01:13    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [3]  [ 920/4571]  eta: 0:01:12    time: 0.0195  data: 0.0173  max mem: 13772
Epoch: [3]  [ 940/4571]  eta: 0:01:12    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [3]  [ 960/4571]  eta: 0:01:11    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [3]  [ 980/4571]  eta: 0:01:11    time: 0.0197  data: 0.0170  max mem: 13772
Epoch: [3]  [1000/4571]  eta: 0:01:11    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [3]  [1020/4571]  eta: 0:01:10    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [3]  [1040/4571]  eta: 0:01:10    time: 0.0202  data: 0.0173  max mem: 13772
Epoch: [3]  [1060/4571]  eta: 0:01:09    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [3]  [1080/4571]  eta: 0:01:09    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [3]  [1100/4571]  eta: 0:01:09    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [3]  [1120/4571]  eta: 0:01:08    time: 0.0196  data: 0.0170  max mem: 13772
Epoch: [3]  [1140/4571]  eta: 0:01:08    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [3]  [1160/4571]  eta: 0:01:07    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [3]  [1180/4571]  eta: 0:01:07    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [3]  [1200/4571]  eta: 0:01:06    time: 0.0199  data: 0.0172  max mem: 13772
Epoch: [3]  [1220/4571]  eta: 0:01:06    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [3]  [1240/4571]  eta: 0:01:06    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [3]  [1260/4571]  eta: 0:01:05    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [3]  [1280/4571]  eta: 0:01:05    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [3]  [1300/4571]  eta: 0:01:04    time: 0.0198  data: 0.0177  max mem: 13772
Epoch: [3]  [1320/4571]  eta: 0:01:04    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [3]  [1340/4571]  eta: 0:01:04    time: 0.0195  data: 0.0170  max mem: 13772
Epoch: [3]  [1360/4571]  eta: 0:01:03    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [3]  [1380/4571]  eta: 0:01:03    time: 0.0195  data: 0.0174  max mem: 13772
Epoch: [3]  [1400/4571]  eta: 0:01:02    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [3]  [1420/4571]  eta: 0:01:02    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [3]  [1440/4571]  eta: 0:01:02    time: 0.0195  data: 0.0173  max mem: 13772
Epoch: [3]  [1460/4571]  eta: 0:01:01    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [3]  [1480/4571]  eta: 0:01:01    time: 0.0200  data: 0.0172  max mem: 13772
Epoch: [3]  [1500/4571]  eta: 0:01:00    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [3]  [1520/4571]  eta: 0:01:00    time: 0.0195  data: 0.0173  max mem: 13772
Epoch: [3]  [1540/4571]  eta: 0:01:00    time: 0.0197  data: 0.0170  max mem: 13772
Epoch: [3]  [1560/4571]  eta: 0:00:59    time: 0.0195  data: 0.0174  max mem: 13772
Epoch: [3]  [1580/4571]  eta: 0:00:59    time: 0.0200  data: 0.0178  max mem: 13772
Epoch: [3]  [1600/4571]  eta: 0:00:58    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [3]  [1620/4571]  eta: 0:00:58    time: 0.0198  data: 0.0177  max mem: 13772
Epoch: [3]  [1640/4571]  eta: 0:00:58    time: 0.0195  data: 0.0173  max mem: 13772
Epoch: [3]  [1660/4571]  eta: 0:00:57    time: 0.0203  data: 0.0178  max mem: 13772
Epoch: [3]  [1680/4571]  eta: 0:00:57    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [3]  [1700/4571]  eta: 0:00:56    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [3]  [1720/4571]  eta: 0:00:56    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [3]  [1740/4571]  eta: 0:00:56    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [3]  [1760/4571]  eta: 0:00:55    time: 0.0200  data: 0.0173  max mem: 13772
Epoch: [3]  [1780/4571]  eta: 0:00:55    time: 0.0200  data: 0.0172  max mem: 13772
Epoch: [3]  [1800/4571]  eta: 0:00:54    time: 0.0197  data: 0.0168  max mem: 13772
Epoch: [3]  [1820/4571]  eta: 0:00:54    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [3]  [1840/4571]  eta: 0:00:54    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [3]  [1860/4571]  eta: 0:00:53    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [3]  [1880/4571]  eta: 0:00:53    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [3]  [1900/4571]  eta: 0:00:52    time: 0.0200  data: 0.0173  max mem: 13772
Epoch: [3]  [1920/4571]  eta: 0:00:52    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [3]  [1940/4571]  eta: 0:00:52    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [3]  [1960/4571]  eta: 0:00:51    time: 0.0197  data: 0.0170  max mem: 13772
Epoch: [3]  [1980/4571]  eta: 0:00:51    time: 0.0195  data: 0.0173  max mem: 13772
Epoch: [3]  [2000/4571]  eta: 0:00:50    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [3]  [2020/4571]  eta: 0:00:50    time: 0.0197  data: 0.0168  max mem: 13772
Epoch: [3]  [2040/4571]  eta: 0:00:50    time: 0.0200  data: 0.0177  max mem: 13772
Epoch: [3]  [2060/4571]  eta: 0:00:49    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [3]  [2080/4571]  eta: 0:00:49    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [3]  [2100/4571]  eta: 0:00:48    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [3]  [2120/4571]  eta: 0:00:48    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [3]  [2140/4571]  eta: 0:00:48    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [3]  [2160/4571]  eta: 0:00:47    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [3]  [2180/4571]  eta: 0:00:47    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [3]  [2200/4571]  eta: 0:00:46    time: 0.0195  data: 0.0173  max mem: 13772
Epoch: [3]  [2220/4571]  eta: 0:00:46    time: 0.0195  data: 0.0174  max mem: 13772
Epoch: [3]  [2240/4571]  eta: 0:00:46    time: 0.0200  data: 0.0173  max mem: 13772
Epoch: [3]  [2260/4571]  eta: 0:00:45    time: 0.0200  data: 0.0172  max mem: 13772
Epoch: [3]  [2280/4571]  eta: 0:00:45    time: 0.0198  data: 0.0170  max mem: 13772
Epoch: [3]  [2300/4571]  eta: 0:00:44    time: 0.0200  data: 0.0178  max mem: 13772
Epoch: [3]  [2320/4571]  eta: 0:00:44    time: 0.0204  data: 0.0171  max mem: 13772
Epoch: [3]  [2340/4571]  eta: 0:00:44    time: 0.0199  data: 0.0178  max mem: 13772
Epoch: [3]  [2360/4571]  eta: 0:00:43    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [3]  [2380/4571]  eta: 0:00:43    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [3]  [2400/4571]  eta: 0:00:42    time: 0.0199  data: 0.0171  max mem: 13772
Epoch: [3]  [2420/4571]  eta: 0:00:42    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [3]  [2440/4571]  eta: 0:00:42    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [3]  [2460/4571]  eta: 0:00:41    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [3]  [2480/4571]  eta: 0:00:41    time: 0.0195  data: 0.0173  max mem: 13772
Epoch: [3]  [2500/4571]  eta: 0:00:40    time: 0.0194  data: 0.0167  max mem: 13772
Epoch: [3]  [2520/4571]  eta: 0:00:40    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [3]  [2540/4571]  eta: 0:00:40    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [3]  [2560/4571]  eta: 0:00:39    time: 0.0201  data: 0.0174  max mem: 13772
Epoch: [3]  [2580/4571]  eta: 0:00:39    time: 0.0204  data: 0.0175  max mem: 13772
Epoch: [3]  [2600/4571]  eta: 0:00:38    time: 0.0195  data: 0.0174  max mem: 13772
Epoch: [3]  [2620/4571]  eta: 0:00:38    time: 0.0195  data: 0.0173  max mem: 13772
Epoch: [3]  [2640/4571]  eta: 0:00:38    time: 0.0195  data: 0.0173  max mem: 13772
Epoch: [3]  [2660/4571]  eta: 0:00:37    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [3]  [2680/4571]  eta: 0:00:37    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [3]  [2700/4571]  eta: 0:00:36    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [3]  [2720/4571]  eta: 0:00:36    time: 0.0195  data: 0.0173  max mem: 13772
Epoch: [3]  [2740/4571]  eta: 0:00:36    time: 0.0195  data: 0.0173  max mem: 13772
Epoch: [3]  [2760/4571]  eta: 0:00:35    time: 0.0197  data: 0.0168  max mem: 13772
Epoch: [3]  [2780/4571]  eta: 0:00:35    time: 0.0195  data: 0.0173  max mem: 13772
Epoch: [3]  [2800/4571]  eta: 0:00:34    time: 0.0195  data: 0.0173  max mem: 13772
Epoch: [3]  [2820/4571]  eta: 0:00:34    time: 0.0196  data: 0.0174  max mem: 13772
Epoch: [3]  [2840/4571]  eta: 0:00:34    time: 0.0207  data: 0.0185  max mem: 13772
Epoch: [3]  [2860/4571]  eta: 0:00:33    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [3]  [2880/4571]  eta: 0:00:33    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [3]  [2900/4571]  eta: 0:00:32    time: 0.0196  data: 0.0174  max mem: 13772
Epoch: [3]  [2920/4571]  eta: 0:00:32    time: 0.0197  data: 0.0175  max mem: 13772
Epoch: [3]  [2940/4571]  eta: 0:00:32    time: 0.0195  data: 0.0173  max mem: 13772
Epoch: [3]  [2960/4571]  eta: 0:00:31    time: 0.0199  data: 0.0172  max mem: 13772
Epoch: [3]  [2980/4571]  eta: 0:00:31    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [3]  [3000/4571]  eta: 0:00:31    time: 0.0198  data: 0.0171  max mem: 13772
Epoch: [3]  [3020/4571]  eta: 0:00:30    time: 0.0194  data: 0.0167  max mem: 13772
Epoch: [3]  [3040/4571]  eta: 0:00:30    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [3]  [3060/4571]  eta: 0:00:29    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [3]  [3080/4571]  eta: 0:00:29    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [3]  [3100/4571]  eta: 0:00:29    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [3]  [3120/4571]  eta: 0:00:28    time: 0.0196  data: 0.0169  max mem: 13772
Epoch: [3]  [3140/4571]  eta: 0:00:28    time: 0.0200  data: 0.0172  max mem: 13772
Epoch: [3]  [3160/4571]  eta: 0:00:27    time: 0.0194  data: 0.0172  max mem: 13772
Epoch: [3]  [3180/4571]  eta: 0:00:27    time: 0.0198  data: 0.0175  max mem: 13772
Epoch: [3]  [3200/4571]  eta: 0:00:27    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [3]  [3220/4571]  eta: 0:00:26    time: 0.0195  data: 0.0173  max mem: 13772
Epoch: [3]  [3240/4571]  eta: 0:00:26    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [3]  [3260/4571]  eta: 0:00:25    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [3]  [3280/4571]  eta: 0:00:25    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [3]  [3300/4571]  eta: 0:00:25    time: 0.0200  data: 0.0171  max mem: 13772
Epoch: [3]  [3320/4571]  eta: 0:00:24    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [3]  [3340/4571]  eta: 0:00:24    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [3]  [3360/4571]  eta: 0:00:23    time: 0.0197  data: 0.0175  max mem: 13772
Epoch: [3]  [3380/4571]  eta: 0:00:23    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [3]  [3400/4571]  eta: 0:00:23    time: 0.0196  data: 0.0168  max mem: 13772
Epoch: [3]  [3420/4571]  eta: 0:00:22    time: 0.0197  data: 0.0170  max mem: 13772
Epoch: [3]  [3440/4571]  eta: 0:00:22    time: 0.0195  data: 0.0173  max mem: 13772
Epoch: [3]  [3460/4571]  eta: 0:00:21    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [3]  [3480/4571]  eta: 0:00:21    time: 0.0199  data: 0.0177  max mem: 13772
Epoch: [3]  [3500/4571]  eta: 0:00:21    time: 0.0195  data: 0.0173  max mem: 13772
Epoch: [3]  [3520/4571]  eta: 0:00:20    time: 0.0195  data: 0.0174  max mem: 13772
Epoch: [3]  [3540/4571]  eta: 0:00:20    time: 0.0194  data: 0.0169  max mem: 13772
Epoch: [3]  [3560/4571]  eta: 0:00:19    time: 0.0203  data: 0.0182  max mem: 13772
Epoch: [3]  [3580/4571]  eta: 0:00:19    time: 0.0198  data: 0.0172  max mem: 13772
Epoch: [3]  [3600/4571]  eta: 0:00:19    time: 0.0200  data: 0.0179  max mem: 13772
Epoch: [3]  [3620/4571]  eta: 0:00:18    time: 0.0195  data: 0.0175  max mem: 13772
Epoch: [3]  [3640/4571]  eta: 0:00:18    time: 0.0195  data: 0.0173  max mem: 13772
Epoch: [3]  [3660/4571]  eta: 0:00:17    time: 0.0196  data: 0.0170  max mem: 13772
Epoch: [3]  [3680/4571]  eta: 0:00:17    time: 0.0203  data: 0.0182  max mem: 13772
Epoch: [3]  [3700/4571]  eta: 0:00:17    time: 0.0195  data: 0.0174  max mem: 13772
Epoch: [3]  [3720/4571]  eta: 0:00:16    time: 0.0195  data: 0.0169  max mem: 13772
Epoch: [3]  [3740/4571]  eta: 0:00:16    time: 0.0197  data: 0.0171  max mem: 13772
Epoch: [3]  [3760/4571]  eta: 0:00:15    time: 0.0195  data: 0.0169  max mem: 13772
Epoch: [3]  [3780/4571]  eta: 0:00:15    time: 0.0194  data: 0.0168  max mem: 13772
Epoch: [3]  [3800/4571]  eta: 0:00:15    time: 0.0195  data: 0.0174  max mem: 13772
Epoch: [3]  [3820/4571]  eta: 0:00:14    time: 0.0195  data: 0.0169  max mem: 13772
Epoch: [3]  [3840/4571]  eta: 0:00:14    time: 0.0195  data: 0.0174  max mem: 13772
Epoch: [3]  [3860/4571]  eta: 0:00:14    time: 0.0209  data: 0.0188  max mem: 13772
Epoch: [3]  [3880/4571]  eta: 0:00:13    time: 0.0196  data: 0.0170  max mem: 13772
Epoch: [3]  [3900/4571]  eta: 0:00:13    time: 0.0196  data: 0.0175  max mem: 13772
Epoch: [3]  [3920/4571]  eta: 0:00:12    time: 0.0196  data: 0.0175  max mem: 13772
Epoch: [3]  [3940/4571]  eta: 0:00:12    time: 0.0196  data: 0.0175  max mem: 13772
Epoch: [3]  [3960/4571]  eta: 0:00:12    time: 0.0196  data: 0.0175  max mem: 13772
Epoch: [3]  [3980/4571]  eta: 0:00:11    time: 0.0195  data: 0.0174  max mem: 13772
Epoch: [3]  [4000/4571]  eta: 0:00:11    time: 0.0197  data: 0.0176  max mem: 13772
Epoch: [3]  [4020/4571]  eta: 0:00:10    time: 0.0195  data: 0.0170  max mem: 13772
Epoch: [3]  [4040/4571]  eta: 0:00:10    time: 0.0195  data: 0.0174  max mem: 13772
Epoch: [3]  [4060/4571]  eta: 0:00:10    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [3]  [4080/4571]  eta: 0:00:09    time: 0.0197  data: 0.0171  max mem: 13772
Epoch: [3]  [4100/4571]  eta: 0:00:09    time: 0.0195  data: 0.0174  max mem: 13772
Epoch: [3]  [4120/4571]  eta: 0:00:08    time: 0.0196  data: 0.0174  max mem: 13772
Epoch: [3]  [4140/4571]  eta: 0:00:08    time: 0.0195  data: 0.0174  max mem: 13772
Epoch: [3]  [4160/4571]  eta: 0:00:08    time: 0.0195  data: 0.0169  max mem: 13772
Epoch: [3]  [4180/4571]  eta: 0:00:07    time: 0.0195  data: 0.0169  max mem: 13772
Epoch: [3]  [4200/4571]  eta: 0:00:07    time: 0.0195  data: 0.0174  max mem: 13772
Epoch: [3]  [4220/4571]  eta: 0:00:06    time: 0.0195  data: 0.0174  max mem: 13772
Epoch: [3]  [4240/4571]  eta: 0:00:06    time: 0.0224  data: 0.0197  max mem: 13772
Epoch: [3]  [4260/4571]  eta: 0:00:06    time: 0.0204  data: 0.0178  max mem: 13772
Epoch: [3]  [4280/4571]  eta: 0:00:05    time: 0.0198  data: 0.0170  max mem: 13772
Epoch: [3]  [4300/4571]  eta: 0:00:05    time: 0.0195  data: 0.0169  max mem: 13772
Epoch: [3]  [4320/4571]  eta: 0:00:04    time: 0.0196  data: 0.0175  max mem: 13772
Epoch: [3]  [4340/4571]  eta: 0:00:04    time: 0.0208  data: 0.0187  max mem: 13772
Epoch: [3]  [4360/4571]  eta: 0:00:04    time: 0.0195  data: 0.0174  max mem: 13772
Epoch: [3]  [4380/4571]  eta: 0:00:03    time: 0.0196  data: 0.0175  max mem: 13772
Epoch: [3]  [4400/4571]  eta: 0:00:03    time: 0.0195  data: 0.0169  max mem: 13772
Epoch: [3]  [4420/4571]  eta: 0:00:02    time: 0.0197  data: 0.0176  max mem: 13772
Epoch: [3]  [4440/4571]  eta: 0:00:02    time: 0.0195  data: 0.0169  max mem: 13772
Epoch: [3]  [4460/4571]  eta: 0:00:02    time: 0.0195  data: 0.0169  max mem: 13772
Epoch: [3]  [4480/4571]  eta: 0:00:01    time: 0.0196  data: 0.0170  max mem: 13772
Epoch: [3]  [4500/4571]  eta: 0:00:01    time: 0.0196  data: 0.0175  max mem: 13772
Epoch: [3]  [4520/4571]  eta: 0:00:01    time: 0.0195  data: 0.0175  max mem: 13772
Epoch: [3]  [4540/4571]  eta: 0:00:00    time: 0.0195  data: 0.0169  max mem: 13772
Epoch: [3]  [4560/4571]  eta: 0:00:00    time: 0.0197  data: 0.0171  max mem: 13772
Epoch: [3]  [4570/4571]  eta: 0:00:00    time: 0.0202  data: 0.0176  max mem: 13772
Epoch: [3] Total time: 0:01:30 (0.0197 s / it)
:::MLLOG {"namespace": "", "time_ms": 1715176087976, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1715176087976, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 202.69037550112103}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 4}}
:::MLLOG {"namespace": "", "time_ms": 1715176087976, "event_type": "INTERVAL_START", "key": "eval_start", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 344, "epoch_num": 4}}
Test:  [ 0/13]  eta: 0:00:03  model_time: 0.2637 (0.2637)  evaluator_time: 0.0031 (0.0031)  time: 0.2677  data: 0.0008  max mem: 13772
Test:  [12/13]  eta: 0:00:00  model_time: 0.2667 (0.2519)  evaluator_time: 0.0032 (0.0031)  time: 0.2560  data: 0.0008  max mem: 13772
Test: Total time: 0:00:03 (0.2560 s / it)
Averaged stats: model_time: 0.2667 (0.2544)  evaluator_time: 0.0032 (0.0035)
:::MLLOG {"namespace": "", "time_ms": 1715176091918, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 4}}
Epoch: [4]  [   0/4572]  eta: 0:01:34    time: 0.0207  data: 0.0008  max mem: 13772
Epoch: [4]  [  20/4572]  eta: 0:01:29    time: 0.0197  data: 0.0176  max mem: 13772
Epoch: [4]  [  40/4572]  eta: 0:01:28    time: 0.0195  data: 0.0174  max mem: 13772
Epoch: [4]  [  60/4572]  eta: 0:01:28    time: 0.0195  data: 0.0169  max mem: 13772
Epoch: [4]  [  80/4572]  eta: 0:01:27    time: 0.0196  data: 0.0170  max mem: 13772
Epoch: [4]  [ 100/4572]  eta: 0:01:27    time: 0.0195  data: 0.0174  max mem: 13772
Epoch: [4]  [ 120/4572]  eta: 0:01:27    time: 0.0196  data: 0.0170  max mem: 13772
Epoch: [4]  [ 140/4572]  eta: 0:01:26    time: 0.0195  data: 0.0173  max mem: 13772
Epoch: [4]  [ 160/4572]  eta: 0:01:26    time: 0.0195  data: 0.0173  max mem: 13772
Epoch: [4]  [ 180/4572]  eta: 0:01:25    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [4]  [ 200/4572]  eta: 0:01:25    time: 0.0195  data: 0.0174  max mem: 13772
Epoch: [4]  [ 220/4572]  eta: 0:01:25    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [4]  [ 240/4572]  eta: 0:01:24    time: 0.0196  data: 0.0175  max mem: 13772
Epoch: [4]  [ 260/4572]  eta: 0:01:24    time: 0.0195  data: 0.0169  max mem: 13772
:::MLLOG {"namespace": "", "time_ms": 1715176097118, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.3447764470892449, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 437, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1715176097119, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 438, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1715176097417, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 315, "status": "success"}}
:::MLLOG {"namespace": "", "time_ms": 1715176097417, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 205.89357624134536}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 5}}
Run time 0:06:24
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097417, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097417, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097417, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097417, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097417, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097417, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097417, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097417, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097417, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097417, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097417, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097417, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097417, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097417, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097418, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097417, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715176097417, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
Loading annotations into memory...
Done (t=0.85s)
Creating index...
Done (t=1.26s)
Loading and preparing results...
DONE (t=3.98s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.27s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.19982
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.32237
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.20816
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00461
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.04355
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.22084
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.33613
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.48501
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.50689
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.02007
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.17694
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.55344
Loading and preparing results...
DONE (t=2.65s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.74s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.28144
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.42404
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.30176
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00751
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.07975
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.31134
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.37406
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.53668
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.56316
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.03311
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.23199
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.61125
Loading and preparing results...
DONE (t=2.37s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.63s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.32322
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.46616
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.34851
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00776
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.09101
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.35722
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.39622
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.56654
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.59381
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.03571
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.24296
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.64424
Loading and preparing results...
DONE (t=2.38s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.64s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.34478
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.49143
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.37229
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00974
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.09519
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.38146
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.40542
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.57890
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.60574
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.03977
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.25007
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.65675
ENDING TIMING RUN AT 2024-05-08 01:48:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,474,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,474,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,474,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,474,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,474,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,474,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,474,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,474,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,474,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,474,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:25 PM
RESULT,SINGLE_STAGE_DETECTOR,,475,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:26 PM
RESULT,SINGLE_STAGE_DETECTOR,,476,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:26 PM
RESULT,SINGLE_STAGE_DETECTOR,,476,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:26 PM
RESULT,SINGLE_STAGE_DETECTOR,,476,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:26 PM
RESULT,SINGLE_STAGE_DETECTOR,,476,nvidia,2024-05-08 01:40:30 PM
ENDING TIMING RUN AT 2024-05-08 01:48:26 PM
RESULT,SINGLE_STAGE_DETECTOR,,476,nvidia,2024-05-08 01:40:30 PM
