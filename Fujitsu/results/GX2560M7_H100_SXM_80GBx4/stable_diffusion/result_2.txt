+ echo 'Beginning trial 1 of 1'
Beginning trial 1 of 1
+ echo ':::DLPAL /home/miwa/Training4.0.2/Fujitsu/benchmarks/sd-slurm/exec/../sqsh/nvcr.io+nvdlfwea+mlperfv40+sd+20240429.pytorch.sqsh 162 1 mlperf-h100-0208 GX2560M7 GX2560M7_01x04x64'
:::DLPAL /home/miwa/Training4.0.2/Fujitsu/benchmarks/sd-slurm/exec/../sqsh/nvcr.io+nvdlfwea+mlperfv40+sd+20240429.pytorch.sqsh 162 1 mlperf-h100-0208 GX2560M7 GX2560M7_01x04x64
++ srun --ntasks=1 --container-name=stable_diffusion_162 mlperf-sysjson.sh
srun: error: mlperf-h100-0208: task 0: Exited with exit code 1
the only legal values for MLPERF_STATUS are
* onprem (means: available on premise)
* cloud  (means: available in cloud)
* preview
* reserach (means: research, devlopment, or internal)
+ echo ':::SYSJSON 
usage: mlperf-sysjson.sh
   behavior is controlled by envvars
   Required:
   * MLPERF_SUBMITTER
   * MLPERF_SYSTEM_NAME
   * MLPERF_STATUS (must be '\''onprem'\'', '\''cloud'\'', '\''preview'\'', or '\''research'\'')

   Required but usually have reasonable defaults:
   * MLPERF_DIVISION (defaults to '\''closed'\'', may change to '\''open'\'')
   * MLPERF_NUM_NODES (defaults to DGXNNODES if defined)

   Optional:
    * MLPERF_HOST_STORAGE_TYPE
    * MLPERF_HOST_STORAGE_CAPACITY
    * MLPERF_HOST_NETWORKING
    * MLPERF_HOST_NETWORKING_TOPOLOGY
    * MLPERF_HOST_MEMORY_CONFIGURATION
    * MLPERF_ACCELERATOR_MODEL_NAME
    * MLPERF_ACCELERATOR_HOST_INTERCONNECT
    * MLPERF_ACCELERATOR_FREQUENCY
    * MLPERF_ACCELERATOR_ON_CHIP_MEMORIES
    * MLPERF_ACCELERATOR_MEMORY_CONFIGURATION
    * MLPERF_ACCELERATOR_INTERCONNECT
    * MLPERF_ACCELERATOR_INTERCONNECT_TOPOLOGY
    * MLPERF_COOLING
    * MLPERF_HW_NOTES

    Automatically generated:
    * most of the rest of the fields in the system json, including things like
      * cpu sockets, cores, model name
      * accelerator model name, quantity
      * cuda and library versions'
:::SYSJSON 
usage: mlperf-sysjson.sh
   behavior is controlled by envvars
   Required:
   * MLPERF_SUBMITTER
   * MLPERF_SYSTEM_NAME
   * MLPERF_STATUS (must be 'onprem', 'cloud', 'preview', or 'research')

   Required but usually have reasonable defaults:
   * MLPERF_DIVISION (defaults to 'closed', may change to 'open')
   * MLPERF_NUM_NODES (defaults to DGXNNODES if defined)

   Optional:
    * MLPERF_HOST_STORAGE_TYPE
    * MLPERF_HOST_STORAGE_CAPACITY
    * MLPERF_HOST_NETWORKING
    * MLPERF_HOST_NETWORKING_TOPOLOGY
    * MLPERF_HOST_MEMORY_CONFIGURATION
    * MLPERF_ACCELERATOR_MODEL_NAME
    * MLPERF_ACCELERATOR_HOST_INTERCONNECT
    * MLPERF_ACCELERATOR_FREQUENCY
    * MLPERF_ACCELERATOR_ON_CHIP_MEMORIES
    * MLPERF_ACCELERATOR_MEMORY_CONFIGURATION
    * MLPERF_ACCELERATOR_INTERCONNECT
    * MLPERF_ACCELERATOR_INTERCONNECT_TOPOLOGY
    * MLPERF_COOLING
    * MLPERF_HW_NOTES

    Automatically generated:
    * most of the rest of the fields in the system json, including things like
      * cpu sockets, cores, model name
      * accelerator model name, quantity
      * cuda and library versions
+ '[' 1 -eq 1 ']'
+ srun --ntasks=1 --mpi=pmix bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on mlperf-h100-0208
vm.drop_caches = 3
+ srun --ntasks=1 --mpi=pmix --container-name=stable_diffusion_162 python -c '
from mlperf_logging import mllog
mllogger = mllog.get_mllogger()
mllogger.event(key=mllog.constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1714762297390, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
+ srun -l --mpi=pmix --ntasks=4 --ntasks-per-node=4 --container-name=stable_diffusion_162 --container-mounts=./results:/results,/home/miwa/Training4.0.2/Fujitsu/benchmarks/sd-slurm/exec/../data/datasets:/datasets,/home/miwa/Training4.0.2/Fujitsu/benchmarks/sd-slurm/exec/../data/checkpoints:/checkpoints,/mnt/data5/work/sd/nemologs/:/nemologs --container-workdir=/workspace/sd --container-env=MASTER_PORT,MASTER_ADDR slurm2pytorch ./run_and_time.sh
2: STARTING TIMING RUN AT 2024-05-04 03:51:41 AM
1: STARTING TIMING RUN AT 2024-05-04 03:51:41 AM
3: STARTING TIMING RUN AT 2024-05-04 03:51:41 AM
0: STARTING TIMING RUN AT 2024-05-04 03:51:41 AM
1: :::MLLOG {"namespace": "", "time_ms": 1714762305420, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
2: :::MLLOG {"namespace": "", "time_ms": 1714762305439, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
0: :::MLLOG {"namespace": "", "time_ms": 1714762305443, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
3: :::MLLOG {"namespace": "", "time_ms": 1714762305471, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
2: RANDOM_SEED=9456
1: RANDOM_SEED=9456
0: RANDOM_SEED=9456
3: RANDOM_SEED=9456
0: num_gpus=4 num_sockets = 2 num_nodes=2 cores_per_socket=48
3: num_gpus=4 num_sockets = 2 num_nodes=2 cores_per_socket=48
2: num_gpus=4 num_sockets = 2 num_nodes=2 cores_per_socket=48
1: num_gpus=4 num_sockets = 2 num_nodes=2 cores_per_socket=48
1: FlashAttention Installed
0: FlashAttention Installed
2: FlashAttention Installed
3: FlashAttention Installed
1: :::MLLOG {"namespace": "", "time_ms": 1714762329583, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/sd/main.py", "lineno": 73}}
2: :::MLLOG {"namespace": "", "time_ms": 1714762329583, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/sd/main.py", "lineno": 73}}
0: [NeMo W 2024-05-04 03:52:09 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
0:     See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
0:       ret = run_job(
0:     
0: :::MLLOG {"namespace": "", "time_ms": 1714762329730, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/sd/main.py", "lineno": 73}}
3: :::MLLOG {"namespace": "", "time_ms": 1714762329765, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/sd/main.py", "lineno": 73}}
1: :::MLLOG {"namespace": "", "time_ms": 1714762330412, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3661889204, "metadata": {"file": "/workspace/sd/main.py", "lineno": 84}}
1: [rank: 1] Seed set to 3661889204
2: :::MLLOG {"namespace": "", "time_ms": 1714762330493, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3951582245, "metadata": {"file": "/workspace/sd/main.py", "lineno": 84}}
2: [rank: 2] Seed set to 3951582245
0: [NeMo I 2024-05-04 03:52:10 main:67] L2 promotion: 128 B
0: :::MLLOG {"namespace": "", "time_ms": 1714762330531, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1228225332, "metadata": {"file": "/workspace/sd/main.py", "lineno": 84}}
0: [rank: 0] Seed set to 1228225332
0: [NeMo I 2024-05-04 03:52:10 main:87] 
0:     
0:     ************** Experiment configuration ***********
3: :::MLLOG {"namespace": "", "time_ms": 1714762330537, "event_type": "POINT_IN_TIME", "key": "seed", "value": 4095906737, "metadata": {"file": "/workspace/sd/main.py", "lineno": 84}}
3: [rank: 3] Seed set to 4095906737
0: [NeMo I 2024-05-04 03:52:10 main:88] 
0:     name: stable-diffusion2-train-240504035020273822643
0:     trainer:
0:       devices: 4
0:       num_nodes: 1
0:       accelerator: gpu
0:       logger: false
0:       enable_checkpointing: false
0:       max_epochs: -1
0:       max_steps: 12000
0:       log_every_n_steps: 10000
0:       accumulate_grad_batches: 1
0:       gradient_clip_val: 1.0
0:       benchmark: false
0:       enable_model_summary: true
0:     exp_manager:
0:       exp_dir: /tmp/nemologs
0:       name: ${name}
0:       create_wandb_logger: false
0:       wandb_logger_kwargs:
0:         project: stable-diffusion
0:         group: nemo-sd
0:         name: ${name}
0:         resume: true
0:       create_checkpoint_callback: true
0:       create_tensorboard_logger: true
0:       checkpoint_callback_params:
0:         every_n_train_steps: 2000
0:         every_n_epochs: 0
0:         monitor: timestamp
0:         filename: ${name}--{timestamp}-{step}-{consumed_samples}
0:         save_top_k: -1
0:         save_last: false
0:         save_nemo_on_train_end: false
0:         save_weights_only: true
0:       resume_if_exists: true
0:       resume_ignore_no_checkpoint: true
0:       ema:
0:         enable: false
0:         decay: 0.9999
0:         validate_original_weights: false
0:         every_n_steps: 1
0:         cpu_offload: false
0:       create_preemption_callback: false
0:       log_step_timing: false
0:     model:
0:       precision: 16
0:       micro_batch_size: 64
0:       global_batch_size: 256
0:       linear_start: 0.00085
0:       linear_end: 0.012
0:       num_timesteps_cond: 1
0:       log_every_t: 200
0:       timesteps: 1000
0:       first_stage_key: images_moments
0:       cond_stage_key: clip_encoded
0:       image_size: 64
0:       channels: 4
0:       cond_stage_trainable: false
0:       conditioning_key: crossattn
0:       monitor: val/loss_simple_ema
0:       scale_factor: 0.18215
0:       use_ema: false
0:       scale_by_std: false
0:       ckpt_path: /checkpoints/sd/512-base-ema.ckpt
0:       load_vae: true
0:       load_unet: false
0:       load_encoder: true
0:       ignore_keys: []
0:       parameterization: v
0:       clip_denoised: true
0:       load_only_unet: false
0:       cosine_s: 0.008
0:       given_betas: null
0:       original_elbo_weight: 0
0:       v_posterior: 0
0:       l_simple_weight: 1
0:       use_positional_encodings: false
0:       learn_logvar: false
0:       logvar_init: 0
0:       beta_schedule: linear
0:       loss_type: l2
0:       channels_last: true
0:       concat_mode: true
0:       cond_stage_forward: null
0:       text_embedding_dropout_rate: 0.0
0:       fused_opt: true
0:       inductor: true
0:       inductor_cudagraphs: false
0:       capture_cudagraph_iters: 15
0:       unet_config:
0:         _target_: nemo.collections.multimodal.modules.stable_diffusion.diffusionmodules.openaimodel.UNetModel
0:         from_pretrained: null
0:         from_NeMo: null
0:         image_size: 32
0:         in_channels: 4
0:         out_channels: 4
0:         model_channels: 320
0:         attention_resolutions:
0:         - 4
0:         - 2
0:         - 1
0:         num_res_blocks: 2
0:         channel_mult:
0:         - 1
0:         - 2
0:         - 4
0:         - 4
0:         num_head_channels: 64
0:         use_spatial_transformer: true
0:         use_linear_in_transformer: true
0:         transformer_depth: 1
0:         context_dim: 1024
0:         use_checkpoint: false
0:         legacy: false
0:         use_flash_attention: true
0:         resblock_gn_groups: 16
0:         unet_precision: fp16
0:         timesteps: ${model.timesteps}
0:       first_stage_config:
0:         _target_: nemo.collections.multimodal.models.text_to_image.stable_diffusion.ldm.autoencoder.AutoencoderKL
0:         from_pretrained: null
0:         embed_dim: 4
0:         monitor: val/rec_loss
0:         ddconfig:
0:           double_z: true
0:           z_channels: 4
0:           resolution: 256
0:           in_channels: 3
0:           out_ch: 3
0:           ch: 128
0:           ch_mult:
0:           - 1
0:           - 2
0:           - 4
0:           - 4
0:           num_res_blocks: 2
0:           attn_resolutions: []
0:           dropout: 0.0
0:         lossconfig:
0:           target: torch.nn.Identity
0:       cond_stage_config:
0:         _target_: nemo.collections.multimodal.modules.stable_diffusion.encoders.modules.FrozenOpenCLIPEmbedder
0:         arch: ViT-H-14
0:         version: laion2b_s32b_b79k
0:         freeze: true
0:         layer: penultimate
0:         cache_dir: /checkpoints/clip
0:       seed: 9456
0:       resume_from_checkpoint: null
0:       apex_transformer_log_level: 30
0:       gradient_as_bucket_view: true
0:       ddp_overlap: false
0:       nsys_profile:
0:         enabled: false
0:         start_step: 10
0:         end_step: 10
0:         ranks:
0:         - 0
0:         gen_shape: false
0:       data:
0:         num_workers: 16
0:         train:
0:           dataset_path: /datasets/laion-400m/webdataset-moments-filtered-encoded/*.tar
0:           augmentations:
0:             resize_smallest_side: 512
0:             center_crop_h_w: 512, 512
0:             horizontal_flip: false
0:           filterings: null
0:         webdataset:
0:           infinite_sampler: true
0:           local_root_path: /datasets/laion-400m/webdataset-moments-filtered-encoded
0:       optim:
0:         name: distributed_fused_adam
0:         lr: 2.56e-05
0:         weight_decay: 0.0
0:         betas:
0:         - 0.9
0:         - 0.999
0:         sched:
0:           name: WarmupHoldPolicy
0:           warmup_steps: 1000
0:           hold_steps: 10000000000000
0:         bucket_cap_mb: 288
0:         overlap_grad_sync: true
0:         overlap_param_sync: false
0:         contiguous_grad_buffer: true
0:         contiguous_param_buffer: true
0:         store_params: true
0:         dtype: torch.float32
0:         grad_sync_dtype: torch.float16
0:         param_sync_dtype: torch.float16
0:         capturable: true
0:         distribute_within_nodes: true
0:     
0: [NeMo W 2024-05-04 03:52:10 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/_graveyard/precision.py:49: The `MixedPrecisionPlugin` is deprecated. Use `pytorch_lightning.plugins.precision.MixedPrecision` instead.
0:     
0: GPU available: True (cuda), used: True
0: TPU available: False, using: 0 TPU cores
0: IPU available: False, using: 0 IPUs
0: HPU available: False, using: 0 HPUs
0: [NeMo W 2024-05-04 03:52:10 exp_manager:773] No version folders would be created under the log folder as 'resume_if_exists' is enabled.
0: [NeMo W 2024-05-04 03:52:10 exp_manager:630] There were no checkpoints found in checkpoint_dir or no checkpoint folder at checkpoint_dir :/tmp/nemologs/stable-diffusion2-train-240504035020273822643/checkpoints. Training from scratch.
0: [NeMo I 2024-05-04 03:52:10 exp_manager:396] Experiments will be logged at /tmp/nemologs/stable-diffusion2-train-240504035020273822643
0: [NeMo I 2024-05-04 03:52:10 exp_manager:856] TensorboardLogger has been set up
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tensor_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: pipeline_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: virtual_pipeline_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: sequence_parallel in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: context_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: use_cpu_initialization in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: gradient_accumulation_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: use_te_rng_tracker in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_overlap_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_overlap_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_overlap_rs_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: overlap_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: batch_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: defer_embedding_wgrad_compute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading_activations in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading_weights in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1161] hidden_size not found in {'precision': 16, 'micro_batch_size': 64, 'global_batch_size': 256, 'linear_start': 0.00085, 'linear_end': 0.012, 'num_timesteps_cond': 1, 'log_every_t': 200, 'timesteps': 1000, 'first_stage_key': 'images_moments', 'cond_stage_key': 'clip_encoded', 'image_size': 64, 'channels': 4, 'cond_stage_trainable': False, 'conditioning_key': 'crossattn', 'monitor': 'val/loss_simple_ema', 'scale_factor': 0.18215, 'use_ema': False, 'scale_by_std': False, 'ckpt_path': '/checkpoints/sd/512-base-ema.ckpt', 'load_vae': True, 'load_unet': False, 'load_encoder': True, 'ignore_keys': [], 'parameterization': 'v', 'clip_denoised': True, 'load_only_unet': False, 'cosine_s': 0.008, 'given_betas': None, 'original_elbo_weight': 0, 'v_posterior': 0, 'l_simple_weight': 1, 'use_positional_encodings': False, 'learn_logvar': False, 'logvar_init': 0, 'beta_schedule': 'linear', 'loss_type': 'l2', 'channels_last': True, 'concat_mode': True, 'cond_stage_forward': No
0: ne, 'text_embedding_dropout_rate': 0.0, 'fused_opt': True, 'inductor': True, 'inductor_cudagraphs': False, 'capture_cudagraph_iters': 15, 'unet_config': {'_target_': 'nemo.collections.multimodal.modules.stable_diffusion.diffusionmodules.openaimodel.UNetModel', 'from_pretrained': None, 'from_NeMo': None, 'image_size': 32, 'in_channels': 4, 'out_channels': 4, 'model_channels': 320, 'attention_resolutions': [4, 2, 1], 'num_res_blocks': 2, 'channel_mult': [1, 2, 4, 4], 'num_head_channels': 64, 'use_spatial_transformer': True, 'use_linear_in_transformer': True, 'transformer_depth': 1, 'context_dim': 1024, 'use_checkpoint': False, 'legacy': False, 'use_flash_attention': True, 'resblock_gn_groups': 16, 'unet_precision': 'fp16', 'timesteps': 1000}, 'first_stage_config': {'_target_': 'nemo.collections.multimodal.models.text_to_image.stable_diffusion.ldm.autoencoder.AutoencoderKL', 'from_pretrained': None, 'embed_dim': 4, 'monitor': 'val/rec_loss', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 256, 'in_
0: channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0}, 'lossconfig': {'target': 'torch.nn.Identity'}}, 'cond_stage_config': {'_target_': 'nemo.collections.multimodal.modules.stable_diffusion.encoders.modules.FrozenOpenCLIPEmbedder', 'arch': 'ViT-H-14', 'version': 'laion2b_s32b_b79k', 'freeze': True, 'layer': 'penultimate', 'cache_dir': '/checkpoints/clip'}, 'seed': 9456, 'resume_from_checkpoint': None, 'apex_transformer_log_level': 30, 'gradient_as_bucket_view': True, 'ddp_overlap': False, 'nsys_profile': {'enabled': False, 'start_step': 10, 'end_step': 10, 'ranks': [0], 'gen_shape': False}, 'data': {'num_workers': 16, 'train': {'dataset_path': '/datasets/laion-400m/webdataset-moments-filtered-encoded/*.tar', 'augmentations': {'resize_smallest_side': 512, 'center_crop_h_w': '512, 512', 'horizontal_flip': False}, 'filterings': None}, 'webdataset': {'infinite_sampler': True, 'local_root_path': '/datasets/laion-400m/webdataset-moments-filtered
0: -encoded'}}, 'optim': {'name': 'distributed_fused_adam', 'lr': 2.56e-05, 'weight_decay': 0.0, 'betas': [0.9, 0.999], 'sched': {'name': 'WarmupHoldPolicy', 'warmup_steps': 1000, 'hold_steps': 10000000000000}, 'bucket_cap_mb': 288, 'overlap_grad_sync': True, 'overlap_param_sync': False, 'contiguous_grad_buffer': True, 'contiguous_param_buffer': True, 'store_params': True, 'dtype': 'torch.float32', 'grad_sync_dtype': 'torch.float16', 'param_sync_dtype': 'torch.float16', 'capturable': True, 'distribute_within_nodes': True}, 'target': 'nemo.collections.multimodal.models.text_to_image.stable_diffusion.ldm.ddpm.MegatronLatentDiffusion', 'nemo_version': '2.0.0b0'}. Set this in model_parallel_config if using pipeline parallelism.
0: [W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
0: [NeMo I 2024-05-04 03:52:10 megatron_init:265] Rank 0 has data parallel group : [0, 1, 2, 3]
0: [NeMo I 2024-05-04 03:52:10 megatron_init:271] Rank 0 has combined group of data parallel and context parallel : [0, 1, 2, 3]
0: [NeMo I 2024-05-04 03:52:10 megatron_init:276] All data parallel group ranks with context parallel combined: [[0, 1, 2, 3]]
0: [NeMo I 2024-05-04 03:52:10 megatron_init:279] Ranks 0 has data parallel rank: 0
0: [NeMo I 2024-05-04 03:52:10 megatron_init:287] Rank 0 has context parallel group: [0]
0: [NeMo I 2024-05-04 03:52:10 megatron_init:290] All context parallel group ranks: [[0], [1], [2], [3]]
0: [NeMo I 2024-05-04 03:52:10 megatron_init:291] Ranks 0 has context parallel rank: 0
0: [NeMo I 2024-05-04 03:52:10 megatron_init:298] Rank 0 has model parallel group: [0]
0: [NeMo I 2024-05-04 03:52:10 megatron_init:299] All model parallel group ranks: [[0], [1], [2], [3]]
0: [NeMo I 2024-05-04 03:52:10 megatron_init:308] Rank 0 has tensor model parallel group: [0]
0: [NeMo I 2024-05-04 03:52:10 megatron_init:312] All tensor model parallel group ranks: [[0], [1], [2], [3]]
0: [NeMo I 2024-05-04 03:52:10 megatron_init:313] Rank 0 has tensor model parallel rank: 0
0: [NeMo I 2024-05-04 03:52:10 megatron_init:333] Rank 0 has pipeline model parallel group: [0]
0: [NeMo I 2024-05-04 03:52:10 megatron_init:345] Rank 0 has embedding group: [0]
0: [NeMo I 2024-05-04 03:52:10 megatron_init:351] All pipeline model parallel group ranks: [[0], [1], [2], [3]]
0: [NeMo I 2024-05-04 03:52:10 megatron_init:352] Rank 0 has pipeline model parallel rank 0
0: [NeMo I 2024-05-04 03:52:10 megatron_init:353] All embedding group ranks: [[0], [1], [2], [3]]
0: [NeMo I 2024-05-04 03:52:10 megatron_init:354] Rank 0 has embedding rank: 0
0: 24-05-04 03:52:10 - PID:262039 - rank:(0, 0, 0, 0) - microbatches.py:39 - INFO - setting number of micro-batches to constant 1
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tensor_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: pipeline_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: virtual_pipeline_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: sequence_parallel in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: context_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: use_cpu_initialization in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: gradient_accumulation_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: use_te_rng_tracker in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_overlap_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_overlap_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_overlap_rs_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: overlap_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: batch_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: defer_embedding_wgrad_compute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading_activations in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading_weights in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 03:52:10 megatron_base_model:1161] hidden_size not found in {'precision': 16, 'micro_batch_size': 64, 'global_batch_size': 256, 'linear_start': 0.00085, 'linear_end': 0.012, 'num_timesteps_cond': 1, 'log_every_t': 200, 'timesteps': 1000, 'first_stage_key': 'images_moments', 'cond_stage_key': 'clip_encoded', 'image_size': 64, 'channels': 4, 'cond_stage_trainable': False, 'conditioning_key': 'crossattn', 'monitor': 'val/loss_simple_ema', 'scale_factor': 0.18215, 'use_ema': False, 'scale_by_std': False, 'ckpt_path': '/checkpoints/sd/512-base-ema.ckpt', 'load_vae': True, 'load_unet': False, 'load_encoder': True, 'ignore_keys': [], 'parameterization': 'v', 'clip_denoised': True, 'load_only_unet': False, 'cosine_s': 0.008, 'given_betas': None, 'original_elbo_weight': 0, 'v_posterior': 0, 'l_simple_weight': 1, 'use_positional_encodings': False, 'learn_logvar': False, 'logvar_init': 0, 'beta_schedule': 'linear', 'loss_type': 'l2', 'channels_last': True, 'concat_mode': True, 'cond_stage_forward': No
0: ne, 'text_embedding_dropout_rate': 0.0, 'fused_opt': True, 'inductor': True, 'inductor_cudagraphs': False, 'capture_cudagraph_iters': 15, 'unet_config': {'_target_': 'nemo.collections.multimodal.modules.stable_diffusion.diffusionmodules.openaimodel.UNetModel', 'from_pretrained': None, 'from_NeMo': None, 'image_size': 32, 'in_channels': 4, 'out_channels': 4, 'model_channels': 320, 'attention_resolutions': [4, 2, 1], 'num_res_blocks': 2, 'channel_mult': [1, 2, 4, 4], 'num_head_channels': 64, 'use_spatial_transformer': True, 'use_linear_in_transformer': True, 'transformer_depth': 1, 'context_dim': 1024, 'use_checkpoint': False, 'legacy': False, 'use_flash_attention': True, 'resblock_gn_groups': 16, 'unet_precision': 'fp16', 'timesteps': 1000}, 'first_stage_config': {'_target_': 'nemo.collections.multimodal.models.text_to_image.stable_diffusion.ldm.autoencoder.AutoencoderKL', 'from_pretrained': None, 'embed_dim': 4, 'monitor': 'val/rec_loss', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 256, 'in_
0: channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0}, 'lossconfig': {'target': 'torch.nn.Identity'}}, 'cond_stage_config': {'_target_': 'nemo.collections.multimodal.modules.stable_diffusion.encoders.modules.FrozenOpenCLIPEmbedder', 'arch': 'ViT-H-14', 'version': 'laion2b_s32b_b79k', 'freeze': True, 'layer': 'penultimate', 'cache_dir': '/checkpoints/clip'}, 'seed': 9456, 'resume_from_checkpoint': None, 'apex_transformer_log_level': 30, 'gradient_as_bucket_view': True, 'ddp_overlap': False, 'nsys_profile': {'enabled': False, 'start_step': 10, 'end_step': 10, 'ranks': [0], 'gen_shape': False}, 'data': {'num_workers': 16, 'train': {'dataset_path': '/datasets/laion-400m/webdataset-moments-filtered-encoded/*.tar', 'augmentations': {'resize_smallest_side': 512, 'center_crop_h_w': '512, 512', 'horizontal_flip': False}, 'filterings': None}, 'webdataset': {'infinite_sampler': True, 'local_root_path': '/datasets/laion-400m/webdataset-moments-filtered
0: -encoded'}}, 'optim': {'name': 'distributed_fused_adam', 'lr': 2.56e-05, 'weight_decay': 0.0, 'betas': [0.9, 0.999], 'sched': {'name': 'WarmupHoldPolicy', 'warmup_steps': 1000, 'hold_steps': 10000000000000}, 'bucket_cap_mb': 288, 'overlap_grad_sync': True, 'overlap_param_sync': False, 'contiguous_grad_buffer': True, 'contiguous_param_buffer': True, 'store_params': True, 'dtype': 'torch.float32', 'grad_sync_dtype': 'torch.float16', 'param_sync_dtype': 'torch.float16', 'capturable': True, 'distribute_within_nodes': True}, 'target': 'nemo.collections.multimodal.models.text_to_image.stable_diffusion.ldm.ddpm.MegatronLatentDiffusion', 'nemo_version': '2.0.0b0'}. Set this in model_parallel_config if using pipeline parallelism.
0: [NeMo I 2024-05-04 03:52:10 ddpm:130] LatentDiffusion: Running in v-prediction mode
0: [NeMo I 2024-05-04 03:52:10 attention:436] constructing SpatialTransformer of depth 1 w/ 320 channels and 5 heads
0: [NeMo I 2024-05-04 03:52:10 attention:436] constructing SpatialTransformer of depth 1 w/ 320 channels and 5 heads
0: [NeMo I 2024-05-04 03:52:10 attention:436] constructing SpatialTransformer of depth 1 w/ 640 channels and 10 heads
0: [NeMo I 2024-05-04 03:52:10 attention:436] constructing SpatialTransformer of depth 1 w/ 640 channels and 10 heads
0: [NeMo I 2024-05-04 03:52:11 attention:436] constructing SpatialTransformer of depth 1 w/ 1280 channels and 20 heads
0: [NeMo I 2024-05-04 03:52:11 attention:436] constructing SpatialTransformer of depth 1 w/ 1280 channels and 20 heads
0: [NeMo I 2024-05-04 03:52:11 attention:436] constructing SpatialTransformer of depth 1 w/ 1280 channels and 20 heads
0: [NeMo I 2024-05-04 03:52:13 attention:436] constructing SpatialTransformer of depth 1 w/ 1280 channels and 20 heads
0: [NeMo I 2024-05-04 03:52:13 attention:436] constructing SpatialTransformer of depth 1 w/ 1280 channels and 20 heads
0: [NeMo I 2024-05-04 03:52:13 attention:436] constructing SpatialTransformer of depth 1 w/ 1280 channels and 20 heads
0: [NeMo I 2024-05-04 03:52:13 attention:436] constructing SpatialTransformer of depth 1 w/ 640 channels and 10 heads
0: [NeMo I 2024-05-04 03:52:14 attention:436] constructing SpatialTransformer of depth 1 w/ 640 channels and 10 heads
0: [NeMo I 2024-05-04 03:52:14 attention:436] constructing SpatialTransformer of depth 1 w/ 640 channels and 10 heads
0: [NeMo I 2024-05-04 03:52:14 attention:436] constructing SpatialTransformer of depth 1 w/ 320 channels and 5 heads
0: [NeMo I 2024-05-04 03:52:14 attention:436] constructing SpatialTransformer of depth 1 w/ 320 channels and 5 heads
0: [NeMo I 2024-05-04 03:52:14 attention:436] constructing SpatialTransformer of depth 1 w/ 320 channels and 5 heads
0: [NeMo I 2024-05-04 03:52:14 utils:92] DiffusionWrapper has 865.91 M params.
0: [NeMo I 2024-05-04 03:52:15 ddpm:168] Use system random generator since CUDA graph enabled
0: making attention of type 'vanilla' with 512 in_channels
0: Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
0: making attention of type 'vanilla' with 512 in_channels
0: Downloading clip with ViT-H-14 laion2b_s32b_b79k /checkpoints/clip
0: Loaded ViT-H-14 model config.
1: [W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
2: [W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
3: [W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
0: Loading pretrained ViT-H-14 weights (laion2b_s32b_b79k).
3: making attention of type 'vanilla' with 512 in_channels
3: Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
2: making attention of type 'vanilla' with 512 in_channels
3: making attention of type 'vanilla' with 512 in_channels
2: Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
2: making attention of type 'vanilla' with 512 in_channels
1: making attention of type 'vanilla' with 512 in_channels
1: Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
1: making attention of type 'vanilla' with 512 in_channels
3: Downloading clip with ViT-H-14 laion2b_s32b_b79k /checkpoints/clip
3: Loaded ViT-H-14 model config.
2: Downloading clip with ViT-H-14 laion2b_s32b_b79k /checkpoints/clip
2: Loaded ViT-H-14 model config.
1: Downloading clip with ViT-H-14 laion2b_s32b_b79k /checkpoints/clip
1: Loaded ViT-H-14 model config.
3: Loading pretrained ViT-H-14 weights (laion2b_s32b_b79k).
2: Loading pretrained ViT-H-14 weights (laion2b_s32b_b79k).
1: Loading pretrained ViT-H-14 weights (laion2b_s32b_b79k).
0: [NeMo I 2024-05-04 03:52:34 ddpm:260] Loading /checkpoints/sd/512-base-ema.ckpt
0: [NeMo I 2024-05-04 03:52:34 ddpm:261] It has 1242 entries
0: [NeMo I 2024-05-04 03:52:34 ddpm:262] Existing model has 1240 entries
0: [NeMo I 2024-05-04 03:52:34 ddpm:296] Deleted 686 keys from `model.diffusion_model` state_dict.
0: [NeMo I 2024-05-04 03:52:35 ddpm:301] Restored from /checkpoints/sd/512-base-ema.ckpt with 686 missing and 2 unexpected keys
0: [NeMo I 2024-05-04 03:52:35 ddpm:303] Missing Keys: ['model.diffusion_model._orig_mod.time_embed.0.weight', 'model.diffusion_model._orig_mod.time_embed.0.bias', 'model.diffusion_model._orig_mod.time_embed.2.weight', 'model.diffusion_model._orig_mod.time_embed.2.bias', 'model.diffusion_model._orig_mod.input_blocks.0.0.weight', 'model.diffusion_model._orig_mod.input_blocks.0.0.bias', 'model.diffusion_model._orig_mod.input_blocks.1.0.in_layers.0.weight', 'model.diffusion_model._orig_mod.input_blocks.1.0.in_layers.0.bias', 'model.diffusion_model._orig_mod.input_blocks.1.0.in_layers.1.weight', 'model.diffusion_model._orig_mod.input_blocks.1.0.in_layers.1.bias', 'model.diffusion_model._orig_mod.input_blocks.1.0.emb_layers.1.weight', 'model.diffusion_model._orig_mod.input_blocks.1.0.emb_layers.1.bias', 'model.diffusion_model._orig_mod.input_blocks.1.0.out_layers.0.weight', 'model.diffusion_model._orig_mod.input_blocks.1.0.out_layers.0.bias', 'model.diffusion_model._orig_mod.input_blocks.1.0.out_layers.2.weight', 'mo
0: del.diffusion_model._orig_mod.input_blocks.1.0.out_layers.2.bias', 'model.diffusion_model._orig_mod.input_blocks.1.1.norm.weight', 'model.diffusion_model._orig_mod.input_blocks.1.1.norm.bias', 'model.diffusion_model._orig_mod.input_blocks.1.1.proj_in.weight', 'model.diffusion_model._orig_mod.input_blocks.1.1.proj_in.bias', 'model.diffusion_model._orig_mod.input_blocks.1.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model._orig_mod.input_blocks.1.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model._orig_mod.input_blocks.1.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model._orig_mod.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model._orig_mod.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model._orig_mod.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model._orig_mod.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model._orig_mod.input_blocks.1.1.tr
0: ansformer_blocks.0.ff.net.2.weight', 'model.diffusion_model._orig_mod.input_blocks.1.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model._orig_mod.input_blocks.1.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model._orig_mod.input_blocks.1.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model._orig_mod.input_blocks.1.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model._orig_mod.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model._orig_mod.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model._orig_mod.input_blocks.1.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model._orig_mod.input_blocks.1.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model._orig_mod.input_blocks.1.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model._orig_mod.input_blocks.1.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model._orig_mod.input_blocks.1.1.transformer_blocks.0.norm3.weight', 'model.diffus
0: ion_model._orig_mod.input_blocks.1.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model._orig_mod.input_blocks.1.1.proj_out.weight', 'model.diffusion_model._orig_mod.input_blocks.1.1.proj_out.bias', 'model.diffusion_model._orig_mod.input_blocks.2.0.in_layers.0.weight', 'model.diffusion_model._orig_mod.input_blocks.2.0.in_layers.0.bias', 'model.diffusion_model._orig_mod.input_blocks.2.0.in_layers.1.weight', 'model.diffusion_model._orig_mod.input_blocks.2.0.in_layers.1.bias', 'model.diffusion_model._orig_mod.input_blocks.2.0.emb_layers.1.weight', 'model.diffusion_model._orig_mod.input_blocks.2.0.emb_layers.1.bias', 'model.diffusion_model._orig_mod.input_blocks.2.0.out_layers.0.weight', 'model.diffusion_model._orig_mod.input_blocks.2.0.out_layers.0.bias', 'model.diffusion_model._orig_mod.input_blocks.2.0.out_layers.2.weight', 'model.diffusion_model._orig_mod.input_blocks.2.0.out_layers.2.bias', 'model.diffusion_model._orig_mod.input_blocks.2.1.norm.weight', 'model.diffusion_model._orig_mod.input_blocks.2.1
0: .norm.bias', 'model.diffusion_model._orig_mod.input_blocks.2.1.proj_in.weight', 'model.diffusion_model._orig_mod.input_blocks.2.1.proj_in.bias', 'model.diffusion_model._orig_mod.input_blocks.2.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model._orig_mod.input_blocks.2.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model._orig_mod.input_blocks.2.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model._orig_mod.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model._orig_mod.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model._orig_mod.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model._orig_mod.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model._orig_mod.input_blocks.2.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model._orig_mod.input_blocks.2.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model._orig_mod.input_blocks.2.1.transf
0: ormer_blocks.0.attn2.to_q.weight', 'model.diffusion_model._orig_mod.input_blocks.2.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model._orig_mod.input_blocks.2.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model._orig_mod.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model._orig_mod.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model._orig_mod.input_blocks.2.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model._orig_mod.input_blocks.2.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model._orig_mod.input_blocks.2.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model._orig_mod.input_blocks.2.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model._orig_mod.input_blocks.2.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model._orig_mod.input_blocks.2.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model._orig_mod.input_blocks.2.1.proj_out.weight', 'model.diffusion_model._orig_mod.input_bl
0: ocks.2.1.proj_out.bias', 'model.diffusion_model._orig_mod.input_blocks.3.0.op.weight', 'model.diffusion_model._orig_mod.input_blocks.3.0.op.bias', 'model.diffusion_model._orig_mod.input_blocks.4.0.in_layers.0.weight', 'model.diffusion_model._orig_mod.input_blocks.4.0.in_layers.0.bias', 'model.diffusion_model._orig_mod.input_blocks.4.0.in_layers.1.weight', 'model.diffusion_model._orig_mod.input_blocks.4.0.in_layers.1.bias', 'model.diffusion_model._orig_mod.input_blocks.4.0.emb_layers.1.weight', 'model.diffusion_model._orig_mod.input_blocks.4.0.emb_layers.1.bias', 'model.diffusion_model._orig_mod.input_blocks.4.0.out_layers.0.weight', 'model.diffusion_model._orig_mod.input_blocks.4.0.out_layers.0.bias', 'model.diffusion_model._orig_mod.input_blocks.4.0.out_layers.2.weight', 'model.diffusion_model._orig_mod.input_blocks.4.0.out_layers.2.bias', 'model.diffusion_model._orig_mod.input_blocks.4.0.skip_connection.weight', 'model.diffusion_model._orig_mod.input_blocks.4.0.skip_connection.bias', 'model.diffusion_model.
0: _orig_mod.input_blocks.4.1.norm.weight', 'model.diffusion_model._orig_mod.input_blocks.4.1.norm.bias', 'model.diffusion_model._orig_mod.input_blocks.4.1.proj_in.weight', 'model.diffusion_model._orig_mod.input_blocks.4.1.proj_in.bias', 'model.diffusion_model._orig_mod.input_blocks.4.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model._orig_mod.input_blocks.4.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model._orig_mod.input_blocks.4.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model._orig_mod.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model._orig_mod.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model._orig_mod.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model._orig_mod.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model._orig_mod.input_blocks.4.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model._orig_mod.input_blocks.4.1.tra
0: nsformer_blocks.0.ff.net.2.bias', 'model.diffusion_model._orig_mod.input_blocks.4.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model._orig_mod.input_blocks.4.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model._orig_mod.input_blocks.4.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model._orig_mod.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model._orig_mod.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model._orig_mod.input_blocks.4.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model._orig_mod.input_blocks.4.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model._orig_mod.input_blocks.4.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model._orig_mod.input_blocks.4.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model._orig_mod.input_blocks.4.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model._orig_mod.input_blocks.4.1.transformer_blocks.0.norm3.bias', 'model.diffusion_mo
0: del._orig_mod.input_blocks.4.1.proj_out.weight', 'model.diffusion_model._orig_mod.input_blocks.4.1.proj_out.bias', 'model.diffusion_model._orig_mod.input_blocks.5.0.in_layers.0.weight', 'model.diffusion_model._orig_mod.input_blocks.5.0.in_layers.0.bias', 'model.diffusion_model._orig_mod.input_blocks.5.0.in_layers.1.weight', 'model.diffusion_model._orig_mod.input_blocks.5.0.in_layers.1.bias', 'model.diffusion_model._orig_mod.input_blocks.5.0.emb_layers.1.weight', 'model.diffusion_model._orig_mod.input_blocks.5.0.emb_layers.1.bias', 'model.diffusion_model._orig_mod.input_blocks.5.0.out_layers.0.weight', 'model.diffusion_model._orig_mod.input_blocks.5.0.out_layers.0.bias', 'model.diffusion_model._orig_mod.input_blocks.5.0.out_layers.2.weight', 'model.diffusion_model._orig_mod.input_blocks.5.0.out_layers.2.bias', 'model.diffusion_model._orig_mod.input_blocks.5.1.norm.weight', 'model.diffusion_model._orig_mod.input_blocks.5.1.norm.bias', 'model.diffusion_model._orig_mod.input_blocks.5.1.proj_in.weight', 'model.dif
0: fusion_model._orig_mod.input_blocks.5.1.proj_in.bias', 'model.diffusion_model._orig_mod.input_blocks.5.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model._orig_mod.input_blocks.5.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model._orig_mod.input_blocks.5.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model._orig_mod.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model._orig_mod.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model._orig_mod.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model._orig_mod.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model._orig_mod.input_blocks.5.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model._orig_mod.input_blocks.5.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model._orig_mod.input_blocks.5.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model._orig_mod.input_blocks.5.1.trans
0: former_blocks.0.attn2.to_k.weight', 'model.diffusion_model._orig_mod.input_blocks.5.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model._orig_mod.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model._orig_mod.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model._orig_mod.input_blocks.5.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model._orig_mod.input_blocks.5.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model._orig_mod.input_blocks.5.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model._orig_mod.input_blocks.5.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model._orig_mod.input_blocks.5.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model._orig_mod.input_blocks.5.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model._orig_mod.input_blocks.5.1.proj_out.weight', 'model.diffusion_model._orig_mod.input_blocks.5.1.proj_out.bias', 'model.diffusion_model._orig_mod.input_blocks.6.0.op.weight', 'mo
0: del.diffusion_model._orig_mod.input_blocks.6.0.op.bias', 'model.diffusion_model._orig_mod.input_blocks.7.0.in_layers.0.weight', 'model.diffusion_model._orig_mod.input_blocks.7.0.in_layers.0.bias', 'model.diffusion_model._orig_mod.input_blocks.7.0.in_layers.1.weight', 'model.diffusion_model._orig_mod.input_blocks.7.0.in_layers.1.bias', 'model.diffusion_model._orig_mod.input_blocks.7.0.emb_layers.1.weight', 'model.diffusion_model._orig_mod.input_blocks.7.0.emb_layers.1.bias', 'model.diffusion_model._orig_mod.input_blocks.7.0.out_layers.0.weight', 'model.diffusion_model._orig_mod.input_blocks.7.0.out_layers.0.bias', 'model.diffusion_model._orig_mod.input_blocks.7.0.out_layers.2.weight', 'model.diffusion_model._orig_mod.input_blocks.7.0.out_layers.2.bias', 'model.diffusion_model._orig_mod.input_blocks.7.0.skip_connection.weight', 'model.diffusion_model._orig_mod.input_blocks.7.0.skip_connection.bias', 'model.diffusion_model._orig_mod.input_blocks.7.1.norm.weight', 'model.diffusion_model._orig_mod.input_blocks.7.1
0: .norm.bias', 'model.diffusion_model._orig_mod.input_blocks.7.1.proj_in.weight', 'model.diffusion_model._orig_mod.input_blocks.7.1.proj_in.bias', 'model.diffusion_model._orig_mod.input_blocks.7.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model._orig_mod.input_blocks.7.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model._orig_mod.input_blocks.7.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model._orig_mod.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model._orig_mod.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model._orig_mod.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model._orig_mod.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model._orig_mod.input_blocks.7.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model._orig_mod.input_blocks.7.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model._orig_mod.input_blocks.7.1.transf
0: ormer_blocks.0.attn2.to_q.weight', 'model.diffusion_model._orig_mod.input_blocks.7.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model._orig_mod.input_blocks.7.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model._orig_mod.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model._orig_mod.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model._orig_mod.input_blocks.7.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model._orig_mod.input_blocks.7.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model._orig_mod.input_blocks.7.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model._orig_mod.input_blocks.7.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model._orig_mod.input_blocks.7.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model._orig_mod.input_blocks.7.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model._orig_mod.input_blocks.7.1.proj_out.weight', 'model.diffusion_model._orig_mod.input_bl
0: ocks.7.1.proj_out.bias', 'model.diffusion_model._orig_mod.input_blocks.8.0.in_layers.0.weight', 'model.diffusion_model._orig_mod.input_blocks.8.0.in_layers.0.bias', 'model.diffusion_model._orig_mod.input_blocks.8.0.in_layers.1.weight', 'model.diffusion_model._orig_mod.input_blocks.8.0.in_layers.1.bias', 'model.diffusion_model._orig_mod.input_blocks.8.0.emb_layers.1.weight', 'model.diffusion_model._orig_mod.input_blocks.8.0.emb_layers.1.bias', 'model.diffusion_model._orig_mod.input_blocks.8.0.out_layers.0.weight', 'model.diffusion_model._orig_mod.input_blocks.8.0.out_layers.0.bias', 'model.diffusion_model._orig_mod.input_blocks.8.0.out_layers.2.weight', 'model.diffusion_model._orig_mod.input_blocks.8.0.out_layers.2.bias', 'model.diffusion_model._orig_mod.input_blocks.8.1.norm.weight', 'model.diffusion_model._orig_mod.input_blocks.8.1.norm.bias', 'model.diffusion_model._orig_mod.input_blocks.8.1.proj_in.weight', 'model.diffusion_model._orig_mod.input_blocks.8.1.proj_in.bias', 'model.diffusion_model._orig_mod.in
0: put_blocks.8.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model._orig_mod.input_blocks.8.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model._orig_mod.input_blocks.8.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model._orig_mod.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model._orig_mod.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model._orig_mod.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model._orig_mod.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model._orig_mod.input_blocks.8.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model._orig_mod.input_blocks.8.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model._orig_mod.input_blocks.8.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model._orig_mod.input_blocks.8.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model._orig_mod.input_blocks.8.1.tran
0: sformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model._orig_mod.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model._orig_mod.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model._orig_mod.input_blocks.8.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model._orig_mod.input_blocks.8.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model._orig_mod.input_blocks.8.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model._orig_mod.input_blocks.8.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model._orig_mod.input_blocks.8.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model._orig_mod.input_blocks.8.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model._orig_mod.input_blocks.8.1.proj_out.weight', 'model.diffusion_model._orig_mod.input_blocks.8.1.proj_out.bias', 'model.diffusion_model._orig_mod.input_blocks.9.0.op.weight', 'model.diffusion_model._orig_mod.input_blocks.9.0.op.bias', 'model.diffusion_model._orig_mod.
0: input_blocks.10.0.in_layers.0.weight', 'model.diffusion_model._orig_mod.input_blocks.10.0.in_layers.0.bias', 'model.diffusion_model._orig_mod.input_blocks.10.0.in_layers.1.weight', 'model.diffusion_model._orig_mod.input_blocks.10.0.in_layers.1.bias', 'model.diffusion_model._orig_mod.input_blocks.10.0.emb_layers.1.weight', 'model.diffusion_model._orig_mod.input_blocks.10.0.emb_layers.1.bias', 'model.diffusion_model._orig_mod.input_blocks.10.0.out_layers.0.weight', 'model.diffusion_model._orig_mod.input_blocks.10.0.out_layers.0.bias', 'model.diffusion_model._orig_mod.input_blocks.10.0.out_layers.2.weight', 'model.diffusion_model._orig_mod.input_blocks.10.0.out_layers.2.bias', 'model.diffusion_model._orig_mod.input_blocks.11.0.in_layers.0.weight', 'model.diffusion_model._orig_mod.input_blocks.11.0.in_layers.0.bias', 'model.diffusion_model._orig_mod.input_blocks.11.0.in_layers.1.weight', 'model.diffusion_model._orig_mod.input_blocks.11.0.in_layers.1.bias', 'model.diffusion_model._orig_mod.input_blocks.11.0.emb_la
0: yers.1.weight', 'model.diffusion_model._orig_mod.input_blocks.11.0.emb_layers.1.bias', 'model.diffusion_model._orig_mod.input_blocks.11.0.out_layers.0.weight', 'model.diffusion_model._orig_mod.input_blocks.11.0.out_layers.0.bias', 'model.diffusion_model._orig_mod.input_blocks.11.0.out_layers.2.weight', 'model.diffusion_model._orig_mod.input_blocks.11.0.out_layers.2.bias', 'model.diffusion_model._orig_mod.middle_block.0.in_layers.0.weight', 'model.diffusion_model._orig_mod.middle_block.0.in_layers.0.bias', 'model.diffusion_model._orig_mod.middle_block.0.in_layers.1.weight', 'model.diffusion_model._orig_mod.middle_block.0.in_layers.1.bias', 'model.diffusion_model._orig_mod.middle_block.0.emb_layers.1.weight', 'model.diffusion_model._orig_mod.middle_block.0.emb_layers.1.bias', 'model.diffusion_model._orig_mod.middle_block.0.out_layers.0.weight', 'model.diffusion_model._orig_mod.middle_block.0.out_layers.0.bias', 'model.diffusion_model._orig_mod.middle_block.0.out_layers.2.weight', 'model.diffusion_model._orig_mo
0: d.middle_block.0.out_layers.2.bias', 'model.diffusion_model._orig_mod.middle_block.1.norm.weight', 'model.diffusion_model._orig_mod.middle_block.1.norm.bias', 'model.diffusion_model._orig_mod.middle_block.1.proj_in.weight', 'model.diffusion_model._orig_mod.middle_block.1.proj_in.bias', 'model.diffusion_model._orig_mod.middle_block.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model._orig_mod.middle_block.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model._orig_mod.middle_block.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model._orig_mod.middle_block.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model._orig_mod.middle_block.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model._orig_mod.middle_block.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model._orig_mod.middle_block.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model._orig_mod.middle_block.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_
0: model._orig_mod.middle_block.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model._orig_mod.middle_block.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model._orig_mod.middle_block.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model._orig_mod.middle_block.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model._orig_mod.middle_block.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model._orig_mod.middle_block.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model._orig_mod.middle_block.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model._orig_mod.middle_block.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model._orig_mod.middle_block.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model._orig_mod.middle_block.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model._orig_mod.middle_block.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model._orig_mod.middle_block.1.transformer_blocks.0.norm3.bias', 'model.
0: diffusion_model._orig_mod.middle_block.1.proj_out.weight', 'model.diffusion_model._orig_mod.middle_block.1.proj_out.bias', 'model.diffusion_model._orig_mod.middle_block.2.in_layers.0.weight', 'model.diffusion_model._orig_mod.middle_block.2.in_layers.0.bias', 'model.diffusion_model._orig_mod.middle_block.2.in_layers.1.weight', 'model.diffusion_model._orig_mod.middle_block.2.in_layers.1.bias', 'model.diffusion_model._orig_mod.middle_block.2.emb_layers.1.weight', 'model.diffusion_model._orig_mod.middle_block.2.emb_layers.1.bias', 'model.diffusion_model._orig_mod.middle_block.2.out_layers.0.weight', 'model.diffusion_model._orig_mod.middle_block.2.out_layers.0.bias', 'model.diffusion_model._orig_mod.middle_block.2.out_layers.2.weight', 'model.diffusion_model._orig_mod.middle_block.2.out_layers.2.bias', 'model.diffusion_model._orig_mod.output_blocks.0.0.in_layers.0.weight', 'model.diffusion_model._orig_mod.output_blocks.0.0.in_layers.0.bias', 'model.diffusion_model._orig_mod.output_blocks.0.0.in_layers.1.weight', '
0: model.diffusion_model._orig_mod.output_blocks.0.0.in_layers.1.bias', 'model.diffusion_model._orig_mod.output_blocks.0.0.emb_layers.1.weight', 'model.diffusion_model._orig_mod.output_blocks.0.0.emb_layers.1.bias', 'model.diffusion_model._orig_mod.output_blocks.0.0.out_layers.0.weight', 'model.diffusion_model._orig_mod.output_blocks.0.0.out_layers.0.bias', 'model.diffusion_model._orig_mod.output_blocks.0.0.out_layers.2.weight', 'model.diffusion_model._orig_mod.output_blocks.0.0.out_layers.2.bias', 'model.diffusion_model._orig_mod.output_blocks.0.0.skip_connection.weight', 'model.diffusion_model._orig_mod.output_blocks.0.0.skip_connection.bias', 'model.diffusion_model._orig_mod.output_blocks.1.0.in_layers.0.weight', 'model.diffusion_model._orig_mod.output_blocks.1.0.in_layers.0.bias', 'model.diffusion_model._orig_mod.output_blocks.1.0.in_layers.1.weight', 'model.diffusion_model._orig_mod.output_blocks.1.0.in_layers.1.bias', 'model.diffusion_model._orig_mod.output_blocks.1.0.emb_layers.1.weight', 'model.diffusion
0: _model._orig_mod.output_blocks.1.0.emb_layers.1.bias', 'model.diffusion_model._orig_mod.output_blocks.1.0.out_layers.0.weight', 'model.diffusion_model._orig_mod.output_blocks.1.0.out_layers.0.bias', 'model.diffusion_model._orig_mod.output_blocks.1.0.out_layers.2.weight', 'model.diffusion_model._orig_mod.output_blocks.1.0.out_layers.2.bias', 'model.diffusion_model._orig_mod.output_blocks.1.0.skip_connection.weight', 'model.diffusion_model._orig_mod.output_blocks.1.0.skip_connection.bias', 'model.diffusion_model._orig_mod.output_blocks.2.0.in_layers.0.weight', 'model.diffusion_model._orig_mod.output_blocks.2.0.in_layers.0.bias', 'model.diffusion_model._orig_mod.output_blocks.2.0.in_layers.1.weight', 'model.diffusion_model._orig_mod.output_blocks.2.0.in_layers.1.bias', 'model.diffusion_model._orig_mod.output_blocks.2.0.emb_layers.1.weight', 'model.diffusion_model._orig_mod.output_blocks.2.0.emb_layers.1.bias', 'model.diffusion_model._orig_mod.output_blocks.2.0.out_layers.0.weight', 'model.diffusion_model._orig_m
0: od.output_blocks.2.0.out_layers.0.bias', 'model.diffusion_model._orig_mod.output_blocks.2.0.out_layers.2.weight', 'model.diffusion_model._orig_mod.output_blocks.2.0.out_layers.2.bias', 'model.diffusion_model._orig_mod.output_blocks.2.0.skip_connection.weight', 'model.diffusion_model._orig_mod.output_blocks.2.0.skip_connection.bias', 'model.diffusion_model._orig_mod.output_blocks.2.1.conv.weight', 'model.diffusion_model._orig_mod.output_blocks.2.1.conv.bias', 'model.diffusion_model._orig_mod.output_blocks.3.0.in_layers.0.weight', 'model.diffusion_model._orig_mod.output_blocks.3.0.in_layers.0.bias', 'model.diffusion_model._orig_mod.output_blocks.3.0.in_layers.1.weight', 'model.diffusion_model._orig_mod.output_blocks.3.0.in_layers.1.bias', 'model.diffusion_model._orig_mod.output_blocks.3.0.emb_layers.1.weight', 'model.diffusion_model._orig_mod.output_blocks.3.0.emb_layers.1.bias', 'model.diffusion_model._orig_mod.output_blocks.3.0.out_layers.0.weight', 'model.diffusion_model._orig_mod.output_blocks.3.0.out_layer
0: s.0.bias', 'model.diffusion_model._orig_mod.output_blocks.3.0.out_layers.2.weight', 'model.diffusion_model._orig_mod.output_blocks.3.0.out_layers.2.bias', 'model.diffusion_model._orig_mod.output_blocks.3.0.skip_connection.weight', 'model.diffusion_model._orig_mod.output_blocks.3.0.skip_connection.bias', 'model.diffusion_model._orig_mod.output_blocks.3.1.norm.weight', 'model.diffusion_model._orig_mod.output_blocks.3.1.norm.bias', 'model.diffusion_model._orig_mod.output_blocks.3.1.proj_in.weight', 'model.diffusion_model._orig_mod.output_blocks.3.1.proj_in.bias', 'model.diffusion_model._orig_mod.output_blocks.3.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model._orig_mod.output_blocks.3.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model._orig_mod.output_blocks.3.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model._orig_mod.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model._orig_mod.output_blocks.3.1.transformer_blocks.0.attn1.to_out.
0: 0.bias', 'model.diffusion_model._orig_mod.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model._orig_mod.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model._orig_mod.output_blocks.3.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model._orig_mod.output_blocks.3.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model._orig_mod.output_blocks.3.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model._orig_mod.output_blocks.3.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model._orig_mod.output_blocks.3.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model._orig_mod.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model._orig_mod.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model._orig_mod.output_blocks.3.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model._orig_mod.output_blocks.3.1.transformer_blocks.0.norm1.bias', 'model.diff
0: usion_model._orig_mod.output_blocks.3.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model._orig_mod.output_blocks.3.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model._orig_mod.output_blocks.3.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model._orig_mod.output_blocks.3.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model._orig_mod.output_blocks.3.1.proj_out.weight', 'model.diffusion_model._orig_mod.output_blocks.3.1.proj_out.bias', 'model.diffusion_model._orig_mod.output_blocks.4.0.in_layers.0.weight', 'model.diffusion_model._orig_mod.output_blocks.4.0.in_layers.0.bias', 'model.diffusion_model._orig_mod.output_blocks.4.0.in_layers.1.weight', 'model.diffusion_model._orig_mod.output_blocks.4.0.in_layers.1.bias', 'model.diffusion_model._orig_mod.output_blocks.4.0.emb_layers.1.weight', 'model.diffusion_model._orig_mod.output_blocks.4.0.emb_layers.1.bias', 'model.diffusion_model._orig_mod.output_blocks.4.0.out_layers.0.weight', 'model.diffusion_model._orig_mod.output_blocks.4.0.out
0: _layers.0.bias', 'model.diffusion_model._orig_mod.output_blocks.4.0.out_layers.2.weight', 'model.diffusion_model._orig_mod.output_blocks.4.0.out_layers.2.bias', 'model.diffusion_model._orig_mod.output_blocks.4.0.skip_connection.weight', 'model.diffusion_model._orig_mod.output_blocks.4.0.skip_connection.bias', 'model.diffusion_model._orig_mod.output_blocks.4.1.norm.weight', 'model.diffusion_model._orig_mod.output_blocks.4.1.norm.bias', 'model.diffusion_model._orig_mod.output_blocks.4.1.proj_in.weight', 'model.diffusion_model._orig_mod.output_blocks.4.1.proj_in.bias', 'model.diffusion_model._orig_mod.output_blocks.4.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model._orig_mod.output_blocks.4.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model._orig_mod.output_blocks.4.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model._orig_mod.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model._orig_mod.output_blocks.4.1.transformer_blocks.0.attn1.t
0: o_out.0.bias', 'model.diffusion_model._orig_mod.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model._orig_mod.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model._orig_mod.output_blocks.4.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model._orig_mod.output_blocks.4.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model._orig_mod.output_blocks.4.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model._orig_mod.output_blocks.4.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model._orig_mod.output_blocks.4.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model._orig_mod.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model._orig_mod.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model._orig_mod.output_blocks.4.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model._orig_mod.output_blocks.4.1.transformer_blocks.0.norm1.bias', 'mode
0: l.diffusion_model._orig_mod.output_blocks.4.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model._orig_mod.output_blocks.4.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model._orig_mod.output_blocks.4.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model._orig_mod.output_blocks.4.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model._orig_mod.output_blocks.4.1.proj_out.weight', 'model.diffusion_model._orig_mod.output_blocks.4.1.proj_out.bias', 'model.diffusion_model._orig_mod.output_blocks.5.0.in_layers.0.weight', 'model.diffusion_model._orig_mod.output_blocks.5.0.in_layers.0.bias', 'model.diffusion_model._orig_mod.output_blocks.5.0.in_layers.1.weight', 'model.diffusion_model._orig_mod.output_blocks.5.0.in_layers.1.bias', 'model.diffusion_model._orig_mod.output_blocks.5.0.emb_layers.1.weight', 'model.diffusion_model._orig_mod.output_blocks.5.0.emb_layers.1.bias', 'model.diffusion_model._orig_mod.output_blocks.5.0.out_layers.0.weight', 'model.diffusion_model._orig_mod.output_blocks.5
0: .0.out_layers.0.bias', 'model.diffusion_model._orig_mod.output_blocks.5.0.out_layers.2.weight', 'model.diffusion_model._orig_mod.output_blocks.5.0.out_layers.2.bias', 'model.diffusion_model._orig_mod.output_blocks.5.0.skip_connection.weight', 'model.diffusion_model._orig_mod.output_blocks.5.0.skip_connection.bias', 'model.diffusion_model._orig_mod.output_blocks.5.1.norm.weight', 'model.diffusion_model._orig_mod.output_blocks.5.1.norm.bias', 'model.diffusion_model._orig_mod.output_blocks.5.1.proj_in.weight', 'model.diffusion_model._orig_mod.output_blocks.5.1.proj_in.bias', 'model.diffusion_model._orig_mod.output_blocks.5.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model._orig_mod.output_blocks.5.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model._orig_mod.output_blocks.5.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model._orig_mod.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model._orig_mod.output_blocks.5.1.transformer_blocks.0.a
0: ttn1.to_out.0.bias', 'model.diffusion_model._orig_mod.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model._orig_mod.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model._orig_mod.output_blocks.5.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model._orig_mod.output_blocks.5.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model._orig_mod.output_blocks.5.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model._orig_mod.output_blocks.5.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model._orig_mod.output_blocks.5.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model._orig_mod.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model._orig_mod.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model._orig_mod.output_blocks.5.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model._orig_mod.output_blocks.5.1.transformer_blocks.0.norm1.bias',
0:  'model.diffusion_model._orig_mod.output_blocks.5.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model._orig_mod.output_blocks.5.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model._orig_mod.output_blocks.5.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model._orig_mod.output_blocks.5.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model._orig_mod.output_blocks.5.1.proj_out.weight', 'model.diffusion_model._orig_mod.output_blocks.5.1.proj_out.bias', 'model.diffusion_model._orig_mod.output_blocks.5.2.conv.weight', 'model.diffusion_model._orig_mod.output_blocks.5.2.conv.bias', 'model.diffusion_model._orig_mod.output_blocks.6.0.in_layers.0.weight', 'model.diffusion_model._orig_mod.output_blocks.6.0.in_layers.0.bias', 'model.diffusion_model._orig_mod.output_blocks.6.0.in_layers.1.weight', 'model.diffusion_model._orig_mod.output_blocks.6.0.in_layers.1.bias', 'model.diffusion_model._orig_mod.output_blocks.6.0.emb_layers.1.weight', 'model.diffusion_model._orig_mod.output_blocks.6.0.emb_lay
0: ers.1.bias', 'model.diffusion_model._orig_mod.output_blocks.6.0.out_layers.0.weight', 'model.diffusion_model._orig_mod.output_blocks.6.0.out_layers.0.bias', 'model.diffusion_model._orig_mod.output_blocks.6.0.out_layers.2.weight', 'model.diffusion_model._orig_mod.output_blocks.6.0.out_layers.2.bias', 'model.diffusion_model._orig_mod.output_blocks.6.0.skip_connection.weight', 'model.diffusion_model._orig_mod.output_blocks.6.0.skip_connection.bias', 'model.diffusion_model._orig_mod.output_blocks.6.1.norm.weight', 'model.diffusion_model._orig_mod.output_blocks.6.1.norm.bias', 'model.diffusion_model._orig_mod.output_blocks.6.1.proj_in.weight', 'model.diffusion_model._orig_mod.output_blocks.6.1.proj_in.bias', 'model.diffusion_model._orig_mod.output_blocks.6.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model._orig_mod.output_blocks.6.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model._orig_mod.output_blocks.6.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model._orig_mod.ou
0: tput_blocks.6.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model._orig_mod.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model._orig_mod.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model._orig_mod.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model._orig_mod.output_blocks.6.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model._orig_mod.output_blocks.6.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model._orig_mod.output_blocks.6.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model._orig_mod.output_blocks.6.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model._orig_mod.output_blocks.6.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model._orig_mod.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model._orig_mod.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model._orig_mod.outp
0: ut_blocks.6.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model._orig_mod.output_blocks.6.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model._orig_mod.output_blocks.6.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model._orig_mod.output_blocks.6.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model._orig_mod.output_blocks.6.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model._orig_mod.output_blocks.6.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model._orig_mod.output_blocks.6.1.proj_out.weight', 'model.diffusion_model._orig_mod.output_blocks.6.1.proj_out.bias', 'model.diffusion_model._orig_mod.output_blocks.7.0.in_layers.0.weight', 'model.diffusion_model._orig_mod.output_blocks.7.0.in_layers.0.bias', 'model.diffusion_model._orig_mod.output_blocks.7.0.in_layers.1.weight', 'model.diffusion_model._orig_mod.output_blocks.7.0.in_layers.1.bias', 'model.diffusion_model._orig_mod.output_blocks.7.0.emb_layers.1.weight', 'model.diffusion_model._orig_mod.output_blocks.7.0.e
0: mb_layers.1.bias', 'model.diffusion_model._orig_mod.output_blocks.7.0.out_layers.0.weight', 'model.diffusion_model._orig_mod.output_blocks.7.0.out_layers.0.bias', 'model.diffusion_model._orig_mod.output_blocks.7.0.out_layers.2.weight', 'model.diffusion_model._orig_mod.output_blocks.7.0.out_layers.2.bias', 'model.diffusion_model._orig_mod.output_blocks.7.0.skip_connection.weight', 'model.diffusion_model._orig_mod.output_blocks.7.0.skip_connection.bias', 'model.diffusion_model._orig_mod.output_blocks.7.1.norm.weight', 'model.diffusion_model._orig_mod.output_blocks.7.1.norm.bias', 'model.diffusion_model._orig_mod.output_blocks.7.1.proj_in.weight', 'model.diffusion_model._orig_mod.output_blocks.7.1.proj_in.bias', 'model.diffusion_model._orig_mod.output_blocks.7.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model._orig_mod.output_blocks.7.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model._orig_mod.output_blocks.7.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model._orig_
0: mod.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model._orig_mod.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model._orig_mod.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model._orig_mod.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model._orig_mod.output_blocks.7.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model._orig_mod.output_blocks.7.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model._orig_mod.output_blocks.7.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model._orig_mod.output_blocks.7.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model._orig_mod.output_blocks.7.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model._orig_mod.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model._orig_mod.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model._orig_mo
0: d.output_blocks.7.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model._orig_mod.output_blocks.7.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model._orig_mod.output_blocks.7.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model._orig_mod.output_blocks.7.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model._orig_mod.output_blocks.7.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model._orig_mod.output_blocks.7.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model._orig_mod.output_blocks.7.1.proj_out.weight', 'model.diffusion_model._orig_mod.output_blocks.7.1.proj_out.bias', 'model.diffusion_model._orig_mod.output_blocks.8.0.in_layers.0.weight', 'model.diffusion_model._orig_mod.output_blocks.8.0.in_layers.0.bias', 'model.diffusion_model._orig_mod.output_blocks.8.0.in_layers.1.weight', 'model.diffusion_model._orig_mod.output_blocks.8.0.in_layers.1.bias', 'model.diffusion_model._orig_mod.output_blocks.8.0.emb_layers.1.weight', 'model.diffusion_model._orig_mod.output_blocks
0: .8.0.emb_layers.1.bias', 'model.diffusion_model._orig_mod.output_blocks.8.0.out_layers.0.weight', 'model.diffusion_model._orig_mod.output_blocks.8.0.out_layers.0.bias', 'model.diffusion_model._orig_mod.output_blocks.8.0.out_layers.2.weight', 'model.diffusion_model._orig_mod.output_blocks.8.0.out_layers.2.bias', 'model.diffusion_model._orig_mod.output_blocks.8.0.skip_connection.weight', 'model.diffusion_model._orig_mod.output_blocks.8.0.skip_connection.bias', 'model.diffusion_model._orig_mod.output_blocks.8.1.norm.weight', 'model.diffusion_model._orig_mod.output_blocks.8.1.norm.bias', 'model.diffusion_model._orig_mod.output_blocks.8.1.proj_in.weight', 'model.diffusion_model._orig_mod.output_blocks.8.1.proj_in.bias', 'model.diffusion_model._orig_mod.output_blocks.8.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model._orig_mod.output_blocks.8.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model._orig_mod.output_blocks.8.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.
0: _orig_mod.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model._orig_mod.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model._orig_mod.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model._orig_mod.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model._orig_mod.output_blocks.8.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model._orig_mod.output_blocks.8.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model._orig_mod.output_blocks.8.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model._orig_mod.output_blocks.8.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model._orig_mod.output_blocks.8.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model._orig_mod.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model._orig_mod.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model._o
0: rig_mod.output_blocks.8.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model._orig_mod.output_blocks.8.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model._orig_mod.output_blocks.8.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model._orig_mod.output_blocks.8.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model._orig_mod.output_blocks.8.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model._orig_mod.output_blocks.8.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model._orig_mod.output_blocks.8.1.proj_out.weight', 'model.diffusion_model._orig_mod.output_blocks.8.1.proj_out.bias', 'model.diffusion_model._orig_mod.output_blocks.8.2.conv.weight', 'model.diffusion_model._orig_mod.output_blocks.8.2.conv.bias', 'model.diffusion_model._orig_mod.output_blocks.9.0.in_layers.0.weight', 'model.diffusion_model._orig_mod.output_blocks.9.0.in_layers.0.bias', 'model.diffusion_model._orig_mod.output_blocks.9.0.in_layers.1.weight', 'model.diffusion_model._orig_mod.output_blocks.9.0.in_l
0: ayers.1.bias', 'model.diffusion_model._orig_mod.output_blocks.9.0.emb_layers.1.weight', 'model.diffusion_model._orig_mod.output_blocks.9.0.emb_layers.1.bias', 'model.diffusion_model._orig_mod.output_blocks.9.0.out_layers.0.weight', 'model.diffusion_model._orig_mod.output_blocks.9.0.out_layers.0.bias', 'model.diffusion_model._orig_mod.output_blocks.9.0.out_layers.2.weight', 'model.diffusion_model._orig_mod.output_blocks.9.0.out_layers.2.bias', 'model.diffusion_model._orig_mod.output_blocks.9.0.skip_connection.weight', 'model.diffusion_model._orig_mod.output_blocks.9.0.skip_connection.bias', 'model.diffusion_model._orig_mod.output_blocks.9.1.norm.weight', 'model.diffusion_model._orig_mod.output_blocks.9.1.norm.bias', 'model.diffusion_model._orig_mod.output_blocks.9.1.proj_in.weight', 'model.diffusion_model._orig_mod.output_blocks.9.1.proj_in.bias', 'model.diffusion_model._orig_mod.output_blocks.9.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model._orig_mod.output_blocks.9.1.transformer_blocks.0.a
0: ttn1.to_k.weight', 'model.diffusion_model._orig_mod.output_blocks.9.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model._orig_mod.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model._orig_mod.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model._orig_mod.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model._orig_mod.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model._orig_mod.output_blocks.9.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model._orig_mod.output_blocks.9.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model._orig_mod.output_blocks.9.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model._orig_mod.output_blocks.9.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model._orig_mod.output_blocks.9.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model._orig_mod.output_blocks.9.1.transformer_blocks.0.attn2.to_
0: out.0.weight', 'model.diffusion_model._orig_mod.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model._orig_mod.output_blocks.9.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model._orig_mod.output_blocks.9.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model._orig_mod.output_blocks.9.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model._orig_mod.output_blocks.9.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model._orig_mod.output_blocks.9.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model._orig_mod.output_blocks.9.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model._orig_mod.output_blocks.9.1.proj_out.weight', 'model.diffusion_model._orig_mod.output_blocks.9.1.proj_out.bias', 'model.diffusion_model._orig_mod.output_blocks.10.0.in_layers.0.weight', 'model.diffusion_model._orig_mod.output_blocks.10.0.in_layers.0.bias', 'model.diffusion_model._orig_mod.output_blocks.10.0.in_layers.1.weight', 'model.diffusion_model._orig_mod.output_blocks
0: .10.0.in_layers.1.bias', 'model.diffusion_model._orig_mod.output_blocks.10.0.emb_layers.1.weight', 'model.diffusion_model._orig_mod.output_blocks.10.0.emb_layers.1.bias', 'model.diffusion_model._orig_mod.output_blocks.10.0.out_layers.0.weight', 'model.diffusion_model._orig_mod.output_blocks.10.0.out_layers.0.bias', 'model.diffusion_model._orig_mod.output_blocks.10.0.out_layers.2.weight', 'model.diffusion_model._orig_mod.output_blocks.10.0.out_layers.2.bias', 'model.diffusion_model._orig_mod.output_blocks.10.0.skip_connection.weight', 'model.diffusion_model._orig_mod.output_blocks.10.0.skip_connection.bias', 'model.diffusion_model._orig_mod.output_blocks.10.1.norm.weight', 'model.diffusion_model._orig_mod.output_blocks.10.1.norm.bias', 'model.diffusion_model._orig_mod.output_blocks.10.1.proj_in.weight', 'model.diffusion_model._orig_mod.output_blocks.10.1.proj_in.bias', 'model.diffusion_model._orig_mod.output_blocks.10.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model._orig_mod.output_blocks.10.
0: 1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model._orig_mod.output_blocks.10.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model._orig_mod.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model._orig_mod.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model._orig_mod.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model._orig_mod.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model._orig_mod.output_blocks.10.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model._orig_mod.output_blocks.10.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model._orig_mod.output_blocks.10.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model._orig_mod.output_blocks.10.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model._orig_mod.output_blocks.10.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model._orig_mod.output_blocks.
0: 10.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model._orig_mod.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model._orig_mod.output_blocks.10.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model._orig_mod.output_blocks.10.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model._orig_mod.output_blocks.10.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model._orig_mod.output_blocks.10.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model._orig_mod.output_blocks.10.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model._orig_mod.output_blocks.10.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model._orig_mod.output_blocks.10.1.proj_out.weight', 'model.diffusion_model._orig_mod.output_blocks.10.1.proj_out.bias', 'model.diffusion_model._orig_mod.output_blocks.11.0.in_layers.0.weight', 'model.diffusion_model._orig_mod.output_blocks.11.0.in_layers.0.bias', 'model.diffusion_model._orig_mod.output_blocks.11.0.in_layers.1.weight', 'm
0: odel.diffusion_model._orig_mod.output_blocks.11.0.in_layers.1.bias', 'model.diffusion_model._orig_mod.output_blocks.11.0.emb_layers.1.weight', 'model.diffusion_model._orig_mod.output_blocks.11.0.emb_layers.1.bias', 'model.diffusion_model._orig_mod.output_blocks.11.0.out_layers.0.weight', 'model.diffusion_model._orig_mod.output_blocks.11.0.out_layers.0.bias', 'model.diffusion_model._orig_mod.output_blocks.11.0.out_layers.2.weight', 'model.diffusion_model._orig_mod.output_blocks.11.0.out_layers.2.bias', 'model.diffusion_model._orig_mod.output_blocks.11.0.skip_connection.weight', 'model.diffusion_model._orig_mod.output_blocks.11.0.skip_connection.bias', 'model.diffusion_model._orig_mod.output_blocks.11.1.norm.weight', 'model.diffusion_model._orig_mod.output_blocks.11.1.norm.bias', 'model.diffusion_model._orig_mod.output_blocks.11.1.proj_in.weight', 'model.diffusion_model._orig_mod.output_blocks.11.1.proj_in.bias', 'model.diffusion_model._orig_mod.output_blocks.11.1.transformer_blocks.0.attn1.to_q.weight', 'model
0: .diffusion_model._orig_mod.output_blocks.11.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model._orig_mod.output_blocks.11.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model._orig_mod.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model._orig_mod.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model._orig_mod.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model._orig_mod.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model._orig_mod.output_blocks.11.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model._orig_mod.output_blocks.11.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model._orig_mod.output_blocks.11.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model._orig_mod.output_blocks.11.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model._orig_mod.output_blocks.11.1.transformer_blocks.0.attn2.to_v.weight', 'mo
0: del.diffusion_model._orig_mod.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model._orig_mod.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model._orig_mod.output_blocks.11.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model._orig_mod.output_blocks.11.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model._orig_mod.output_blocks.11.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model._orig_mod.output_blocks.11.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model._orig_mod.output_blocks.11.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model._orig_mod.output_blocks.11.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model._orig_mod.output_blocks.11.1.proj_out.weight', 'model.diffusion_model._orig_mod.output_blocks.11.1.proj_out.bias', 'model.diffusion_model._orig_mod.out.0.weight', 'model.diffusion_model._orig_mod.out.0.bias', 'model.diffusion_model._orig_mod.out.1.weight', 'model.diffusion_model._orig_mod.
0: out.1.bias']
0: [NeMo I 2024-05-04 03:52:35 ddpm:305] Unexpected Keys: ['model_ema.decay', 'model_ema.num_updates']
3: [rank: 3] Seed set to 4095906737
3: Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4
2: [rank: 2] Seed set to 3951582245
2: Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4
1: [rank: 1] Seed set to 3661889204
1: Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4
0: [NeMo W 2024-05-04 03:56:41 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/configuration_validator.py:181: You have overridden `MegatronLatentDiffusion.configure_sharded_model` which is deprecated. Please override the `configure_model` hook instead. Instantiation with the newer hook will be created on the device right away and have the right data type depending on the precision setting in the Trainer.
0:     
0: [NeMo W 2024-05-04 03:56:41 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/configuration_validator.py:163: You are using the `dataloader_iter` step flavor. If you consume the iterator more than once per step, the `batch_idx` argument in any hook that takes it will not match with the batch index of the last batch consumed. This might have unforeseen effects on callbacks or code that expects to get the correct index. This will also not work well with gradient accumulation. This feature is very experimental and subject to change. Here be dragons.
0:     
0: [rank: 0] Seed set to 1228225332
0: Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4
0: ----------------------------------------------------------------------------------------------------
0: distributed_backend=nccl
0: All distributed processes registered. Starting with 4 processes
0: ----------------------------------------------------------------------------------------------------
0: 
0: [NeMo I 2024-05-04 03:56:41 main:191] Warmup allreduce with communicator at 7ef7c964b2b0, size 1
0: [NeMo I 2024-05-04 03:57:04 ddpm:1977] Pipeline model parallel rank: 0, Tensor model parallel rank: 0, Number of model parameters on device: 8.66e+08. Total number of model parameters: 8.66e+08.
0: [NeMo I 2024-05-04 03:57:04 ddpm:2005] Building datasets for Stable Diffusion...
0: [NeMo I 2024-05-04 03:57:04 webdataset:145] Read Webdataset locally. Data stores at /datasets/laion-400m/webdataset-moments-filtered-encoded
0: [NeMo I 2024-05-04 03:57:04 webdataset:221] Setting nbatches=13000 for infinite sampler. world_size=4
0: [NeMo I 2024-05-04 03:57:04 webdataset:224] Total number of training shards: 832
0: [NeMo I 2024-05-04 03:57:04 webdataset:225] Total training key count: 832000
0: [NeMo I 2024-05-04 03:57:04 ddpm:2025] Length of train dataset: 832000
0: [NeMo I 2024-05-04 03:57:04 ddpm:2030] Finished building datasets for LatentDiffusion.
0: [NeMo I 2024-05-04 03:57:04 ddpm:2036] Setting up train dataloader with len(len(self._train_ds)): 832000 and consumed samples: 0
1: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
2: LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
3: LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
0: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
0: [NeMo I 2024-05-04 03:57:04 modelPT:724] Optimizer config = MegatronDistributedFusedAdam (
0:     Parameter Group 0
0:         betas: [0.9, 0.999]
0:         bias_correction: True
0:         eps: 1e-08
0:         lr: 2.5600000299164094e-05
0:         weight_decay: 0.0
0:     adam_w_mode: True
0:     amsgrad: False
0:     dtype: torch.float32
0:     grad_sync_dtype: torch.float16
0:     param_sync_dtype: torch.float16
0:     device: cuda:0
0:     process_group: 0x7ef7c964bef0, world size 4
0:     distributed_process_group: 0x7ef8fc1fd230, world size 4
0:     redundant_process_group: 0x7ef7c964b2b0, world size 1
0:     average_grad_sync: True
0:     overlap_grad_sync: True
0:     overlap_param_sync: False
0:     bucket_cap_mb: 288
0:     pipeline_size: 2
0:     contiguous_param_buffer: True
0:     contiguous_grad_buffer: True
0:     store_params: True
0:     store_param_remainders: False
0:     with_scaled_states: False
0:     nccl_ub: False
0:     capturable: True
0:     )
0: [NeMo I 2024-05-04 03:57:04 lr_scheduler:923] Scheduler "<nemo.core.optim.lr_scheduler.WarmupHoldPolicy object at 0x7ef7c8cc1c60>" 
0:     will be used during training (effective maximum steps = 12000) - 
0:     Parameters : 
0:     (warmup_steps: 1000
0:     hold_steps: 10000000000000
0:     max_steps: 12000
0:     )
0: :::MLLOG {"namespace": "", "time_ms": 1714762624649, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 78}}
0: :::MLLOG {"namespace": "", "time_ms": 1714762624650, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 256, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 82}}
0: :::MLLOG {"namespace": "", "time_ms": 1714762624650, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "adamw", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 86}}
0: :::MLLOG {"namespace": "", "time_ms": 1714762624650, "event_type": "POINT_IN_TIME", "key": "opt_adamw_beta_1", "value": 0.9, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 87}}
0: :::MLLOG {"namespace": "", "time_ms": 1714762624650, "event_type": "POINT_IN_TIME", "key": "opt_adamw_beta_2", "value": 0.999, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 88}}
0: :::MLLOG {"namespace": "", "time_ms": 1714762624650, "event_type": "POINT_IN_TIME", "key": "opt_adamw_epsilon", "value": 1e-08, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 89}}
0: :::MLLOG {"namespace": "", "time_ms": 1714762624650, "event_type": "POINT_IN_TIME", "key": "opt_adamw_weight_decay", "value": 0.01, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 90}}
0: :::MLLOG {"namespace": "", "time_ms": 1714762624650, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 2.56e-05, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 92}}
0: :::MLLOG {"namespace": "", "time_ms": 1714762624650, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_steps", "value": 1000, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 93}}
0: :::MLLOG {"namespace": "", "time_ms": 1714762624650, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 6513144, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 98}}
0: :::MLLOG {"namespace": "", "time_ms": 1714762624651, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 30000, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 99}}
0: :::MLLOG {"namespace": "", "time_ms": 1714762624651, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "stable_diffusion", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 101}}
0: :::MLLOG {"namespace": "", "time_ms": 1714762624651, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "Fujitsu", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 101}}
0: :::MLLOG {"namespace": "", "time_ms": 1714762624651, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 101}}
0: :::MLLOG {"namespace": "", "time_ms": 1714762624651, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 101}}
0: :::MLLOG {"namespace": "", "time_ms": 1714762624651, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "GX2560M7_H100_SXM_80GBx4", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 101}}
0: :::MLLOG {"namespace": "", "time_ms": 1714762624651, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 105}}
0: :::MLLOG {"namespace": "", "time_ms": 1714762624652, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 105}}
0: 
0:   | Name  | Type            | Params
0: ------------------------------------------
0: 0 | model | LatentDiffusion | 865 M 
0: ------------------------------------------
0: 865 M     Trainable params
0: 0         Non-trainable params
0: 865 M     Total params
0: 3,463.643 Total estimated model params size (MB)
0: SLURM auto-requeueing enabled. Setting signal handlers.
1: SLURM auto-requeueing enabled. Setting signal handlers.
2: SLURM auto-requeueing enabled. Setting signal handlers.
3: SLURM auto-requeueing enabled. Setting signal handlers.
0: [NeMo W 2024-05-04 03:57:04 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:104: Total length of `list` across ranks is zero. Please make sure this was your intention.
0:     
0: [NeMo W 2024-05-04 03:57:04 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:121: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.
0:     
0: :::MLLOG {"namespace": "", "time_ms": 1714762641711, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 0}}
0: CUDAGraphCallback: disable autocast cache.
0: [NeMo W 2024-05-04 03:57:37 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
0:       warnings.warn(
0:     
0: [NeMo W 2024-05-04 03:57:37 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:213: You called `self.log('global_step', ...)` in your `optimizer_step` but the value needs to be floating to be reduced. Converting it to torch.float32. You can silence this warning by converting the value to floating point yourself. If you don't intend to reduce the value (for instance when logging the global step or epoch) then you can use `self.logger.log_metrics({'global_step': ...})` instead.
0:     
0: [NeMo W 2024-05-04 03:57:37 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:213: You called `self.log('consumed_samples', ...)` in your `optimizer_step` but the value needs to be floating to be reduced. Converting it to torch.float32. You can silence this warning by converting the value to floating point yourself. If you don't intend to reduce the value (for instance when logging the global step or epoch) then you can use `self.logger.log_metrics({'consumed_samples': ...})` instead.
0:     
0: CUDAGraphCallback: capturing CUDA graph for module MegatronLatentDiffusion.
0: CUDAGraphCallback: set optimizer.zero_grad as nop during graph capturing.
0: :::MLLOG {"namespace": "", "time_ms": 1714762707367, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 25600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714762708771, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 389.92236485464144, "loss": 1.120546406030864, "lr": 2.557442485340289e-06}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 100}}
0: :::MLLOG {"namespace": "", "time_ms": 1714762708772, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 25600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714762757666, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 51200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714762759077, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 523.5807797474332, "loss": 0.8624364385191903, "lr": 5.114884970680578e-06}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714762759079, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 51200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714762808150, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 76800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714762809565, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 521.685713436208, "loss": 0.6769133690853585, "lr": 7.672327228647191e-06}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 300}}
0: :::MLLOG {"namespace": "", "time_ms": 1714762809566, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 76800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714762858731, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 102400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714762860149, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 520.7022627471805, "loss": 0.553152193259982, "lr": 1.0229769941361155e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714762860150, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 102400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714762909342, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 128000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714762910757, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 520.4065073973035, "loss": 0.48366584294166187, "lr": 1.2787213563569821e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 500}}
0: :::MLLOG {"namespace": "", "time_ms": 1714762910758, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 128000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714762959966, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 153600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714762961388, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 520.2327852935182, "loss": 0.4477772477194932, "lr": 1.5344654457294382e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714762961389, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 153600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763010623, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 179200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763012044, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 519.9607454440389, "loss": 0.4278687243590081, "lr": 1.790209898899775e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 700}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763012045, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 179200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763061317, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 204800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763062734, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 519.5603472499572, "loss": 0.4078305775867333, "lr": 2.045953988272231e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763062735, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 204800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763112032, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 230400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763113451, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 519.300989267443, "loss": 0.4013669927514668, "lr": 2.3016982595436275e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 900}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763113452, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 230400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763162757, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 256000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763164177, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 519.2233795489724, "loss": 0.39252475346000637, "lr": 2.5574427127139643e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 1000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763164178, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 256000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763213582, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 281600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763215008, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 518.1711664713322, "loss": 0.38618526072554976, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 1100}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763215009, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 281600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763264442, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 307200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763265869, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 517.8651580775545, "loss": 0.38025470353387875, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 1200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763265870, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 307200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763315307, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 332800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763316730, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 517.8301696578579, "loss": 0.37239959344397283, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 1300}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763316731, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 332800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763366183, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 358400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763367608, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 517.6700568430355, "loss": 0.36929347622649883, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 1400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763367609, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 358400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763417044, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 384000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763418473, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 517.8451892143304, "loss": 0.3669416390918141, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 1500}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763418474, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 384000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763467942, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 409600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763469365, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 517.5140231630584, "loss": 0.36199866886536486, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 1600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763469366, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 409600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763518817, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 435200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763520244, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 517.6777850440944, "loss": 0.3604711115075936, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 1700}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763520246, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 435200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763569694, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 460800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763571117, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 517.7117554087538, "loss": 0.35709945321611486, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 1800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763571118, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 460800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763620601, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 486400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763622030, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 517.3484080618692, "loss": 0.35703216195702214, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 1900}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763622031, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 486400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763671495, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 512000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763672921, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 517.5471764968056, "loss": 0.35369990948790325, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 2000}}
0: Epoch 0, global step 2000: 'timestamp' reached 1714763671494.00000 (best 1714763671494.00000), saving model to '/tmp/nemologs/stable-diffusion2-train-240504035020273822643/checkpoints/stable-diffusion2-train-240504035020273822643--timestamp=1714763671494.0-step=2000-consumed_samples=512000.0.ckpt' as top 1
0: Saving /tmp/nemologs/stable-diffusion2-train-240504035020273822643/checkpoints/stable-diffusion2-train-240504035020273822643--timestamp=1714763671494.0-step=2000-consumed_samples=512000.0.ckpt in the background
0: :::MLLOG {"namespace": "", "time_ms": 1714763673069, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 512000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763722585, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 537600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763724016, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 517.0145074633172, "loss": 0.3513735926776703, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 2100}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763724017, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 537600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763773539, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 563200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763774967, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.9414438928616, "loss": 0.3503223384157219, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 2200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763774968, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 563200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763824499, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 588800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763825927, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.8477398846406, "loss": 0.34969627030674827, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 2300}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763825928, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 588800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763875463, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 614400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763876893, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.8112527866617, "loss": 0.34585960042323993, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 2400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763876894, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 614400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763926412, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 640000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763927842, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.9798555764395, "loss": 0.3482813228111321, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 2500}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763927843, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 640000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763977382, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 665600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763978813, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.7631941418209, "loss": 0.3429729045902905, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 2600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714763978814, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 665600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764028338, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 691200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764029768, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.9216295370913, "loss": 0.34525489461874015, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 2700}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764029769, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 691200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764079310, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 716800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764080739, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.7490877189724, "loss": 0.34932902940465893, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 2800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764080740, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 716800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764130292, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 742400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764131719, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.626136676217, "loss": 0.3419366420884461, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 2900}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764131719, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 742400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764181270, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 768000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764182700, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.6410244507724, "loss": 0.3425408519823063, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 3000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764182701, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 768000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764232279, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 793600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764233710, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.3578427024232, "loss": 0.3401871837929524, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 3100}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764233711, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 793600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764283282, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 819200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764284712, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.4317340648965, "loss": 0.3426086772990109, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 3200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764284713, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 819200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764339508, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 844800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764340939, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 467.1913003174895, "loss": 0.34132545129865954, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 3300}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764340941, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 844800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764390512, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 870400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764391938, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.4291321838826, "loss": 0.33808780332078214, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 3400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764391939, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 870400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764441520, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 896000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764442953, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.3228135190279, "loss": 0.339091373867387, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 3500}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764442954, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 896000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764492527, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 921600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764493955, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.4072550688596, "loss": 0.3387027706608239, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 3600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764493956, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 921600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764543537, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 947200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764544970, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.3304055299468, "loss": 0.341015507148927, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 3700}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764544971, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 947200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764594553, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 972800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764595980, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.3100154174984, "loss": 0.3383543743630383, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 3800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764595981, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 972800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764645560, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 998400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764646992, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.3477241223787, "loss": 0.33649726531178514, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 3900}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764646993, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 998400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764696588, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 1024000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764698020, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.181008792504, "loss": 0.33816753049283643, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 4000}}
0: Epoch 1, global step 4000: 'timestamp' reached 1714764696587.00000 (best 1714763671494.00000), saving model to '/tmp/nemologs/stable-diffusion2-train-240504035020273822643/checkpoints/stable-diffusion2-train-240504035020273822643--timestamp=1714764696587.0-step=4000-consumed_samples=1024000.0.ckpt' as top 2
0: Saving /tmp/nemologs/stable-diffusion2-train-240504035020273822643/checkpoints/stable-diffusion2-train-240504035020273822643--timestamp=1714764696587.0-step=4000-consumed_samples=1024000.0.ckpt in the background
0: :::MLLOG {"namespace": "", "time_ms": 1714764698297, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 1024000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764747928, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 1049600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764749359, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 515.8063609470811, "loss": 0.33686984678999293, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 4100}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764749360, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 1049600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764798987, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 1075200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764800419, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 515.8409520489103, "loss": 0.33534316681258397, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 4200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764800420, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 1075200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764850051, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 1100800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764851482, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 515.8045231913612, "loss": 0.334571987621077, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 4300}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764851483, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 1100800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764901096, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 1126400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764902528, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 515.988966148053, "loss": 0.3359696163912804, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 4400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764902528, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 1126400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764952126, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 1152000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764953554, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.1508816221132, "loss": 0.3347796597381409, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 4500}}
0: :::MLLOG {"namespace": "", "time_ms": 1714764953555, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 1152000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765003135, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 1177600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765004570, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.3356756458141, "loss": 0.33135295536566967, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 4600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765004571, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 1177600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765054161, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 1203200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765055593, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.229267100272, "loss": 0.337378384077388, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 4700}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765055594, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 1203200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765105180, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 1228800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765106612, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.2716842761024, "loss": 0.3338775601377869, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 4800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765106613, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 1228800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765156209, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 1254400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765157639, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.168421778056, "loss": 0.3319119992443566, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 4900}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765157640, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 1254400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765207251, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 1280000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765208683, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.0129228170117, "loss": 0.3328965344517964, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 5000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765208684, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 1280000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765258287, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 1305600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765259715, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.1044134011632, "loss": 0.3319845547856232, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 5100}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765259716, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 1305600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765309315, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 1331200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765310744, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.1331986600253, "loss": 0.3308745541863716, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 5200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765310745, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 1331200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765360354, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 1356800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765361785, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.0440307962998, "loss": 0.33284801150306287, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 5300}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765361786, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 1356800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765411405, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 1382400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765412834, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 515.9351329026882, "loss": 0.3331467404429467, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 5400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765412835, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 1382400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765462464, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 1408000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765463893, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 515.8236845833509, "loss": 0.32951614050366673, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 5500}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765463894, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 1408000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765513504, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 1433600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765514933, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.0250209646655, "loss": 0.33146293308673785, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 5600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765514934, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 1433600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765564545, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 1459200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765565975, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.0188009666986, "loss": 0.33128638889905015, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 5700}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765565976, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 1459200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765615602, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 1484800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765617032, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 515.8637868722068, "loss": 0.33082599309066585, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 5800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765617033, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 1484800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765666619, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 1510400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765668048, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.2693639303526, "loss": 0.33003253606735045, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 5900}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765668049, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 1510400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765717625, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 1536000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765719049, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.3831667562221, "loss": 0.32687240273713536, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 6000}}
0: Epoch 1, global step 6000: 'timestamp' reached 1714765717624.00000 (best 1714763671494.00000), saving model to '/tmp/nemologs/stable-diffusion2-train-240504035020273822643/checkpoints/stable-diffusion2-train-240504035020273822643--timestamp=1714765717624.0-step=6000-consumed_samples=1536000.0.ckpt' as top 3
0: Saving /tmp/nemologs/stable-diffusion2-train-240504035020273822643/checkpoints/stable-diffusion2-train-240504035020273822643--timestamp=1714765717624.0-step=6000-consumed_samples=1536000.0.ckpt in the background
0: :::MLLOG {"namespace": "", "time_ms": 1714765719332, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 1536000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765769084, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 1561600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765770521, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 514.5533976753653, "loss": 0.32846126227935224, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 6100}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765770522, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 1561600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765820268, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 1587200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765821710, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 514.6087665737231, "loss": 0.3273578229593319, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 6200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765821711, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 1587200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765871469, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 1612800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765872907, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 514.490048094375, "loss": 0.3263848462844914, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 6300}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765872908, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 1612800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765922682, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 1638400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765924117, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 514.3217525824737, "loss": 0.3271027341557305, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 6400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765924118, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 1638400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765975726, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 1664000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765977760, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 496.04413241026157, "loss": 0.3272111478509354, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 6500}}
0: :::MLLOG {"namespace": "", "time_ms": 1714765977762, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 1664000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766027403, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 1689600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766028832, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 515.7009856135779, "loss": 0.32824332862674643, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 6600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766028833, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 1689600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766078412, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 1715200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766079842, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.3527308458647, "loss": 0.3270836225226208, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 6700}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766079843, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 1715200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766129420, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 1740800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766130851, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.366285992759, "loss": 0.32810073524438327, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 6800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766130852, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 1740800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766180443, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 1766400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766181873, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.2235029595972, "loss": 0.3278098645807881, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 6900}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766181874, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 1766400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766231452, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 1792000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766232885, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.3528966192396, "loss": 0.32441013011771513, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 7000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766232886, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 1792000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766282453, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 1817600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766283881, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.4718938846185, "loss": 0.3269313398092999, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 7100}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766283882, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 1817600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766333478, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 1843200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766334908, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.1739179302654, "loss": 0.3257422605365227, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 7200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766334910, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 1843200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766384478, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 1868800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766385910, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.4539386370889, "loss": 0.3258588376837944, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 7300}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766385911, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 1868800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766435501, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 1894400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766436930, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.2289431036997, "loss": 0.3264735761420025, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 7400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766436931, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 1894400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766486525, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 1920000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766487954, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.1928483785799, "loss": 0.32456767711320994, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 7500}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766487955, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 1920000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766537546, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 1945600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766538975, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.2148055213607, "loss": 0.32608832986899955, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 7600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766538976, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 1945600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766588551, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 1971200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766589980, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.3860283706707, "loss": 0.3252059141063393, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 7700}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766589981, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 1971200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766639581, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 1996800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766641008, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.129819106245, "loss": 0.325555302225404, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 7800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766641009, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 1996800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766690608, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 2022400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766692040, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.1335257727314, "loss": 0.3243687787997693, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 7900}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766692040, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 2022400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766741637, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 2048000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766743066, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.160844281191, "loss": 0.32367995892140355, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 8000}}
0: Epoch 2, global step 8000: 'timestamp' reached 1714766741636.00000 (best 1714763671494.00000), saving model to '/tmp/nemologs/stable-diffusion2-train-240504035020273822643/checkpoints/stable-diffusion2-train-240504035020273822643--timestamp=1714766741636.0-step=8000-consumed_samples=2048000.0.ckpt' as top 4
0: Saving /tmp/nemologs/stable-diffusion2-train-240504035020273822643/checkpoints/stable-diffusion2-train-240504035020273822643--timestamp=1714766741636.0-step=8000-consumed_samples=2048000.0.ckpt in the background
0: :::MLLOG {"namespace": "", "time_ms": 1714766743360, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 2048000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766792981, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 2073600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766794410, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 515.9040158433558, "loss": 0.32753402382426916, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 8100}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766794411, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 2073600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766844005, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 2099200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766845437, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.193617216967, "loss": 0.3222882429319027, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 8200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766845438, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 2099200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766895030, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 2124800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766896463, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.2139261671766, "loss": 0.3253624311335827, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 8300}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766896464, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 2124800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766946074, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 2150400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766947502, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.0245891204794, "loss": 0.32337112103386695, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 8400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766947503, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 2150400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766997099, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 2176000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766998530, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.1739487472249, "loss": 0.3259761396235394, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 8500}}
0: :::MLLOG {"namespace": "", "time_ms": 1714766998530, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 2176000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767048126, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 2201600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767049553, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.1725389427124, "loss": 0.3258765760259022, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 8600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767049554, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 2201600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767099154, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 2227200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767100586, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.1327253230799, "loss": 0.32310016308979916, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 8700}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767100587, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 2227200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767150187, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 2252800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767151614, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.1292961187354, "loss": 0.3229899564868973, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 8800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767151615, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 2252800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767201207, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 2278400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767202634, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.2165880450019, "loss": 0.3210982099848187, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 8900}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767202635, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 2278400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767252238, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 2304000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767253670, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.1014220077473, "loss": 0.3232676664450577, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 9000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767253670, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 2304000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767303290, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 2329600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767304719, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 515.9243701677793, "loss": 0.32250602399661943, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 9100}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767304720, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 2329600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767354327, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 2355200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767355758, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.0530308704363, "loss": 0.31911004701031553, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 9200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767355759, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 2355200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767405363, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 2380800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767406792, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.0877631128317, "loss": 0.3227125898514874, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 9300}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767406793, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 2380800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767456384, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 2406400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767457814, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.2232475802409, "loss": 0.3224510542095715, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 9400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767457815, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 2406400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767507432, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 2432000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767508865, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 515.9471753169976, "loss": 0.32076640761997266, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 9500}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767508866, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 2432000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767558464, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 2457600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767559895, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.1511248269749, "loss": 0.3210166899050675, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 9600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767559896, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 2457600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767609473, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 2483200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767610906, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.364195027083, "loss": 0.32375011120341685, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 9700}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767610907, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 2483200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767665694, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 2508800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767667122, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 467.26329108685235, "loss": 0.3205445448292225, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 9800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767667123, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 2508800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767716732, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 2534400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767718160, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.0375610110756, "loss": 0.32191070234729924, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 9900}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767718162, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 2534400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767767763, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 2560000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767769193, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 516.1157200936526, "loss": 0.3212835279761296, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 10000}}
0: Epoch 3, global step 10000: 'timestamp' reached 1714767767762.00000 (best 1714763671494.00000), saving model to '/tmp/nemologs/stable-diffusion2-train-240504035020273822643/checkpoints/stable-diffusion2-train-240504035020273822643--timestamp=1714767767762.0-step=10000-consumed_samples=2560000.0.ckpt' as top 5
0: Saving /tmp/nemologs/stable-diffusion2-train-240504035020273822643/checkpoints/stable-diffusion2-train-240504035020273822643--timestamp=1714767767762.0-step=10000-consumed_samples=2560000.0.ckpt in the background
0: :::MLLOG {"namespace": "", "time_ms": 1714767769481, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 2560000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767819263, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 2585600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767820700, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 514.2452118426849, "loss": 0.3214900938309975, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 10100}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767820701, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 2585600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767870481, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 2611200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767871918, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 514.2611808121646, "loss": 0.3202927366652367, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 10200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767871919, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 2611200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767921721, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 2636800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767923159, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 514.0301039953265, "loss": 0.3195945326316914, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 10300}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767923160, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 2636800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767972961, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 2662400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767974399, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 514.0451891442328, "loss": 0.32274310742930723, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 10400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714767974400, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 2662400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768024151, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 2688000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768025585, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 514.5609771148632, "loss": 0.3221202055190323, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 10500}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768025587, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 2688000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768075354, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 2713600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768076795, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 514.3964252827543, "loss": 0.32099193252006114, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 10600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768076796, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 2713600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768126564, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 2739200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768128002, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 514.3854870471661, "loss": 0.32205039655976947, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 10700}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768128003, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 2739200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768177783, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 2764800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768179218, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 514.259443792057, "loss": 0.32000564255189673, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 10800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768179218, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 2764800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768228976, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 2790400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768230414, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 514.4935978804378, "loss": 0.3197388998482653, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 10900}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768230415, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 2790400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768280194, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 2816000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768281629, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 514.2722223724278, "loss": 0.3206943098423733, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 11000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768281630, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 2816000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768331405, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 2841600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768332842, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 514.3203687799318, "loss": 0.31957929291626763, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 11100}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768332843, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 2841600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768382611, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 2867200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768384047, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 514.3866207661498, "loss": 0.31868581453164774, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 11200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768384047, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 2867200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768433830, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 2892800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768435262, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 514.2389428248526, "loss": 0.31765268008152986, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 11300}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768435263, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 2892800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768485074, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 2918400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768486512, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 513.9445727838792, "loss": 0.3205043379204449, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 11400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768486513, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 2918400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768536269, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 2944000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768537705, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 514.5081164690524, "loss": 0.3197365538094704, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 11500}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768537706, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 2944000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768587470, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 2969600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768588906, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 514.4285318477647, "loss": 0.32076385177283023, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 11600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768588906, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 2969600}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768638697, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 2995200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768640133, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 514.151186693156, "loss": 0.31835611025027677, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 11700}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768640134, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 2995200}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768689909, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 3020800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768691347, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 514.3204200731511, "loss": 0.32109096206008647, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 11800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768691348, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 3020800}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768741122, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 3046400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768742557, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 514.3202774052078, "loss": 0.31876632371663366, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 11900}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768742559, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 143, "samples_count": 3046400}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768792337, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 167, "samples_count": 3072000}}
0: :::MLLOG {"namespace": "", "time_ms": 1714768793775, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 514.2830105299815, "loss": 0.31914943375918925, "lr": 2.5600000299164094e-05}, "metadata": {"file": "/workspace/sd/mlperf_logging_utils.py", "lineno": 178, "step_num": 12000}}
0: Epoch 3, global step 12000: 'timestamp' reached 1714768792336.00000 (best 1714763671494.00000), saving model to '/tmp/nemologs/stable-diffusion2-train-240504035020273822643/checkpoints/stable-diffusion2-train-240504035020273822643--timestamp=1714768792336.0-step=12000-consumed_samples=3072000.0.ckpt' as top 6
0: Saving /tmp/nemologs/stable-diffusion2-train-240504035020273822643/checkpoints/stable-diffusion2-train-240504035020273822643--timestamp=1714768792336.0-step=12000-consumed_samples=3072000.0.ckpt in the background
0: `Trainer.fit` stopped: `max_steps=12000` reached.
0: Moving checkpoints to nemologs
0: total 0
0: drwxrwxr-x 5 miwa miwa 200 May  4 04:14 stable-diffusion2-train-240504035020273822643
0: CKPT_PATH=/nemologs/stable-diffusion2-train-240504035020273822643/checkpoints/
3: CKPT_PATH=/nemologs/stable-diffusion2-train-240504035020273822643/checkpoints/
2: CKPT_PATH=/nemologs/stable-diffusion2-train-240504035020273822643/checkpoints/
1: CKPT_PATH=/nemologs/stable-diffusion2-train-240504035020273822643/checkpoints/
0: FlashAttention Installed
0: [NeMo W 2024-05-04 05:41:10 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
0:     See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
0:       ret = run_job(
0:     
0: [NeMo W 2024-05-04 05:41:10 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
0:       warnings.warn(
0:     
0: [NeMo W 2024-05-04 05:41:10 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.
0:       warnings.warn(msg)
0:     
2: FlashAttention Installed
0: Loaded ViT-H-14 model config.
2: Loaded ViT-H-14 model config.
3: FlashAttention Installed
1: FlashAttention Installed
3: Loaded ViT-H-14 model config.
1: Loaded ViT-H-14 model config.
0: Loading pretrained ViT-H-14 weights (laion2b_s32b_b79k).
2: Loading pretrained ViT-H-14 weights (laion2b_s32b_b79k).
3: Loading pretrained ViT-H-14 weights (laion2b_s32b_b79k).
1: Loading pretrained ViT-H-14 weights (laion2b_s32b_b79k).
0: Using 16bit Automatic Mixed Precision (AMP)
0: GPU available: True (cuda), used: True
0: TPU available: False, using: 0 TPU cores
0: IPU available: False, using: 0 IPUs
0: HPU available: False, using: 0 HPUs
0: [NeMo W 2024-05-04 05:41:20 utils:296] Loading from .ckpt checkpoint for inference is experimental! It doesn't support models with model parallelism!
2: [W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tensor_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: pipeline_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: virtual_pipeline_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: sequence_parallel in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: context_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: use_cpu_initialization in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: gradient_accumulation_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: use_te_rng_tracker in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_overlap_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_overlap_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_overlap_rs_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: overlap_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: batch_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: defer_embedding_wgrad_compute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading_activations in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading_weights in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1161] hidden_size not found in {'precision': 16, 'micro_batch_size': 64, 'global_batch_size': 256, 'linear_start': 0.00085, 'linear_end': 0.012, 'num_timesteps_cond': 1, 'log_every_t': 200, 'timesteps': 1000, 'first_stage_key': 'images_moments', 'cond_stage_key': 'clip_encoded', 'image_size': 64, 'channels': 4, 'cond_stage_trainable': False, 'conditioning_key': 'crossattn', 'monitor': 'val/loss_simple_ema', 'scale_factor': 0.18215, 'use_ema': False, 'scale_by_std': False, 'ckpt_path': '/checkpoints/sd/512-base-ema.ckpt', 'load_vae': True, 'load_unet': False, 'load_encoder': True, 'ignore_keys': [], 'parameterization': 'v', 'clip_denoised': True, 'load_only_unet': False, 'cosine_s': 0.008, 'given_betas': None, 'original_elbo_weight': 0, 'v_posterior': 0, 'l_simple_weight': 1, 'use_positional_encodings': False, 'learn_logvar': False, 'logvar_init': 0, 'beta_schedule': 'linear', 'loss_type': 'l2', 'channels_last': True, 'concat_mode': True, 'cond_stage_forward': No
0: ne, 'text_embedding_dropout_rate': 0.0, 'fused_opt': True, 'inductor': False, 'inductor_cudagraphs': False, 'capture_cudagraph_iters': 15, 'unet_config': {'_target_': 'nemo.collections.multimodal.modules.stable_diffusion.diffusionmodules.openaimodel.UNetModel', 'from_pretrained': None, 'from_NeMo': None, 'image_size': 32, 'in_channels': 4, 'out_channels': 4, 'model_channels': 320, 'attention_resolutions': [4, 2, 1], 'num_res_blocks': 2, 'channel_mult': [1, 2, 4, 4], 'num_head_channels': 64, 'use_spatial_transformer': True, 'use_linear_in_transformer': True, 'transformer_depth': 1, 'context_dim': 1024, 'use_checkpoint': False, 'legacy': False, 'use_flash_attention': True, 'resblock_gn_groups': 16, 'unet_precision': 'fp16', 'timesteps': 1000}, 'first_stage_config': {'_target_': 'nemo.collections.multimodal.models.text_to_image.stable_diffusion.ldm.autoencoder.AutoencoderKL', 'from_pretrained': None, 'embed_dim': 4, 'monitor': 'val/rec_loss', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 256, 'in
0: _channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0}, 'lossconfig': {'target': 'torch.nn.Identity'}}, 'cond_stage_config': {'_target_': 'nemo.collections.multimodal.modules.stable_diffusion.encoders.modules.FrozenOpenCLIPEmbedder', 'arch': 'ViT-H-14', 'version': 'laion2b_s32b_b79k', 'freeze': True, 'layer': 'penultimate', 'cache_dir': '/checkpoints/clip'}, 'seed': 9456, 'resume_from_checkpoint': None, 'apex_transformer_log_level': 30, 'gradient_as_bucket_view': True, 'ddp_overlap': False, 'nsys_profile': {'enabled': False, 'start_step': 10, 'end_step': 10, 'ranks': [0], 'gen_shape': False}, 'data': {'num_workers': 16, 'train': {'dataset_path': '/datasets/laion-400m/webdataset-moments-filtered-encoded/*.tar', 'augmentations': {'resize_smallest_side': 512, 'center_crop_h_w': '512, 512', 'horizontal_flip': False}, 'filterings': None}, 'webdataset': {'infinite_sampler': True, 'local_root_path': '/datasets/laion-400m/webdataset-moments-filtere
0: d-encoded'}}, 'optim': {'name': 'distributed_fused_adam', 'lr': 2.56e-05, 'weight_decay': 0.0, 'betas': [0.9, 0.999], 'sched': {'name': 'WarmupHoldPolicy', 'warmup_steps': 1000, 'hold_steps': 10000000000000}, 'bucket_cap_mb': 288, 'overlap_grad_sync': True, 'overlap_param_sync': False, 'contiguous_grad_buffer': True, 'contiguous_param_buffer': True, 'store_params': True, 'dtype': 'torch.float32', 'grad_sync_dtype': 'torch.float16', 'param_sync_dtype': 'torch.float16', 'capturable': True, 'distribute_within_nodes': True}, 'target': 'nemo.collections.multimodal.models.text_to_image.stable_diffusion.ldm.ddpm.MegatronLatentDiffusion', 'nemo_version': '2.0.0b0'}. Set this in model_parallel_config if using pipeline parallelism.
0: [W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
0: Found checkpoints:
0: /nemologs/stable-diffusion2-train-240504035020273822643/checkpoints/stable-diffusion2-train-240504035020273822643--timestamp=1714763671494.0-step=2000-consumed_samples=512000.0.ckpt
0: /nemologs/stable-diffusion2-train-240504035020273822643/checkpoints/stable-diffusion2-train-240504035020273822643--timestamp=1714764696587.0-step=4000-consumed_samples=1024000.0.ckpt
0: /nemologs/stable-diffusion2-train-240504035020273822643/checkpoints/stable-diffusion2-train-240504035020273822643--timestamp=1714765717624.0-step=6000-consumed_samples=1536000.0.ckpt
0: /nemologs/stable-diffusion2-train-240504035020273822643/checkpoints/stable-diffusion2-train-240504035020273822643--timestamp=1714766741636.0-step=8000-consumed_samples=2048000.0.ckpt
0: /nemologs/stable-diffusion2-train-240504035020273822643/checkpoints/stable-diffusion2-train-240504035020273822643--timestamp=1714767767762.0-step=10000-consumed_samples=2560000.0.ckpt
0: /nemologs/stable-diffusion2-train-240504035020273822643/checkpoints/stable-diffusion2-train-240504035020273822643--timestamp=1714768792336.0-step=12000-consumed_samples=3072000.0.ckpt
0: [NeMo I 2024-05-04 05:41:22 megatron_init:265] Rank 0 has data parallel group : [0, 1, 2, 3]
0: [NeMo I 2024-05-04 05:41:22 megatron_init:271] Rank 0 has combined group of data parallel and context parallel : [0, 1, 2, 3]
0: [NeMo I 2024-05-04 05:41:22 megatron_init:276] All data parallel group ranks with context parallel combined: [[0, 1, 2, 3]]
0: [NeMo I 2024-05-04 05:41:22 megatron_init:279] Ranks 0 has data parallel rank: 0
0: [NeMo I 2024-05-04 05:41:22 megatron_init:287] Rank 0 has context parallel group: [0]
0: [NeMo I 2024-05-04 05:41:22 megatron_init:290] All context parallel group ranks: [[0], [1], [2], [3]]
0: [NeMo I 2024-05-04 05:41:22 megatron_init:291] Ranks 0 has context parallel rank: 0
0: [NeMo I 2024-05-04 05:41:22 megatron_init:298] Rank 0 has model parallel group: [0]
0: [NeMo I 2024-05-04 05:41:22 megatron_init:299] All model parallel group ranks: [[0], [1], [2], [3]]
0: [NeMo I 2024-05-04 05:41:22 megatron_init:308] Rank 0 has tensor model parallel group: [0]
0: [NeMo I 2024-05-04 05:41:22 megatron_init:312] All tensor model parallel group ranks: [[0], [1], [2], [3]]
0: [NeMo I 2024-05-04 05:41:22 megatron_init:313] Rank 0 has tensor model parallel rank: 0
0: [NeMo I 2024-05-04 05:41:22 megatron_init:333] Rank 0 has pipeline model parallel group: [0]
0: [NeMo I 2024-05-04 05:41:22 megatron_init:345] Rank 0 has embedding group: [0]
0: [NeMo I 2024-05-04 05:41:22 megatron_init:351] All pipeline model parallel group ranks: [[0], [1], [2], [3]]
0: [NeMo I 2024-05-04 05:41:22 megatron_init:352] Rank 0 has pipeline model parallel rank 0
0: [NeMo I 2024-05-04 05:41:22 megatron_init:353] All embedding group ranks: [[0], [1], [2], [3]]
0: [NeMo I 2024-05-04 05:41:22 megatron_init:354] Rank 0 has embedding rank: 0
0: 24-05-04 05:41:22 - PID:300407 - rank:(0, 0, 0, 0) - microbatches.py:39 - INFO - setting number of micro-batches to constant 1
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tensor_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: pipeline_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: virtual_pipeline_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: sequence_parallel in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: context_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: use_cpu_initialization in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: gradient_accumulation_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: use_te_rng_tracker in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_overlap_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_overlap_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_overlap_rs_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: overlap_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: batch_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: defer_embedding_wgrad_compute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading_activations in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading_weights in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 05:41:22 megatron_base_model:1161] hidden_size not found in {'precision': 16, 'micro_batch_size': 64, 'global_batch_size': 256, 'linear_start': 0.00085, 'linear_end': 0.012, 'num_timesteps_cond': 1, 'log_every_t': 200, 'timesteps': 1000, 'first_stage_key': 'images_moments', 'cond_stage_key': 'clip_encoded', 'image_size': 64, 'channels': 4, 'cond_stage_trainable': False, 'conditioning_key': 'crossattn', 'monitor': 'val/loss_simple_ema', 'scale_factor': 0.18215, 'use_ema': False, 'scale_by_std': False, 'ckpt_path': '/checkpoints/sd/512-base-ema.ckpt', 'load_vae': True, 'load_unet': False, 'load_encoder': True, 'ignore_keys': [], 'parameterization': 'v', 'clip_denoised': True, 'load_only_unet': False, 'cosine_s': 0.008, 'given_betas': None, 'original_elbo_weight': 0, 'v_posterior': 0, 'l_simple_weight': 1, 'use_positional_encodings': False, 'learn_logvar': False, 'logvar_init': 0, 'beta_schedule': 'linear', 'loss_type': 'l2', 'channels_last': True, 'concat_mode': True, 'cond_stage_forward': No
0: ne, 'text_embedding_dropout_rate': 0.0, 'fused_opt': True, 'inductor': False, 'inductor_cudagraphs': False, 'capture_cudagraph_iters': 15, 'unet_config': {'_target_': 'nemo.collections.multimodal.modules.stable_diffusion.diffusionmodules.openaimodel.UNetModel', 'from_pretrained': None, 'from_NeMo': None, 'image_size': 32, 'in_channels': 4, 'out_channels': 4, 'model_channels': 320, 'attention_resolutions': [4, 2, 1], 'num_res_blocks': 2, 'channel_mult': [1, 2, 4, 4], 'num_head_channels': 64, 'use_spatial_transformer': True, 'use_linear_in_transformer': True, 'transformer_depth': 1, 'context_dim': 1024, 'use_checkpoint': False, 'legacy': False, 'use_flash_attention': True, 'resblock_gn_groups': 16, 'unet_precision': 'fp16', 'timesteps': 1000}, 'first_stage_config': {'_target_': 'nemo.collections.multimodal.models.text_to_image.stable_diffusion.ldm.autoencoder.AutoencoderKL', 'from_pretrained': None, 'embed_dim': 4, 'monitor': 'val/rec_loss', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 256, 'in
0: _channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0}, 'lossconfig': {'target': 'torch.nn.Identity'}}, 'cond_stage_config': {'_target_': 'nemo.collections.multimodal.modules.stable_diffusion.encoders.modules.FrozenOpenCLIPEmbedder', 'arch': 'ViT-H-14', 'version': 'laion2b_s32b_b79k', 'freeze': True, 'layer': 'penultimate', 'cache_dir': '/checkpoints/clip'}, 'seed': 9456, 'resume_from_checkpoint': None, 'apex_transformer_log_level': 30, 'gradient_as_bucket_view': True, 'ddp_overlap': False, 'nsys_profile': {'enabled': False, 'start_step': 10, 'end_step': 10, 'ranks': [0], 'gen_shape': False}, 'data': {'num_workers': 16, 'train': {'dataset_path': '/datasets/laion-400m/webdataset-moments-filtered-encoded/*.tar', 'augmentations': {'resize_smallest_side': 512, 'center_crop_h_w': '512, 512', 'horizontal_flip': False}, 'filterings': None}, 'webdataset': {'infinite_sampler': True, 'local_root_path': '/datasets/laion-400m/webdataset-moments-filtere
0: d-encoded'}}, 'optim': {'name': 'distributed_fused_adam', 'lr': 2.56e-05, 'weight_decay': 0.0, 'betas': [0.9, 0.999], 'sched': {'name': 'WarmupHoldPolicy', 'warmup_steps': 1000, 'hold_steps': 10000000000000}, 'bucket_cap_mb': 288, 'overlap_grad_sync': True, 'overlap_param_sync': False, 'contiguous_grad_buffer': True, 'contiguous_param_buffer': True, 'store_params': True, 'dtype': 'torch.float32', 'grad_sync_dtype': 'torch.float16', 'param_sync_dtype': 'torch.float16', 'capturable': True, 'distribute_within_nodes': True}, 'target': 'nemo.collections.multimodal.models.text_to_image.stable_diffusion.ldm.ddpm.MegatronLatentDiffusion', 'nemo_version': '2.0.0b0'}. Set this in model_parallel_config if using pipeline parallelism.
0: [NeMo I 2024-05-04 05:41:22 ddpm:130] LatentDiffusion: Running in v-prediction mode
0: [NeMo I 2024-05-04 05:41:22 attention:436] constructing SpatialTransformer of depth 1 w/ 320 channels and 5 heads
0: [NeMo I 2024-05-04 05:41:22 attention:436] constructing SpatialTransformer of depth 1 w/ 320 channels and 5 heads
0: [NeMo I 2024-05-04 05:41:22 attention:436] constructing SpatialTransformer of depth 1 w/ 640 channels and 10 heads
0: [NeMo I 2024-05-04 05:41:22 attention:436] constructing SpatialTransformer of depth 1 w/ 640 channels and 10 heads
0: [NeMo I 2024-05-04 05:41:22 attention:436] constructing SpatialTransformer of depth 1 w/ 1280 channels and 20 heads
0: [NeMo I 2024-05-04 05:41:23 attention:436] constructing SpatialTransformer of depth 1 w/ 1280 channels and 20 heads
3: [W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
1: [W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
0: [NeMo I 2024-05-04 05:41:23 attention:436] constructing SpatialTransformer of depth 1 w/ 1280 channels and 20 heads
0: [NeMo I 2024-05-04 05:41:24 attention:436] constructing SpatialTransformer of depth 1 w/ 1280 channels and 20 heads
0: [NeMo I 2024-05-04 05:41:25 attention:436] constructing SpatialTransformer of depth 1 w/ 1280 channels and 20 heads
0: [NeMo I 2024-05-04 05:41:25 attention:436] constructing SpatialTransformer of depth 1 w/ 1280 channels and 20 heads
0: [NeMo I 2024-05-04 05:41:25 attention:436] constructing SpatialTransformer of depth 1 w/ 640 channels and 10 heads
0: [NeMo I 2024-05-04 05:41:25 attention:436] constructing SpatialTransformer of depth 1 w/ 640 channels and 10 heads
0: [NeMo I 2024-05-04 05:41:26 attention:436] constructing SpatialTransformer of depth 1 w/ 640 channels and 10 heads
0: [NeMo I 2024-05-04 05:41:26 attention:436] constructing SpatialTransformer of depth 1 w/ 320 channels and 5 heads
0: [NeMo I 2024-05-04 05:41:26 attention:436] constructing SpatialTransformer of depth 1 w/ 320 channels and 5 heads
0: [NeMo I 2024-05-04 05:41:26 attention:436] constructing SpatialTransformer of depth 1 w/ 320 channels and 5 heads
0: [NeMo I 2024-05-04 05:41:26 utils:92] DiffusionWrapper has 865.91 M params.
0: [NeMo I 2024-05-04 05:41:26 ddpm:168] Use system random generator since CUDA graph enabled
2: Found checkpoints:
2: /nemologs/stable-diffusion2-train-240504035020273822643/checkpoints/stable-diffusion2-train-240504035020273822643--timestamp=1714763671494.0-step=2000-consumed_samples=512000.0.ckpt
2: /nemologs/stable-diffusion2-train-240504035020273822643/checkpoints/stable-diffusion2-train-240504035020273822643--timestamp=1714764696587.0-step=4000-consumed_samples=1024000.0.ckpt
2: /nemologs/stable-diffusion2-train-240504035020273822643/checkpoints/stable-diffusion2-train-240504035020273822643--timestamp=1714765717624.0-step=6000-consumed_samples=1536000.0.ckpt
2: /nemologs/stable-diffusion2-train-240504035020273822643/checkpoints/stable-diffusion2-train-240504035020273822643--timestamp=1714766741636.0-step=8000-consumed_samples=2048000.0.ckpt
2: /nemologs/stable-diffusion2-train-240504035020273822643/checkpoints/stable-diffusion2-train-240504035020273822643--timestamp=1714767767762.0-step=10000-consumed_samples=2560000.0.ckpt
2: /nemologs/stable-diffusion2-train-240504035020273822643/checkpoints/stable-diffusion2-train-240504035020273822643--timestamp=1714768792336.0-step=12000-consumed_samples=3072000.0.ckpt
2: making attention of type 'vanilla' with 512 in_channels
2: Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
2: making attention of type 'vanilla' with 512 in_channels
2: Downloading clip with ViT-H-14 laion2b_s32b_b79k /checkpoints/clip
2: Loaded ViT-H-14 model config.
0: making attention of type 'vanilla' with 512 in_channels
0: Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
0: making attention of type 'vanilla' with 512 in_channels
0: Downloading clip with ViT-H-14 laion2b_s32b_b79k /checkpoints/clip
0: Loaded ViT-H-14 model config.
3: Found checkpoints:
3: /nemologs/stable-diffusion2-train-240504035020273822643/checkpoints/stable-diffusion2-train-240504035020273822643--timestamp=1714763671494.0-step=2000-consumed_samples=512000.0.ckpt
3: /nemologs/stable-diffusion2-train-240504035020273822643/checkpoints/stable-diffusion2-train-240504035020273822643--timestamp=1714764696587.0-step=4000-consumed_samples=1024000.0.ckpt
3: /nemologs/stable-diffusion2-train-240504035020273822643/checkpoints/stable-diffusion2-train-240504035020273822643--timestamp=1714765717624.0-step=6000-consumed_samples=1536000.0.ckpt
3: /nemologs/stable-diffusion2-train-240504035020273822643/checkpoints/stable-diffusion2-train-240504035020273822643--timestamp=1714766741636.0-step=8000-consumed_samples=2048000.0.ckpt
3: /nemologs/stable-diffusion2-train-240504035020273822643/checkpoints/stable-diffusion2-train-240504035020273822643--timestamp=1714767767762.0-step=10000-consumed_samples=2560000.0.ckpt
3: /nemologs/stable-diffusion2-train-240504035020273822643/checkpoints/stable-diffusion2-train-240504035020273822643--timestamp=1714768792336.0-step=12000-consumed_samples=3072000.0.ckpt
3: making attention of type 'vanilla' with 512 in_channels
3: Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
3: making attention of type 'vanilla' with 512 in_channels
3: Downloading clip with ViT-H-14 laion2b_s32b_b79k /checkpoints/clip
3: Loaded ViT-H-14 model config.
1: Found checkpoints:
1: /nemologs/stable-diffusion2-train-240504035020273822643/checkpoints/stable-diffusion2-train-240504035020273822643--timestamp=1714763671494.0-step=2000-consumed_samples=512000.0.ckpt
1: /nemologs/stable-diffusion2-train-240504035020273822643/checkpoints/stable-diffusion2-train-240504035020273822643--timestamp=1714764696587.0-step=4000-consumed_samples=1024000.0.ckpt
1: /nemologs/stable-diffusion2-train-240504035020273822643/checkpoints/stable-diffusion2-train-240504035020273822643--timestamp=1714765717624.0-step=6000-consumed_samples=1536000.0.ckpt
1: /nemologs/stable-diffusion2-train-240504035020273822643/checkpoints/stable-diffusion2-train-240504035020273822643--timestamp=1714766741636.0-step=8000-consumed_samples=2048000.0.ckpt
1: /nemologs/stable-diffusion2-train-240504035020273822643/checkpoints/stable-diffusion2-train-240504035020273822643--timestamp=1714767767762.0-step=10000-consumed_samples=2560000.0.ckpt
1: /nemologs/stable-diffusion2-train-240504035020273822643/checkpoints/stable-diffusion2-train-240504035020273822643--timestamp=1714768792336.0-step=12000-consumed_samples=3072000.0.ckpt
1: making attention of type 'vanilla' with 512 in_channels
1: Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
1: making attention of type 'vanilla' with 512 in_channels
1: Downloading clip with ViT-H-14 laion2b_s32b_b79k /checkpoints/clip
1: Loaded ViT-H-14 model config.
2: Loading pretrained ViT-H-14 weights (laion2b_s32b_b79k).
0: Loading pretrained ViT-H-14 weights (laion2b_s32b_b79k).
3: Loading pretrained ViT-H-14 weights (laion2b_s32b_b79k).
1: Loading pretrained ViT-H-14 weights (laion2b_s32b_b79k).
0: [NeMo I 2024-05-04 05:41:36 ddpm:260] Loading /checkpoints/sd/512-base-ema.ckpt
0: [NeMo I 2024-05-04 05:41:36 ddpm:261] It has 1242 entries
0: [NeMo I 2024-05-04 05:41:36 ddpm:262] Existing model has 1240 entries
0: [NeMo I 2024-05-04 05:41:36 ddpm:296] Deleted 686 keys from `model.diffusion_model` state_dict.
0: [NeMo I 2024-05-04 05:41:36 ddpm:301] Restored from /checkpoints/sd/512-base-ema.ckpt with 686 missing and 2 unexpected keys
0: [NeMo I 2024-05-04 05:41:36 ddpm:303] Missing Keys: ['model.diffusion_model.time_embed.0.weight', 'model.diffusion_model.time_embed.0.bias', 'model.diffusion_model.time_embed.2.weight', 'model.diffusion_model.time_embed.2.bias', 'model.diffusion_model.input_blocks.0.0.weight', 'model.diffusion_model.input_blocks.0.0.bias', 'model.diffusion_model.input_blocks.1.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.1.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.1.0.in_layers.1.weight', 'model.diffusion_model.input_blocks.1.0.in_layers.1.bias', 'model.diffusion_model.input_blocks.1.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.1.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.1.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.1.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.1.0.out_layers.2.weight', 'model.diffusion_model.input_blocks.1.0.out_layers.2.bias', 'model.diffusion_model.input_blocks.1.1.norm.weight', 'model.diffusion_model.input_blocks.1.1
0: .norm.bias', 'model.diffusion_model.input_blocks.1.1.proj_in.weight', 'model.diffusion_model.input_blocks.1.1.proj_in.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_k.weight', 'mod
0: el.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.1.1.proj_out.weight', 'model.diffusion_model.input_blocks.1.1.proj_out.bias', 'model.diffusion_model.input_blocks.2.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.2.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.2.0.in_layers.1.weight', 'model.diffusion_model.input_block
0: s.2.0.in_layers.1.bias', 'model.diffusion_model.input_blocks.2.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.2.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.2.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.2.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.2.0.out_layers.2.weight', 'model.diffusion_model.input_blocks.2.0.out_layers.2.bias', 'model.diffusion_model.input_blocks.2.1.norm.weight', 'model.diffusion_model.input_blocks.2.1.norm.bias', 'model.diffusion_model.input_blocks.2.1.proj_in.weight', 'model.diffusion_model.input_blocks.2.1.proj_in.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.bias', 'mod
0: el.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2.bi
0: as', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.2.1.proj_out.weight', 'model.diffusion_model.input_blocks.2.1.proj_out.bias', 'model.diffusion_model.input_blocks.3.0.op.weight', 'model.diffusion_model.input_blocks.3.0.op.bias', 'model.diffusion_model.input_blocks.4.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.4.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.4.0.in_layers.1.weight', 'model.diffusion_model.input_blocks.4.0.in_layers.1.bias', 'model.diffusion_model.input_blocks.4.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.4.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.4.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.4.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.4.0.out_layers.2.weight', 'model.diffusion_model.input_blocks.4.0.out_layers.2.bias', 'model.diffusion_model.input_blocks.4.0.skip_co
0: nnection.weight', 'model.diffusion_model.input_blocks.4.0.skip_connection.bias', 'model.diffusion_model.input_blocks.4.1.norm.weight', 'model.diffusion_model.input_blocks.4.1.norm.bias', 'model.diffusion_model.input_blocks.4.1.proj_in.weight', 'model.diffusion_model.input_blocks.4.1.proj_in.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2
0: .bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.4.1.proj_out.weight', 'model.diffusion_model.input_blocks.4.1.proj_out.bias', 'model.diffusion_model.input_blocks.5.0.i
0: n_layers.0.weight', 'model.diffusion_model.input_blocks.5.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.5.0.in_layers.1.weight', 'model.diffusion_model.input_blocks.5.0.in_layers.1.bias', 'model.diffusion_model.input_blocks.5.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.5.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.5.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.5.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.5.0.out_layers.2.weight', 'model.diffusion_model.input_blocks.5.0.out_layers.2.bias', 'model.diffusion_model.input_blocks.5.1.norm.weight', 'model.diffusion_model.input_blocks.5.1.norm.bias', 'model.diffusion_model.input_blocks.5.1.proj_in.weight', 'model.diffusion_model.input_blocks.5.1.proj_in.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_v.weight'
0: , 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.5.1.trans
0: former_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.5.1.proj_out.weight', 'model.diffusion_model.input_blocks.5.1.proj_out.bias', 'model.diffusion_model.input_blocks.6.0.op.weight', 'model.diffusion_model.input_blocks.6.0.op.bias', 'model.diffusion_model.input_blocks.7.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.7.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.7.0.in_layers.1.weight', 'model.diffusion_model.input_blocks.7.0.in_layers.1.bias', 'model.diffusion_model.input_blocks.7.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.7.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.7.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.7.0.out_layers.0.bi
0: as', 'model.diffusion_model.input_blocks.7.0.out_layers.2.weight', 'model.diffusion_model.input_blocks.7.0.out_layers.2.bias', 'model.diffusion_model.input_blocks.7.0.skip_connection.weight', 'model.diffusion_model.input_blocks.7.0.skip_connection.bias', 'model.diffusion_model.input_blocks.7.1.norm.weight', 'model.diffusion_model.input_blocks.7.1.norm.bias', 'model.diffusion_model.input_blocks.7.1.proj_in.weight', 'model.diffusion_model.input_blocks.7.1.proj_in.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.7.1.transformer_bloc
0: ks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blo
0: cks.0.norm3.bias', 'model.diffusion_model.input_blocks.7.1.proj_out.weight', 'model.diffusion_model.input_blocks.7.1.proj_out.bias', 'model.diffusion_model.input_blocks.8.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.8.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.8.0.in_layers.1.weight', 'model.diffusion_model.input_blocks.8.0.in_layers.1.bias', 'model.diffusion_model.input_blocks.8.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.8.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.8.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.8.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.8.0.out_layers.2.weight', 'model.diffusion_model.input_blocks.8.0.out_layers.2.bias', 'model.diffusion_model.input_blocks.8.1.norm.weight', 'model.diffusion_model.input_blocks.8.1.norm.bias', 'model.diffusion_model.input_blocks.8.1.proj_in.weight', 'model.diffusion_model.input_blocks.8.1.proj_in.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.
0: to_q.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_b
0: locks.8.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.8.1.proj_out.weight', 'model.diffusion_model.input_blocks.8.1.proj_out.bias', 'model.diffusion_model.input_blocks.9.0.op.weight', 'model.diffusion_model.input_blocks.9.0.op.bias', 'model.diffusion_model.input_blocks.10.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.10.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.10.0.in_layers.1.weight', 'model.diffusion_model.input_blocks.10.0.in_layers.1.bias', 'model.diffusion_model.input_blocks.10.0.emb_layers.1.weight'
0: , 'model.diffusion_model.input_blocks.10.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.10.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.10.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.10.0.out_layers.2.weight', 'model.diffusion_model.input_blocks.10.0.out_layers.2.bias', 'model.diffusion_model.input_blocks.11.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.11.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.11.0.in_layers.1.weight', 'model.diffusion_model.input_blocks.11.0.in_layers.1.bias', 'model.diffusion_model.input_blocks.11.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.11.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.11.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.11.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.11.0.out_layers.2.weight', 'model.diffusion_model.input_blocks.11.0.out_layers.2.bias', 'model.diffusion_model.middle_block.0.in_layers.0.weight', 'model.diffusion_model.middle_block.0.
0: in_layers.0.bias', 'model.diffusion_model.middle_block.0.in_layers.1.weight', 'model.diffusion_model.middle_block.0.in_layers.1.bias', 'model.diffusion_model.middle_block.0.emb_layers.1.weight', 'model.diffusion_model.middle_block.0.emb_layers.1.bias', 'model.diffusion_model.middle_block.0.out_layers.0.weight', 'model.diffusion_model.middle_block.0.out_layers.0.bias', 'model.diffusion_model.middle_block.0.out_layers.2.weight', 'model.diffusion_model.middle_block.0.out_layers.2.bias', 'model.diffusion_model.middle_block.1.norm.weight', 'model.diffusion_model.middle_block.1.norm.bias', 'model.diffusion_model.middle_block.1.proj_in.weight', 'model.diffusion_model.middle_block.1.proj_in.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.weight', 'mode
0: l.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm2.weight', 'model.diffus
0: ion_model.middle_block.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.middle_block.1.proj_out.weight', 'model.diffusion_model.middle_block.1.proj_out.bias', 'model.diffusion_model.middle_block.2.in_layers.0.weight', 'model.diffusion_model.middle_block.2.in_layers.0.bias', 'model.diffusion_model.middle_block.2.in_layers.1.weight', 'model.diffusion_model.middle_block.2.in_layers.1.bias', 'model.diffusion_model.middle_block.2.emb_layers.1.weight', 'model.diffusion_model.middle_block.2.emb_layers.1.bias', 'model.diffusion_model.middle_block.2.out_layers.0.weight', 'model.diffusion_model.middle_block.2.out_layers.0.bias', 'model.diffusion_model.middle_block.2.out_layers.2.weight', 'model.diffusion_model.middle_block.2.out_layers.2.bias', 'model.diffusion_model.output_blocks.0.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.0.0.in_layers.0.bias', '
0: model.diffusion_model.output_blocks.0.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.0.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.0.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.0.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.0.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.0.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.0.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.0.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.0.0.skip_connection.weight', 'model.diffusion_model.output_blocks.0.0.skip_connection.bias', 'model.diffusion_model.output_blocks.1.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.1.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.1.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.1.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.1.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.1.0.emb_layers.1.bias', 'model.diffusion_model.output_blo
0: cks.1.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.1.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.1.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.1.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.1.0.skip_connection.weight', 'model.diffusion_model.output_blocks.1.0.skip_connection.bias', 'model.diffusion_model.output_blocks.2.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.2.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.2.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.2.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.2.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.2.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.2.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.2.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.2.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.2.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.2.0.skip_connection.weight
0: ', 'model.diffusion_model.output_blocks.2.0.skip_connection.bias', 'model.diffusion_model.output_blocks.2.1.conv.weight', 'model.diffusion_model.output_blocks.2.1.conv.bias', 'model.diffusion_model.output_blocks.3.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.3.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.3.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.3.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.3.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.3.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.3.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.3.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.3.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.3.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.3.0.skip_connection.weight', 'model.diffusion_model.output_blocks.3.0.skip_connection.bias', 'model.diffusion_model.output_blocks.3.1.norm.weight', 'model.diffusion_model.output_blocks.3.1.norm.bi
0: as', 'model.diffusion_model.output_blocks.3.1.proj_in.weight', 'model.diffusion_model.output_blocks.3.1.proj_in.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_k.weight',
0:  'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.3.1.proj_out.weight', 'model.diffusion_model.output_blocks.3.1.proj_out.bias', 'model.diffusion_model.output_blocks.4.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.4.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.4.0.in_layers.1.weight', 'model.diffusio
0: n_model.output_blocks.4.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.4.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.4.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.4.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.4.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.4.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.4.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.4.0.skip_connection.weight', 'model.diffusion_model.output_blocks.4.0.skip_connection.bias', 'model.diffusion_model.output_blocks.4.1.norm.weight', 'model.diffusion_model.output_blocks.4.1.norm.bias', 'model.diffusion_model.output_blocks.4.1.proj_in.weight', 'model.diffusion_model.output_blocks.4.1.proj_in.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_v.weight', 'model.di
0: ffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.4.1.tra
0: nsformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.4.1.proj_out.weight', 'model.diffusion_model.output_blocks.4.1.proj_out.bias', 'model.diffusion_model.output_blocks.5.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.5.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.5.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.5.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.5.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.5.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.5.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.5.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.5.0.out_layers.2.weight', 'model.diffusion_m
0: odel.output_blocks.5.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.5.0.skip_connection.weight', 'model.diffusion_model.output_blocks.5.0.skip_connection.bias', 'model.diffusion_model.output_blocks.5.1.norm.weight', 'model.diffusion_model.output_blocks.5.1.norm.bias', 'model.diffusion_model.output_blocks.5.1.proj_in.weight', 'model.diffusion_model.output_blocks.5.1.proj_in.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.5.1.tran
0: sformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.5.
0: 1.proj_out.weight', 'model.diffusion_model.output_blocks.5.1.proj_out.bias', 'model.diffusion_model.output_blocks.5.2.conv.weight', 'model.diffusion_model.output_blocks.5.2.conv.bias', 'model.diffusion_model.output_blocks.6.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.6.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.6.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.6.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.6.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.6.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.6.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.6.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.6.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.6.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.6.0.skip_connection.weight', 'model.diffusion_model.output_blocks.6.0.skip_connection.bias', 'model.diffusion_model.output_blocks.6.1.norm.weight', 'model.diffusion_model.output_blocks.6
0: .1.norm.bias', 'model.diffusion_model.output_blocks.6.1.proj_in.weight', 'model.diffusion_model.output_blocks.6.1.proj_in.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_
0: k.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.6.1.proj_out.weight', 'model.diffusion_model.output_blocks.6.1.proj_out.bias', 'model.diffusion_model.output_blocks.7.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.7.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.7.0.in_layers.1.weight', 'mode
0: l.diffusion_model.output_blocks.7.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.7.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.7.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.7.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.7.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.7.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.7.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.7.0.skip_connection.weight', 'model.diffusion_model.output_blocks.7.0.skip_connection.bias', 'model.diffusion_model.output_blocks.7.1.norm.weight', 'model.diffusion_model.output_blocks.7.1.norm.bias', 'model.diffusion_model.output_blocks.7.1.proj_in.weight', 'model.diffusion_model.output_blocks.7.1.proj_in.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_v.weight',
0:  'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_bloc
0: ks.7.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.7.1.proj_out.weight', 'model.diffusion_model.output_blocks.7.1.proj_out.bias', 'model.diffusion_model.output_blocks.8.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.8.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.8.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.8.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.8.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.8.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.8.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.8.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.8.0.out_layers.2.weight', 'model.d
0: iffusion_model.output_blocks.8.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.8.0.skip_connection.weight', 'model.diffusion_model.output_blocks.8.0.skip_connection.bias', 'model.diffusion_model.output_blocks.8.1.norm.weight', 'model.diffusion_model.output_blocks.8.1.norm.bias', 'model.diffusion_model.output_blocks.8.1.proj_in.weight', 'model.diffusion_model.output_blocks.8.1.proj_in.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_block
0: s.8.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output
0: _blocks.8.1.proj_out.weight', 'model.diffusion_model.output_blocks.8.1.proj_out.bias', 'model.diffusion_model.output_blocks.8.2.conv.weight', 'model.diffusion_model.output_blocks.8.2.conv.bias', 'model.diffusion_model.output_blocks.9.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.9.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.9.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.9.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.9.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.9.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.9.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.9.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.9.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.9.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.9.0.skip_connection.weight', 'model.diffusion_model.output_blocks.9.0.skip_connection.bias', 'model.diffusion_model.output_blocks.9.1.norm.weight', 'model.diffusion_model.outpu
0: t_blocks.9.1.norm.bias', 'model.diffusion_model.output_blocks.9.1.proj_in.weight', 'model.diffusion_model.output_blocks.9.1.proj_in.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0
0: .attn2.to_k.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.9.1.proj_out.weight', 'model.diffusion_model.output_blocks.9.1.proj_out.bias', 'model.diffusion_model.output_blocks.10.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.10.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.10.0.in_layers.1.w
0: eight', 'model.diffusion_model.output_blocks.10.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.10.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.10.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.10.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.10.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.10.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.10.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.10.0.skip_connection.weight', 'model.diffusion_model.output_blocks.10.0.skip_connection.bias', 'model.diffusion_model.output_blocks.10.1.norm.weight', 'model.diffusion_model.output_blocks.10.1.norm.bias', 'model.diffusion_model.output_blocks.10.1.proj_in.weight', 'model.diffusion_model.output_blocks.10.1.proj_in.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.10.1.transformer
0: _blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.we
0: ight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.10.1.proj_out.weight', 'model.diffusion_model.output_blocks.10.1.proj_out.bias', 'model.diffusion_model.output_blocks.11.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.11.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.11.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.11.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.11.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.11.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.11.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.11.0.out_layers.0.bias', 'model.diffusio
0: n_model.output_blocks.11.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.11.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.11.0.skip_connection.weight', 'model.diffusion_model.output_blocks.11.0.skip_connection.bias', 'model.diffusion_model.output_blocks.11.1.norm.weight', 'model.diffusion_model.output_blocks.11.1.norm.bias', 'model.diffusion_model.output_blocks.11.1.proj_in.weight', 'model.diffusion_model.output_blocks.11.1.proj_in.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.11.1.transf
0: ormer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.weight', 'model.diffusion_mode
0: l.output_blocks.11.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.11.1.proj_out.weight', 'model.diffusion_model.output_blocks.11.1.proj_out.bias', 'model.diffusion_model.out.0.weight', 'model.diffusion_model.out.0.bias', 'model.diffusion_model.out.1.weight', 'model.diffusion_model.out.1.bias']
0: [NeMo I 2024-05-04 05:41:36 ddpm:305] Unexpected Keys: ['model_ema.decay', 'model_ema.num_updates']
0: Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4
3: Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4
2: Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4
1: Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4
0: ----------------------------------------------------------------------------------------------------
0: distributed_backend=nccl
0: All distributed processes registered. Starting with 4 processes
0: ----------------------------------------------------------------------------------------------------
0: 
0: Global ID: 0, local ID: 0, world size: 4
0: Rank 0 before barrier
1: Global ID: 1, local ID: 1, world size: 4
1: Rank 1 before barrier
2: Global ID: 2, local ID: 2, world size: 4
2: Rank 2 before barrier
3: Global ID: 3, local ID: 3, world size: 4
3: Rank 3 before barrier
0: :::MLLOG {"namespace": "", "time_ms": 1714768915419, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 127, "samples_count": 512000}}
0: Assigned 7500 prompts for this worker.
0: :::MLLOG {"namespace": "", "time_ms": 1714771177287, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 184, "samples_count": 512000}}
3: Assigned 7500 prompts for this worker.
1: Assigned 7500 prompts for this worker.
2: Assigned 7500 prompts for this worker.
0: Calculating FID activations:   0%|          | 0/235 [00:00<?, ?it/s]Calculating FID activations:   0%|          | 1/235 [00:01<04:55,  1.26s/it]Calculating FID activations:   4%|▍         | 10/235 [00:01<00:25,  8.92it/s]Calculating FID activations:   6%|▌         | 14/235 [00:01<00:17, 12.47it/s]Calculating FID activations:   8%|▊         | 18/235 [00:01<00:13, 15.79it/s]Calculating FID activations:   9%|▉         | 22/235 [00:01<00:11, 17.78it/s]Calculating FID activations:  11%|█         | 25/235 [00:02<00:11, 18.36it/s]Calculating FID activations:  12%|█▏        | 28/235 [00:02<00:10, 18.98it/s]Calculating FID activations:  13%|█▎        | 31/235 [00:02<00:09, 20.65it/s]Calculating FID activations:  15%|█▍        | 35/235 [00:02<00:08, 22.30it/s]Calculating FID activations:  17%|█▋        | 39/235 [00:02<00:08, 23.37it/s]Calculating FID activations:  18%|█▊        | 43/235 [00:02<00:08, 23.93it/s]Calculating FID activations:  20%|██        | 47/235 [00:02<00:
0: 07, 26.61it/s]Calculating FID activations:  21%|██▏       | 50/235 [00:02<00:07, 25.00it/s]Calculating FID activations:  23%|██▎       | 53/235 [00:03<00:07, 24.03it/s]Calculating FID activations:  24%|██▍       | 57/235 [00:03<00:06, 27.36it/s]Calculating FID activations:  26%|██▌       | 61/235 [00:03<00:07, 23.94it/s]Calculating FID activations:  28%|██▊       | 65/235 [00:03<00:06, 24.56it/s]Calculating FID activations:  29%|██▉       | 69/235 [00:03<00:06, 23.89it/s]Calculating FID activations:  31%|███       | 73/235 [00:03<00:06, 25.56it/s]Calculating FID activations:  33%|███▎      | 77/235 [00:04<00:05, 27.96it/s]Calculating FID activations:  35%|███▍      | 82/235 [00:04<00:04, 32.06it/s]Calculating FID activations:  37%|███▋      | 87/235 [00:04<00:04, 35.72it/s]Calculating FID activations:  39%|███▊      | 91/235 [00:04<00:04, 31.28it/s]Calculating FID activations:  40%|████      | 95/235 [00:04<00:05, 27
0: .18it/s]Calculating FID activations:  42%|████▏     | 98/235 [00:04<00:05, 26.47it/s]Calculating FID activations:  43%|████▎     | 101/235 [00:04<00:06, 22.20it/s]Calculating FID activations:  44%|████▍     | 104/235 [00:05<00:06, 19.61it/s]Calculating FID activations:  46%|████▋     | 109/235 [00:05<00:05, 25.13it/s]Calculating FID activations:  48%|████▊     | 112/235 [00:05<00:04, 25.27it/s]Calculating FID activations:  49%|████▉     | 116/235 [00:05<00:04, 27.25it/s]Calculating FID activations:  51%|█████     | 120/235 [00:05<00:04, 28.20it/s]Calculating FID activations:  53%|█████▎    | 124/235 [00:05<00:03, 28.95it/s]Calculating FID activations:  54%|█████▍    | 128/235 [00:05<00:03, 30.14it/s]Calculating FID activations:  56%|█████▌    | 132/235 [00:05<00:03, 30.30it/s]Calculating FID activations:  58%|█████▊    | 136/235 [00:06<00:03, 30.92it/s]Calculating FID activations: 
0:  60%|█████▉    | 140/235 [00:06<00:03, 30.13it/s]Calculating FID activations:  61%|██████▏   | 144/235 [00:06<00:02, 30.92it/s]Calculating FID activations:  63%|██████▎   | 148/235 [00:06<00:02, 31.22it/s]Calculating FID activations:  65%|██████▍   | 152/235 [00:06<00:02, 31.20it/s]Calculating FID activations:  66%|██████▋   | 156/235 [00:06<00:02, 30.89it/s]Calculating FID activations:  68%|██████▊   | 160/235 [00:06<00:02, 31.73it/s]Calculating FID activations:  70%|██████▉   | 164/235 [00:07<00:02, 31.62it/s]Calculating FID activations:  71%|███████▏  | 168/235 [00:07<00:02, 32.13it/s]Calculating FID activations:  73%|███████▎  | 172/235 [00:07<00:01, 34.03it/s]Calculating FID activations:  75%|███████▍  | 176/235 [00:07<00:01, 35.48it/s]Calculating FID activations:  77%|███████▋  | 181/235 [00:07<00:01, 38.07it/s]Calculating FID activati
0: ons:  80%|███████▉  | 187/235 [00:07<00:01, 44.08it/s]Calculating FID activations:  82%|████████▏ | 192/235 [00:07<00:01, 39.98it/s]Calculating FID activations:  84%|████████▍ | 197/235 [00:07<00:00, 40.94it/s]Calculating FID activations:  87%|████████▋ | 204/235 [00:07<00:00, 42.63it/s]Calculating FID activations:  89%|████████▉ | 209/235 [00:08<00:00, 43.43it/s]Calculating FID activations:  91%|█████████ | 214/235 [00:08<00:00, 44.76it/s]Calculating FID activations:  93%|█████████▎| 219/235 [00:08<00:00, 44.13it/s]Calculating FID activations:  95%|█████████▌| 224/235 [00:08<00:00, 41.28it/s]Calculating FID activations:  97%|█████████▋| 229/235 [00:08<00:00, 42.59it/s]Calculating FID activations: 100%|█████████▉| 234/235 [00:08<00:00, 42.76it/s]Calculating FID activations: 100%|██████████| 235/23
0: 5 [00:09<00:00, 25.69it/s]
0: Computed feature activations of size torch.Size([7500, 2048])
0: :::MLLOG {"namespace": "", "time_ms": 1714771209126, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 224.87549626647186, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 228, "samples_count": 512000, "metric": "FID"}}
0: :::MLLOG {"namespace": "", "time_ms": 1714771315392, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06466106325387955, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 258, "samples_count": 512000, "metric": "CLIP"}}
0: Using 16bit Automatic Mixed Precision (AMP)
0: GPU available: True (cuda), used: True
0: TPU available: False, using: 0 TPU cores
0: IPU available: False, using: 0 IPUs
0: HPU available: False, using: 0 HPUs
0: [NeMo W 2024-05-04 06:21:55 utils:296] Loading from .ckpt checkpoint for inference is experimental! It doesn't support models with model parallelism!
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tensor_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: pipeline_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: virtual_pipeline_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: sequence_parallel in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: context_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: use_cpu_initialization in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: gradient_accumulation_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: use_te_rng_tracker in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_overlap_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_overlap_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_overlap_rs_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: overlap_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: batch_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: defer_embedding_wgrad_compute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading_activations in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading_weights in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1161] hidden_size not found in {'precision': 16, 'micro_batch_size': 64, 'global_batch_size': 256, 'linear_start': 0.00085, 'linear_end': 0.012, 'num_timesteps_cond': 1, 'log_every_t': 200, 'timesteps': 1000, 'first_stage_key': 'images_moments', 'cond_stage_key': 'clip_encoded', 'image_size': 64, 'channels': 4, 'cond_stage_trainable': False, 'conditioning_key': 'crossattn', 'monitor': 'val/loss_simple_ema', 'scale_factor': 0.18215, 'use_ema': False, 'scale_by_std': False, 'ckpt_path': '/checkpoints/sd/512-base-ema.ckpt', 'load_vae': True, 'load_unet': False, 'load_encoder': True, 'ignore_keys': [], 'parameterization': 'v', 'clip_denoised': True, 'load_only_unet': False, 'cosine_s': 0.008, 'given_betas': None, 'original_elbo_weight': 0, 'v_posterior': 0, 'l_simple_weight': 1, 'use_positional_encodings': False, 'learn_logvar': False, 'logvar_init': 0, 'beta_schedule': 'linear', 'loss_type': 'l2', 'channels_last': True, 'concat_mode': True, 'cond_stage_forward': No
0: ne, 'text_embedding_dropout_rate': 0.0, 'fused_opt': True, 'inductor': False, 'inductor_cudagraphs': False, 'capture_cudagraph_iters': 15, 'unet_config': {'_target_': 'nemo.collections.multimodal.modules.stable_diffusion.diffusionmodules.openaimodel.UNetModel', 'from_pretrained': None, 'from_NeMo': None, 'image_size': 32, 'in_channels': 4, 'out_channels': 4, 'model_channels': 320, 'attention_resolutions': [4, 2, 1], 'num_res_blocks': 2, 'channel_mult': [1, 2, 4, 4], 'num_head_channels': 64, 'use_spatial_transformer': True, 'use_linear_in_transformer': True, 'transformer_depth': 1, 'context_dim': 1024, 'use_checkpoint': False, 'legacy': False, 'use_flash_attention': True, 'resblock_gn_groups': 16, 'unet_precision': 'fp16', 'timesteps': 1000}, 'first_stage_config': {'_target_': 'nemo.collections.multimodal.models.text_to_image.stable_diffusion.ldm.autoencoder.AutoencoderKL', 'from_pretrained': None, 'embed_dim': 4, 'monitor': 'val/rec_loss', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 256, 'in
0: _channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0}, 'lossconfig': {'target': 'torch.nn.Identity'}}, 'cond_stage_config': {'_target_': 'nemo.collections.multimodal.modules.stable_diffusion.encoders.modules.FrozenOpenCLIPEmbedder', 'arch': 'ViT-H-14', 'version': 'laion2b_s32b_b79k', 'freeze': True, 'layer': 'penultimate', 'cache_dir': '/checkpoints/clip'}, 'seed': 9456, 'resume_from_checkpoint': None, 'apex_transformer_log_level': 30, 'gradient_as_bucket_view': True, 'ddp_overlap': False, 'nsys_profile': {'enabled': False, 'start_step': 10, 'end_step': 10, 'ranks': [0], 'gen_shape': False}, 'data': {'num_workers': 16, 'train': {'dataset_path': '/datasets/laion-400m/webdataset-moments-filtered-encoded/*.tar', 'augmentations': {'resize_smallest_side': 512, 'center_crop_h_w': '512, 512', 'horizontal_flip': False}, 'filterings': None}, 'webdataset': {'infinite_sampler': True, 'local_root_path': '/datasets/laion-400m/webdataset-moments-filtere
0: d-encoded'}}, 'optim': {'name': 'distributed_fused_adam', 'lr': 2.56e-05, 'weight_decay': 0.0, 'betas': [0.9, 0.999], 'sched': {'name': 'WarmupHoldPolicy', 'warmup_steps': 1000, 'hold_steps': 10000000000000}, 'bucket_cap_mb': 288, 'overlap_grad_sync': True, 'overlap_param_sync': False, 'contiguous_grad_buffer': True, 'contiguous_param_buffer': True, 'store_params': True, 'dtype': 'torch.float32', 'grad_sync_dtype': 'torch.float16', 'param_sync_dtype': 'torch.float16', 'capturable': True, 'distribute_within_nodes': True}, 'target': 'nemo.collections.multimodal.models.text_to_image.stable_diffusion.ldm.ddpm.MegatronLatentDiffusion', 'nemo_version': '2.0.0b0'}. Set this in model_parallel_config if using pipeline parallelism.
0: [rank0]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
0: [NeMo I 2024-05-04 06:21:57 megatron_init:265] Rank 0 has data parallel group : [0, 1, 2, 3]
0: [NeMo I 2024-05-04 06:21:57 megatron_init:271] Rank 0 has combined group of data parallel and context parallel : [0, 1, 2, 3]
0: [NeMo I 2024-05-04 06:21:57 megatron_init:276] All data parallel group ranks with context parallel combined: [[0, 1, 2, 3]]
0: [NeMo I 2024-05-04 06:21:57 megatron_init:279] Ranks 0 has data parallel rank: 0
0: [NeMo I 2024-05-04 06:21:57 megatron_init:287] Rank 0 has context parallel group: [0]
0: [NeMo I 2024-05-04 06:21:57 megatron_init:290] All context parallel group ranks: [[0], [1], [2], [3]]
0: [NeMo I 2024-05-04 06:21:57 megatron_init:291] Ranks 0 has context parallel rank: 0
0: [NeMo I 2024-05-04 06:21:57 megatron_init:298] Rank 0 has model parallel group: [0]
0: [NeMo I 2024-05-04 06:21:57 megatron_init:299] All model parallel group ranks: [[0], [1], [2], [3]]
0: [NeMo I 2024-05-04 06:21:57 megatron_init:308] Rank 0 has tensor model parallel group: [0]
0: [NeMo I 2024-05-04 06:21:57 megatron_init:312] All tensor model parallel group ranks: [[0], [1], [2], [3]]
0: [NeMo I 2024-05-04 06:21:57 megatron_init:313] Rank 0 has tensor model parallel rank: 0
0: [NeMo I 2024-05-04 06:21:57 megatron_init:333] Rank 0 has pipeline model parallel group: [0]
0: [NeMo I 2024-05-04 06:21:57 megatron_init:345] Rank 0 has embedding group: [0]
0: [NeMo I 2024-05-04 06:21:57 megatron_init:351] All pipeline model parallel group ranks: [[0], [1], [2], [3]]
0: [NeMo I 2024-05-04 06:21:57 megatron_init:352] Rank 0 has pipeline model parallel rank 0
0: [NeMo I 2024-05-04 06:21:57 megatron_init:353] All embedding group ranks: [[0], [1], [2], [3]]
0: [NeMo I 2024-05-04 06:21:57 megatron_init:354] Rank 0 has embedding rank: 0
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tensor_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: pipeline_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: virtual_pipeline_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: sequence_parallel in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: context_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: use_cpu_initialization in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: gradient_accumulation_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: use_te_rng_tracker in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_overlap_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_overlap_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_overlap_rs_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: overlap_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: batch_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: defer_embedding_wgrad_compute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading_activations in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading_weights in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 06:21:57 megatron_base_model:1161] hidden_size not found in {'precision': 16, 'micro_batch_size': 64, 'global_batch_size': 256, 'linear_start': 0.00085, 'linear_end': 0.012, 'num_timesteps_cond': 1, 'log_every_t': 200, 'timesteps': 1000, 'first_stage_key': 'images_moments', 'cond_stage_key': 'clip_encoded', 'image_size': 64, 'channels': 4, 'cond_stage_trainable': False, 'conditioning_key': 'crossattn', 'monitor': 'val/loss_simple_ema', 'scale_factor': 0.18215, 'use_ema': False, 'scale_by_std': False, 'ckpt_path': '/checkpoints/sd/512-base-ema.ckpt', 'load_vae': True, 'load_unet': False, 'load_encoder': True, 'ignore_keys': [], 'parameterization': 'v', 'clip_denoised': True, 'load_only_unet': False, 'cosine_s': 0.008, 'given_betas': None, 'original_elbo_weight': 0, 'v_posterior': 0, 'l_simple_weight': 1, 'use_positional_encodings': False, 'learn_logvar': False, 'logvar_init': 0, 'beta_schedule': 'linear', 'loss_type': 'l2', 'channels_last': True, 'concat_mode': True, 'cond_stage_forward': No
0: ne, 'text_embedding_dropout_rate': 0.0, 'fused_opt': True, 'inductor': False, 'inductor_cudagraphs': False, 'capture_cudagraph_iters': 15, 'unet_config': {'_target_': 'nemo.collections.multimodal.modules.stable_diffusion.diffusionmodules.openaimodel.UNetModel', 'from_pretrained': None, 'from_NeMo': None, 'image_size': 32, 'in_channels': 4, 'out_channels': 4, 'model_channels': 320, 'attention_resolutions': [4, 2, 1], 'num_res_blocks': 2, 'channel_mult': [1, 2, 4, 4], 'num_head_channels': 64, 'use_spatial_transformer': True, 'use_linear_in_transformer': True, 'transformer_depth': 1, 'context_dim': 1024, 'use_checkpoint': False, 'legacy': False, 'use_flash_attention': True, 'resblock_gn_groups': 16, 'unet_precision': 'fp16', 'timesteps': 1000}, 'first_stage_config': {'_target_': 'nemo.collections.multimodal.models.text_to_image.stable_diffusion.ldm.autoencoder.AutoencoderKL', 'from_pretrained': None, 'embed_dim': 4, 'monitor': 'val/rec_loss', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 256, 'in
0: _channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0}, 'lossconfig': {'target': 'torch.nn.Identity'}}, 'cond_stage_config': {'_target_': 'nemo.collections.multimodal.modules.stable_diffusion.encoders.modules.FrozenOpenCLIPEmbedder', 'arch': 'ViT-H-14', 'version': 'laion2b_s32b_b79k', 'freeze': True, 'layer': 'penultimate', 'cache_dir': '/checkpoints/clip'}, 'seed': 9456, 'resume_from_checkpoint': None, 'apex_transformer_log_level': 30, 'gradient_as_bucket_view': True, 'ddp_overlap': False, 'nsys_profile': {'enabled': False, 'start_step': 10, 'end_step': 10, 'ranks': [0], 'gen_shape': False}, 'data': {'num_workers': 16, 'train': {'dataset_path': '/datasets/laion-400m/webdataset-moments-filtered-encoded/*.tar', 'augmentations': {'resize_smallest_side': 512, 'center_crop_h_w': '512, 512', 'horizontal_flip': False}, 'filterings': None}, 'webdataset': {'infinite_sampler': True, 'local_root_path': '/datasets/laion-400m/webdataset-moments-filtere
0: d-encoded'}}, 'optim': {'name': 'distributed_fused_adam', 'lr': 2.56e-05, 'weight_decay': 0.0, 'betas': [0.9, 0.999], 'sched': {'name': 'WarmupHoldPolicy', 'warmup_steps': 1000, 'hold_steps': 10000000000000}, 'bucket_cap_mb': 288, 'overlap_grad_sync': True, 'overlap_param_sync': False, 'contiguous_grad_buffer': True, 'contiguous_param_buffer': True, 'store_params': True, 'dtype': 'torch.float32', 'grad_sync_dtype': 'torch.float16', 'param_sync_dtype': 'torch.float16', 'capturable': True, 'distribute_within_nodes': True}, 'target': 'nemo.collections.multimodal.models.text_to_image.stable_diffusion.ldm.ddpm.MegatronLatentDiffusion', 'nemo_version': '2.0.0b0'}. Set this in model_parallel_config if using pipeline parallelism.
0: [NeMo I 2024-05-04 06:21:57 ddpm:130] LatentDiffusion: Running in v-prediction mode
0: [NeMo I 2024-05-04 06:21:57 attention:436] constructing SpatialTransformer of depth 1 w/ 320 channels and 5 heads
0: [NeMo I 2024-05-04 06:21:57 attention:436] constructing SpatialTransformer of depth 1 w/ 320 channels and 5 heads
0: [NeMo I 2024-05-04 06:21:57 attention:436] constructing SpatialTransformer of depth 1 w/ 640 channels and 10 heads
1: [rank1]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
3: [rank3]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
2: [rank2]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
0: [NeMo I 2024-05-04 06:21:57 attention:436] constructing SpatialTransformer of depth 1 w/ 640 channels and 10 heads
0: [NeMo I 2024-05-04 06:21:57 attention:436] constructing SpatialTransformer of depth 1 w/ 1280 channels and 20 heads
0: [NeMo I 2024-05-04 06:21:57 attention:436] constructing SpatialTransformer of depth 1 w/ 1280 channels and 20 heads
0: [NeMo I 2024-05-04 06:21:58 attention:436] constructing SpatialTransformer of depth 1 w/ 1280 channels and 20 heads
0: [NeMo I 2024-05-04 06:21:59 attention:436] constructing SpatialTransformer of depth 1 w/ 1280 channels and 20 heads
0: [NeMo I 2024-05-04 06:21:59 attention:436] constructing SpatialTransformer of depth 1 w/ 1280 channels and 20 heads
0: [NeMo I 2024-05-04 06:22:00 attention:436] constructing SpatialTransformer of depth 1 w/ 1280 channels and 20 heads
0: [NeMo I 2024-05-04 06:22:00 attention:436] constructing SpatialTransformer of depth 1 w/ 640 channels and 10 heads
0: [NeMo I 2024-05-04 06:22:00 attention:436] constructing SpatialTransformer of depth 1 w/ 640 channels and 10 heads
0: [NeMo I 2024-05-04 06:22:00 attention:436] constructing SpatialTransformer of depth 1 w/ 640 channels and 10 heads
0: [NeMo I 2024-05-04 06:22:00 attention:436] constructing SpatialTransformer of depth 1 w/ 320 channels and 5 heads
0: [NeMo I 2024-05-04 06:22:00 attention:436] constructing SpatialTransformer of depth 1 w/ 320 channels and 5 heads
0: [NeMo I 2024-05-04 06:22:00 attention:436] constructing SpatialTransformer of depth 1 w/ 320 channels and 5 heads
0: [NeMo I 2024-05-04 06:22:01 utils:92] DiffusionWrapper has 865.91 M params.
0: [NeMo I 2024-05-04 06:22:01 ddpm:168] Use system random generator since CUDA graph enabled
0: making attention of type 'vanilla' with 512 in_channels
0: Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
0: making attention of type 'vanilla' with 512 in_channels
0: Downloading clip with ViT-H-14 laion2b_s32b_b79k /checkpoints/clip
0: Loaded ViT-H-14 model config.
1: Computed feature activations of size torch.Size([7500, 2048])
1: making attention of type 'vanilla' with 512 in_channels
1: Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
1: making attention of type 'vanilla' with 512 in_channels
1: Downloading clip with ViT-H-14 laion2b_s32b_b79k /checkpoints/clip
1: Loaded ViT-H-14 model config.
3: Computed feature activations of size torch.Size([7500, 2048])
3: making attention of type 'vanilla' with 512 in_channels
3: Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
3: making attention of type 'vanilla' with 512 in_channels
3: Downloading clip with ViT-H-14 laion2b_s32b_b79k /checkpoints/clip
3: Loaded ViT-H-14 model config.
2: Computed feature activations of size torch.Size([7500, 2048])
2: making attention of type 'vanilla' with 512 in_channels
2: Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
2: making attention of type 'vanilla' with 512 in_channels
2: Downloading clip with ViT-H-14 laion2b_s32b_b79k /checkpoints/clip
2: Loaded ViT-H-14 model config.
0: Loading pretrained ViT-H-14 weights (laion2b_s32b_b79k).
3: Loading pretrained ViT-H-14 weights (laion2b_s32b_b79k).
1: Loading pretrained ViT-H-14 weights (laion2b_s32b_b79k).
2: Loading pretrained ViT-H-14 weights (laion2b_s32b_b79k).
0: [NeMo I 2024-05-04 06:22:10 ddpm:260] Loading /checkpoints/sd/512-base-ema.ckpt
0: [NeMo I 2024-05-04 06:22:10 ddpm:261] It has 1242 entries
0: [NeMo I 2024-05-04 06:22:10 ddpm:262] Existing model has 1240 entries
0: [NeMo I 2024-05-04 06:22:10 ddpm:296] Deleted 686 keys from `model.diffusion_model` state_dict.
0: [NeMo I 2024-05-04 06:22:10 ddpm:301] Restored from /checkpoints/sd/512-base-ema.ckpt with 686 missing and 2 unexpected keys
0: [NeMo I 2024-05-04 06:22:10 ddpm:303] Missing Keys: ['model.diffusion_model.time_embed.0.weight', 'model.diffusion_model.time_embed.0.bias', 'model.diffusion_model.time_embed.2.weight', 'model.diffusion_model.time_embed.2.bias', 'model.diffusion_model.input_blocks.0.0.weight', 'model.diffusion_model.input_blocks.0.0.bias', 'model.diffusion_model.input_blocks.1.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.1.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.1.0.in_layers.1.weight', 'model.diffusion_model.input_blocks.1.0.in_layers.1.bias', 'model.diffusion_model.input_blocks.1.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.1.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.1.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.1.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.1.0.out_layers.2.weight', 'model.diffusion_model.input_blocks.1.0.out_layers.2.bias', 'model.diffusion_model.input_blocks.1.1.norm.weight', 'model.diffusion_model.input_blocks.1.1
0: .norm.bias', 'model.diffusion_model.input_blocks.1.1.proj_in.weight', 'model.diffusion_model.input_blocks.1.1.proj_in.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_k.weight', 'mod
0: el.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.1.1.proj_out.weight', 'model.diffusion_model.input_blocks.1.1.proj_out.bias', 'model.diffusion_model.input_blocks.2.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.2.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.2.0.in_layers.1.weight', 'model.diffusion_model.input_block
0: s.2.0.in_layers.1.bias', 'model.diffusion_model.input_blocks.2.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.2.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.2.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.2.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.2.0.out_layers.2.weight', 'model.diffusion_model.input_blocks.2.0.out_layers.2.bias', 'model.diffusion_model.input_blocks.2.1.norm.weight', 'model.diffusion_model.input_blocks.2.1.norm.bias', 'model.diffusion_model.input_blocks.2.1.proj_in.weight', 'model.diffusion_model.input_blocks.2.1.proj_in.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.bias', 'mod
0: el.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2.bi
0: as', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.2.1.proj_out.weight', 'model.diffusion_model.input_blocks.2.1.proj_out.bias', 'model.diffusion_model.input_blocks.3.0.op.weight', 'model.diffusion_model.input_blocks.3.0.op.bias', 'model.diffusion_model.input_blocks.4.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.4.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.4.0.in_layers.1.weight', 'model.diffusion_model.input_blocks.4.0.in_layers.1.bias', 'model.diffusion_model.input_blocks.4.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.4.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.4.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.4.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.4.0.out_layers.2.weight', 'model.diffusion_model.input_blocks.4.0.out_layers.2.bias', 'model.diffusion_model.input_blocks.4.0.skip_co
0: nnection.weight', 'model.diffusion_model.input_blocks.4.0.skip_connection.bias', 'model.diffusion_model.input_blocks.4.1.norm.weight', 'model.diffusion_model.input_blocks.4.1.norm.bias', 'model.diffusion_model.input_blocks.4.1.proj_in.weight', 'model.diffusion_model.input_blocks.4.1.proj_in.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2
0: .bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.4.1.proj_out.weight', 'model.diffusion_model.input_blocks.4.1.proj_out.bias', 'model.diffusion_model.input_blocks.5.0.i
0: n_layers.0.weight', 'model.diffusion_model.input_blocks.5.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.5.0.in_layers.1.weight', 'model.diffusion_model.input_blocks.5.0.in_layers.1.bias', 'model.diffusion_model.input_blocks.5.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.5.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.5.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.5.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.5.0.out_layers.2.weight', 'model.diffusion_model.input_blocks.5.0.out_layers.2.bias', 'model.diffusion_model.input_blocks.5.1.norm.weight', 'model.diffusion_model.input_blocks.5.1.norm.bias', 'model.diffusion_model.input_blocks.5.1.proj_in.weight', 'model.diffusion_model.input_blocks.5.1.proj_in.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_v.weight'
0: , 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.5.1.trans
0: former_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.5.1.proj_out.weight', 'model.diffusion_model.input_blocks.5.1.proj_out.bias', 'model.diffusion_model.input_blocks.6.0.op.weight', 'model.diffusion_model.input_blocks.6.0.op.bias', 'model.diffusion_model.input_blocks.7.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.7.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.7.0.in_layers.1.weight', 'model.diffusion_model.input_blocks.7.0.in_layers.1.bias', 'model.diffusion_model.input_blocks.7.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.7.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.7.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.7.0.out_layers.0.bi
0: as', 'model.diffusion_model.input_blocks.7.0.out_layers.2.weight', 'model.diffusion_model.input_blocks.7.0.out_layers.2.bias', 'model.diffusion_model.input_blocks.7.0.skip_connection.weight', 'model.diffusion_model.input_blocks.7.0.skip_connection.bias', 'model.diffusion_model.input_blocks.7.1.norm.weight', 'model.diffusion_model.input_blocks.7.1.norm.bias', 'model.diffusion_model.input_blocks.7.1.proj_in.weight', 'model.diffusion_model.input_blocks.7.1.proj_in.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.7.1.transformer_bloc
0: ks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blo
0: cks.0.norm3.bias', 'model.diffusion_model.input_blocks.7.1.proj_out.weight', 'model.diffusion_model.input_blocks.7.1.proj_out.bias', 'model.diffusion_model.input_blocks.8.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.8.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.8.0.in_layers.1.weight', 'model.diffusion_model.input_blocks.8.0.in_layers.1.bias', 'model.diffusion_model.input_blocks.8.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.8.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.8.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.8.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.8.0.out_layers.2.weight', 'model.diffusion_model.input_blocks.8.0.out_layers.2.bias', 'model.diffusion_model.input_blocks.8.1.norm.weight', 'model.diffusion_model.input_blocks.8.1.norm.bias', 'model.diffusion_model.input_blocks.8.1.proj_in.weight', 'model.diffusion_model.input_blocks.8.1.proj_in.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.
0: to_q.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_b
0: locks.8.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.8.1.proj_out.weight', 'model.diffusion_model.input_blocks.8.1.proj_out.bias', 'model.diffusion_model.input_blocks.9.0.op.weight', 'model.diffusion_model.input_blocks.9.0.op.bias', 'model.diffusion_model.input_blocks.10.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.10.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.10.0.in_layers.1.weight', 'model.diffusion_model.input_blocks.10.0.in_layers.1.bias', 'model.diffusion_model.input_blocks.10.0.emb_layers.1.weight'
0: , 'model.diffusion_model.input_blocks.10.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.10.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.10.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.10.0.out_layers.2.weight', 'model.diffusion_model.input_blocks.10.0.out_layers.2.bias', 'model.diffusion_model.input_blocks.11.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.11.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.11.0.in_layers.1.weight', 'model.diffusion_model.input_blocks.11.0.in_layers.1.bias', 'model.diffusion_model.input_blocks.11.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.11.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.11.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.11.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.11.0.out_layers.2.weight', 'model.diffusion_model.input_blocks.11.0.out_layers.2.bias', 'model.diffusion_model.middle_block.0.in_layers.0.weight', 'model.diffusion_model.middle_block.0.
0: in_layers.0.bias', 'model.diffusion_model.middle_block.0.in_layers.1.weight', 'model.diffusion_model.middle_block.0.in_layers.1.bias', 'model.diffusion_model.middle_block.0.emb_layers.1.weight', 'model.diffusion_model.middle_block.0.emb_layers.1.bias', 'model.diffusion_model.middle_block.0.out_layers.0.weight', 'model.diffusion_model.middle_block.0.out_layers.0.bias', 'model.diffusion_model.middle_block.0.out_layers.2.weight', 'model.diffusion_model.middle_block.0.out_layers.2.bias', 'model.diffusion_model.middle_block.1.norm.weight', 'model.diffusion_model.middle_block.1.norm.bias', 'model.diffusion_model.middle_block.1.proj_in.weight', 'model.diffusion_model.middle_block.1.proj_in.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.weight', 'mode
0: l.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm2.weight', 'model.diffus
0: ion_model.middle_block.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.middle_block.1.proj_out.weight', 'model.diffusion_model.middle_block.1.proj_out.bias', 'model.diffusion_model.middle_block.2.in_layers.0.weight', 'model.diffusion_model.middle_block.2.in_layers.0.bias', 'model.diffusion_model.middle_block.2.in_layers.1.weight', 'model.diffusion_model.middle_block.2.in_layers.1.bias', 'model.diffusion_model.middle_block.2.emb_layers.1.weight', 'model.diffusion_model.middle_block.2.emb_layers.1.bias', 'model.diffusion_model.middle_block.2.out_layers.0.weight', 'model.diffusion_model.middle_block.2.out_layers.0.bias', 'model.diffusion_model.middle_block.2.out_layers.2.weight', 'model.diffusion_model.middle_block.2.out_layers.2.bias', 'model.diffusion_model.output_blocks.0.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.0.0.in_layers.0.bias', '
0: model.diffusion_model.output_blocks.0.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.0.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.0.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.0.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.0.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.0.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.0.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.0.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.0.0.skip_connection.weight', 'model.diffusion_model.output_blocks.0.0.skip_connection.bias', 'model.diffusion_model.output_blocks.1.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.1.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.1.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.1.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.1.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.1.0.emb_layers.1.bias', 'model.diffusion_model.output_blo
0: cks.1.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.1.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.1.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.1.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.1.0.skip_connection.weight', 'model.diffusion_model.output_blocks.1.0.skip_connection.bias', 'model.diffusion_model.output_blocks.2.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.2.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.2.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.2.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.2.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.2.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.2.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.2.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.2.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.2.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.2.0.skip_connection.weight
0: ', 'model.diffusion_model.output_blocks.2.0.skip_connection.bias', 'model.diffusion_model.output_blocks.2.1.conv.weight', 'model.diffusion_model.output_blocks.2.1.conv.bias', 'model.diffusion_model.output_blocks.3.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.3.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.3.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.3.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.3.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.3.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.3.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.3.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.3.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.3.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.3.0.skip_connection.weight', 'model.diffusion_model.output_blocks.3.0.skip_connection.bias', 'model.diffusion_model.output_blocks.3.1.norm.weight', 'model.diffusion_model.output_blocks.3.1.norm.bi
0: as', 'model.diffusion_model.output_blocks.3.1.proj_in.weight', 'model.diffusion_model.output_blocks.3.1.proj_in.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_k.weight',
0:  'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.3.1.proj_out.weight', 'model.diffusion_model.output_blocks.3.1.proj_out.bias', 'model.diffusion_model.output_blocks.4.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.4.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.4.0.in_layers.1.weight', 'model.diffusio
0: n_model.output_blocks.4.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.4.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.4.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.4.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.4.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.4.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.4.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.4.0.skip_connection.weight', 'model.diffusion_model.output_blocks.4.0.skip_connection.bias', 'model.diffusion_model.output_blocks.4.1.norm.weight', 'model.diffusion_model.output_blocks.4.1.norm.bias', 'model.diffusion_model.output_blocks.4.1.proj_in.weight', 'model.diffusion_model.output_blocks.4.1.proj_in.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_v.weight', 'model.di
0: ffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.4.1.tra
0: nsformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.4.1.proj_out.weight', 'model.diffusion_model.output_blocks.4.1.proj_out.bias', 'model.diffusion_model.output_blocks.5.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.5.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.5.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.5.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.5.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.5.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.5.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.5.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.5.0.out_layers.2.weight', 'model.diffusion_m
0: odel.output_blocks.5.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.5.0.skip_connection.weight', 'model.diffusion_model.output_blocks.5.0.skip_connection.bias', 'model.diffusion_model.output_blocks.5.1.norm.weight', 'model.diffusion_model.output_blocks.5.1.norm.bias', 'model.diffusion_model.output_blocks.5.1.proj_in.weight', 'model.diffusion_model.output_blocks.5.1.proj_in.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.5.1.tran
0: sformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.5.
0: 1.proj_out.weight', 'model.diffusion_model.output_blocks.5.1.proj_out.bias', 'model.diffusion_model.output_blocks.5.2.conv.weight', 'model.diffusion_model.output_blocks.5.2.conv.bias', 'model.diffusion_model.output_blocks.6.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.6.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.6.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.6.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.6.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.6.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.6.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.6.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.6.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.6.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.6.0.skip_connection.weight', 'model.diffusion_model.output_blocks.6.0.skip_connection.bias', 'model.diffusion_model.output_blocks.6.1.norm.weight', 'model.diffusion_model.output_blocks.6
0: .1.norm.bias', 'model.diffusion_model.output_blocks.6.1.proj_in.weight', 'model.diffusion_model.output_blocks.6.1.proj_in.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_
0: k.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.6.1.proj_out.weight', 'model.diffusion_model.output_blocks.6.1.proj_out.bias', 'model.diffusion_model.output_blocks.7.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.7.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.7.0.in_layers.1.weight', 'mode
0: l.diffusion_model.output_blocks.7.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.7.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.7.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.7.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.7.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.7.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.7.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.7.0.skip_connection.weight', 'model.diffusion_model.output_blocks.7.0.skip_connection.bias', 'model.diffusion_model.output_blocks.7.1.norm.weight', 'model.diffusion_model.output_blocks.7.1.norm.bias', 'model.diffusion_model.output_blocks.7.1.proj_in.weight', 'model.diffusion_model.output_blocks.7.1.proj_in.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_v.weight',
0:  'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_bloc
0: ks.7.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.7.1.proj_out.weight', 'model.diffusion_model.output_blocks.7.1.proj_out.bias', 'model.diffusion_model.output_blocks.8.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.8.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.8.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.8.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.8.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.8.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.8.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.8.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.8.0.out_layers.2.weight', 'model.d
0: iffusion_model.output_blocks.8.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.8.0.skip_connection.weight', 'model.diffusion_model.output_blocks.8.0.skip_connection.bias', 'model.diffusion_model.output_blocks.8.1.norm.weight', 'model.diffusion_model.output_blocks.8.1.norm.bias', 'model.diffusion_model.output_blocks.8.1.proj_in.weight', 'model.diffusion_model.output_blocks.8.1.proj_in.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_block
0: s.8.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output
0: _blocks.8.1.proj_out.weight', 'model.diffusion_model.output_blocks.8.1.proj_out.bias', 'model.diffusion_model.output_blocks.8.2.conv.weight', 'model.diffusion_model.output_blocks.8.2.conv.bias', 'model.diffusion_model.output_blocks.9.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.9.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.9.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.9.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.9.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.9.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.9.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.9.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.9.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.9.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.9.0.skip_connection.weight', 'model.diffusion_model.output_blocks.9.0.skip_connection.bias', 'model.diffusion_model.output_blocks.9.1.norm.weight', 'model.diffusion_model.outpu
0: t_blocks.9.1.norm.bias', 'model.diffusion_model.output_blocks.9.1.proj_in.weight', 'model.diffusion_model.output_blocks.9.1.proj_in.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0
0: .attn2.to_k.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.9.1.proj_out.weight', 'model.diffusion_model.output_blocks.9.1.proj_out.bias', 'model.diffusion_model.output_blocks.10.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.10.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.10.0.in_layers.1.w
0: eight', 'model.diffusion_model.output_blocks.10.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.10.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.10.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.10.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.10.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.10.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.10.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.10.0.skip_connection.weight', 'model.diffusion_model.output_blocks.10.0.skip_connection.bias', 'model.diffusion_model.output_blocks.10.1.norm.weight', 'model.diffusion_model.output_blocks.10.1.norm.bias', 'model.diffusion_model.output_blocks.10.1.proj_in.weight', 'model.diffusion_model.output_blocks.10.1.proj_in.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.10.1.transformer
0: _blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.we
0: ight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.10.1.proj_out.weight', 'model.diffusion_model.output_blocks.10.1.proj_out.bias', 'model.diffusion_model.output_blocks.11.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.11.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.11.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.11.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.11.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.11.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.11.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.11.0.out_layers.0.bias', 'model.diffusio
0: n_model.output_blocks.11.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.11.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.11.0.skip_connection.weight', 'model.diffusion_model.output_blocks.11.0.skip_connection.bias', 'model.diffusion_model.output_blocks.11.1.norm.weight', 'model.diffusion_model.output_blocks.11.1.norm.bias', 'model.diffusion_model.output_blocks.11.1.proj_in.weight', 'model.diffusion_model.output_blocks.11.1.proj_in.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.11.1.transf
0: ormer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.weight', 'model.diffusion_mode
0: l.output_blocks.11.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.11.1.proj_out.weight', 'model.diffusion_model.output_blocks.11.1.proj_out.bias', 'model.diffusion_model.out.0.weight', 'model.diffusion_model.out.0.bias', 'model.diffusion_model.out.1.weight', 'model.diffusion_model.out.1.bias']
0: [NeMo I 2024-05-04 06:22:10 ddpm:305] Unexpected Keys: ['model_ema.decay', 'model_ema.num_updates']
0: Global ID: 0, local ID: 0, world size: 4
0: Rank 0 before barrier
1: Global ID: 1, local ID: 1, world size: 4
1: Rank 1 before barrier
2: Global ID: 2, local ID: 2, world size: 4
2: Rank 2 before barrier
3: Global ID: 3, local ID: 3, world size: 4
3: Rank 3 before barrier
0: :::MLLOG {"namespace": "", "time_ms": 1714771332420, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 127, "samples_count": 1024000}}
0: Assigned 7500 prompts for this worker.
0: :::MLLOG {"namespace": "", "time_ms": 1714773595582, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 184, "samples_count": 1024000}}
2: Assigned 7500 prompts for this worker.
1: Assigned 7500 prompts for this worker.
3: Assigned 7500 prompts for this worker.
0: Calculating FID activations:   0%|          | 0/235 [00:00<?, ?it/s]Calculating FID activations:   0%|          | 1/235 [00:01<04:08,  1.06s/it]Calculating FID activations:   2%|▏         | 5/235 [00:01<00:43,  5.30it/s]Calculating FID activations:   4%|▍         | 9/235 [00:01<00:23,  9.62it/s]Calculating FID activations:   6%|▌         | 13/235 [00:01<00:16, 13.69it/s]Calculating FID activations:   7%|▋         | 17/235 [00:01<00:13, 16.62it/s]Calculating FID activations:   9%|▉         | 21/235 [00:01<00:11, 18.73it/s]Calculating FID activations:  11%|█         | 25/235 [00:01<00:10, 20.82it/s]Calculating FID activations:  12%|█▏        | 29/235 [00:02<00:09, 22.01it/s]Calculating FID activations:  14%|█▍        | 33/235 [00:02<00:08, 22.87it/s]Calculating FID activations:  16%|█▌        | 37/235 [00:02<00:08, 23.69it/s]Calculating FID activations:  17%|█▋        | 41/235 [00:02<00:08, 23.69it/s]Calculating FID activations:  19%|█▉        | 45/235 [00:02<00:07, 
0: 24.26it/s]Calculating FID activations:  21%|██        | 49/235 [00:02<00:07, 24.65it/s]Calculating FID activations:  23%|██▎       | 53/235 [00:03<00:07, 24.68it/s]Calculating FID activations:  24%|██▍       | 57/235 [00:03<00:07, 24.89it/s]Calculating FID activations:  26%|██▌       | 61/235 [00:03<00:06, 25.09it/s]Calculating FID activations:  28%|██▊       | 65/235 [00:03<00:06, 25.22it/s]Calculating FID activations:  29%|██▉       | 69/235 [00:03<00:06, 25.27it/s]Calculating FID activations:  31%|███       | 73/235 [00:03<00:06, 25.10it/s]Calculating FID activations:  33%|███▎      | 77/235 [00:04<00:06, 25.55it/s]Calculating FID activations:  34%|███▍      | 81/235 [00:04<00:06, 25.65it/s]Calculating FID activations:  36%|███▌      | 84/235 [00:04<00:05, 26.47it/s]Calculating FID activations:  37%|███▋      | 88/235 [00:04<00:05, 28.78it/s]Calculating FID activations:  39%|███▊      | 91/235 [00:04<00:05, 28.41it/
0: s]Calculating FID activations:  41%|████      | 96/235 [00:04<00:04, 32.93it/s]Calculating FID activations:  43%|████▎     | 100/235 [00:04<00:04, 29.06it/s]Calculating FID activations:  44%|████▍     | 104/235 [00:04<00:04, 28.41it/s]Calculating FID activations:  47%|████▋     | 110/235 [00:05<00:03, 34.92it/s]Calculating FID activations:  49%|████▉     | 115/235 [00:05<00:03, 37.60it/s]Calculating FID activations:  51%|█████     | 120/235 [00:05<00:03, 37.12it/s]Calculating FID activations:  53%|█████▎    | 125/235 [00:05<00:02, 39.68it/s]Calculating FID activations:  56%|█████▌    | 131/235 [00:05<00:02, 43.88it/s]Calculating FID activations:  58%|█████▊    | 136/235 [00:05<00:02, 39.64it/s]Calculating FID activations:  60%|██████    | 141/235 [00:05<00:02, 41.65it/s]Calculating FID activations:  62%|██████▏   | 146/235 [00:05<00:02, 42.04it/s]Calculating FID activations:  65%
0: |██████▍   | 152/235 [00:06<00:01, 41.83it/s]Calculating FID activations:  67%|██████▋   | 157/235 [00:06<00:01, 40.70it/s]Calculating FID activations:  70%|██████▉   | 164/235 [00:06<00:01, 42.06it/s]Calculating FID activations:  72%|███████▏  | 169/235 [00:06<00:01, 42.44it/s]Calculating FID activations:  74%|███████▍  | 174/235 [00:06<00:01, 43.68it/s]Calculating FID activations:  76%|███████▌  | 179/235 [00:06<00:01, 44.82it/s]Calculating FID activations:  78%|███████▊  | 184/235 [00:06<00:01, 41.37it/s]Calculating FID activations:  80%|████████  | 189/235 [00:06<00:01, 42.38it/s]Calculating FID activations:  83%|████████▎ | 194/235 [00:06<00:00, 43.67it/s]Calculating FID activations:  85%|████████▍ | 199/235 [00:07<00:00, 44.29it/s]Calculating FID activations:  87%|████████▋ | 204/235 [00:07<00:00, 42.79it/s]Calculating 
0: FID activations:  89%|████████▉ | 209/235 [00:07<00:00, 44.07it/s]Calculating FID activations:  91%|█████████ | 214/235 [00:07<00:00, 44.74it/s]Calculating FID activations:  93%|█████████▎| 219/235 [00:07<00:00, 45.41it/s]Calculating FID activations:  95%|█████████▌| 224/235 [00:07<00:00, 41.68it/s]Calculating FID activations:  97%|█████████▋| 229/235 [00:07<00:00, 41.94it/s]Calculating FID activations: 100%|██████████| 235/235 [00:07<00:00, 45.84it/s]Calculating FID activations: 100%|██████████| 235/235 [00:08<00:00, 27.70it/s]
0: Computed feature activations of size torch.Size([7500, 2048])
0: :::MLLOG {"namespace": "", "time_ms": 1714773621682, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 156.0945997546757, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 228, "samples_count": 1024000, "metric": "FID"}}
0: :::MLLOG {"namespace": "", "time_ms": 1714773729425, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.11317988485097885, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 258, "samples_count": 1024000, "metric": "CLIP"}}
0: Using 16bit Automatic Mixed Precision (AMP)
0: GPU available: True (cuda), used: True
0: TPU available: False, using: 0 TPU cores
0: IPU available: False, using: 0 IPUs
0: HPU available: False, using: 0 HPUs
0: [NeMo W 2024-05-04 07:02:09 utils:296] Loading from .ckpt checkpoint for inference is experimental! It doesn't support models with model parallelism!
1: [rank1]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
2: [rank2]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
3: [rank3]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tensor_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: pipeline_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: virtual_pipeline_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: sequence_parallel in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: context_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: use_cpu_initialization in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: gradient_accumulation_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: use_te_rng_tracker in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_overlap_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_overlap_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_overlap_rs_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: overlap_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: batch_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: defer_embedding_wgrad_compute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading_activations in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading_weights in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1161] hidden_size not found in {'precision': 16, 'micro_batch_size': 64, 'global_batch_size': 256, 'linear_start': 0.00085, 'linear_end': 0.012, 'num_timesteps_cond': 1, 'log_every_t': 200, 'timesteps': 1000, 'first_stage_key': 'images_moments', 'cond_stage_key': 'clip_encoded', 'image_size': 64, 'channels': 4, 'cond_stage_trainable': False, 'conditioning_key': 'crossattn', 'monitor': 'val/loss_simple_ema', 'scale_factor': 0.18215, 'use_ema': False, 'scale_by_std': False, 'ckpt_path': '/checkpoints/sd/512-base-ema.ckpt', 'load_vae': True, 'load_unet': False, 'load_encoder': True, 'ignore_keys': [], 'parameterization': 'v', 'clip_denoised': True, 'load_only_unet': False, 'cosine_s': 0.008, 'given_betas': None, 'original_elbo_weight': 0, 'v_posterior': 0, 'l_simple_weight': 1, 'use_positional_encodings': False, 'learn_logvar': False, 'logvar_init': 0, 'beta_schedule': 'linear', 'loss_type': 'l2', 'channels_last': True, 'concat_mode': True, 'cond_stage_forward': No
0: ne, 'text_embedding_dropout_rate': 0.0, 'fused_opt': True, 'inductor': False, 'inductor_cudagraphs': False, 'capture_cudagraph_iters': 15, 'unet_config': {'_target_': 'nemo.collections.multimodal.modules.stable_diffusion.diffusionmodules.openaimodel.UNetModel', 'from_pretrained': None, 'from_NeMo': None, 'image_size': 32, 'in_channels': 4, 'out_channels': 4, 'model_channels': 320, 'attention_resolutions': [4, 2, 1], 'num_res_blocks': 2, 'channel_mult': [1, 2, 4, 4], 'num_head_channels': 64, 'use_spatial_transformer': True, 'use_linear_in_transformer': True, 'transformer_depth': 1, 'context_dim': 1024, 'use_checkpoint': False, 'legacy': False, 'use_flash_attention': True, 'resblock_gn_groups': 16, 'unet_precision': 'fp16', 'timesteps': 1000}, 'first_stage_config': {'_target_': 'nemo.collections.multimodal.models.text_to_image.stable_diffusion.ldm.autoencoder.AutoencoderKL', 'from_pretrained': None, 'embed_dim': 4, 'monitor': 'val/rec_loss', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 256, 'in
0: _channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0}, 'lossconfig': {'target': 'torch.nn.Identity'}}, 'cond_stage_config': {'_target_': 'nemo.collections.multimodal.modules.stable_diffusion.encoders.modules.FrozenOpenCLIPEmbedder', 'arch': 'ViT-H-14', 'version': 'laion2b_s32b_b79k', 'freeze': True, 'layer': 'penultimate', 'cache_dir': '/checkpoints/clip'}, 'seed': 9456, 'resume_from_checkpoint': None, 'apex_transformer_log_level': 30, 'gradient_as_bucket_view': True, 'ddp_overlap': False, 'nsys_profile': {'enabled': False, 'start_step': 10, 'end_step': 10, 'ranks': [0], 'gen_shape': False}, 'data': {'num_workers': 16, 'train': {'dataset_path': '/datasets/laion-400m/webdataset-moments-filtered-encoded/*.tar', 'augmentations': {'resize_smallest_side': 512, 'center_crop_h_w': '512, 512', 'horizontal_flip': False}, 'filterings': None}, 'webdataset': {'infinite_sampler': True, 'local_root_path': '/datasets/laion-400m/webdataset-moments-filtere
0: d-encoded'}}, 'optim': {'name': 'distributed_fused_adam', 'lr': 2.56e-05, 'weight_decay': 0.0, 'betas': [0.9, 0.999], 'sched': {'name': 'WarmupHoldPolicy', 'warmup_steps': 1000, 'hold_steps': 10000000000000}, 'bucket_cap_mb': 288, 'overlap_grad_sync': True, 'overlap_param_sync': False, 'contiguous_grad_buffer': True, 'contiguous_param_buffer': True, 'store_params': True, 'dtype': 'torch.float32', 'grad_sync_dtype': 'torch.float16', 'param_sync_dtype': 'torch.float16', 'capturable': True, 'distribute_within_nodes': True}, 'target': 'nemo.collections.multimodal.models.text_to_image.stable_diffusion.ldm.ddpm.MegatronLatentDiffusion', 'nemo_version': '2.0.0b0'}. Set this in model_parallel_config if using pipeline parallelism.
0: [rank0]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
0: [NeMo I 2024-05-04 07:02:12 megatron_init:265] Rank 0 has data parallel group : [0, 1, 2, 3]
0: [NeMo I 2024-05-04 07:02:12 megatron_init:271] Rank 0 has combined group of data parallel and context parallel : [0, 1, 2, 3]
0: [NeMo I 2024-05-04 07:02:12 megatron_init:276] All data parallel group ranks with context parallel combined: [[0, 1, 2, 3]]
0: [NeMo I 2024-05-04 07:02:12 megatron_init:279] Ranks 0 has data parallel rank: 0
0: [NeMo I 2024-05-04 07:02:12 megatron_init:287] Rank 0 has context parallel group: [0]
0: [NeMo I 2024-05-04 07:02:12 megatron_init:290] All context parallel group ranks: [[0], [1], [2], [3]]
0: [NeMo I 2024-05-04 07:02:12 megatron_init:291] Ranks 0 has context parallel rank: 0
0: [NeMo I 2024-05-04 07:02:12 megatron_init:298] Rank 0 has model parallel group: [0]
0: [NeMo I 2024-05-04 07:02:12 megatron_init:299] All model parallel group ranks: [[0], [1], [2], [3]]
0: [NeMo I 2024-05-04 07:02:12 megatron_init:308] Rank 0 has tensor model parallel group: [0]
0: [NeMo I 2024-05-04 07:02:12 megatron_init:312] All tensor model parallel group ranks: [[0], [1], [2], [3]]
0: [NeMo I 2024-05-04 07:02:12 megatron_init:313] Rank 0 has tensor model parallel rank: 0
0: [NeMo I 2024-05-04 07:02:12 megatron_init:333] Rank 0 has pipeline model parallel group: [0]
0: [NeMo I 2024-05-04 07:02:12 megatron_init:345] Rank 0 has embedding group: [0]
0: [NeMo I 2024-05-04 07:02:12 megatron_init:351] All pipeline model parallel group ranks: [[0], [1], [2], [3]]
0: [NeMo I 2024-05-04 07:02:12 megatron_init:352] Rank 0 has pipeline model parallel rank 0
0: [NeMo I 2024-05-04 07:02:12 megatron_init:353] All embedding group ranks: [[0], [1], [2], [3]]
0: [NeMo I 2024-05-04 07:02:12 megatron_init:354] Rank 0 has embedding rank: 0
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tensor_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: pipeline_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: virtual_pipeline_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: sequence_parallel in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: context_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: use_cpu_initialization in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: gradient_accumulation_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: use_te_rng_tracker in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_overlap_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_overlap_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_overlap_rs_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: overlap_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: batch_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: defer_embedding_wgrad_compute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading_activations in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading_weights in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:02:12 megatron_base_model:1161] hidden_size not found in {'precision': 16, 'micro_batch_size': 64, 'global_batch_size': 256, 'linear_start': 0.00085, 'linear_end': 0.012, 'num_timesteps_cond': 1, 'log_every_t': 200, 'timesteps': 1000, 'first_stage_key': 'images_moments', 'cond_stage_key': 'clip_encoded', 'image_size': 64, 'channels': 4, 'cond_stage_trainable': False, 'conditioning_key': 'crossattn', 'monitor': 'val/loss_simple_ema', 'scale_factor': 0.18215, 'use_ema': False, 'scale_by_std': False, 'ckpt_path': '/checkpoints/sd/512-base-ema.ckpt', 'load_vae': True, 'load_unet': False, 'load_encoder': True, 'ignore_keys': [], 'parameterization': 'v', 'clip_denoised': True, 'load_only_unet': False, 'cosine_s': 0.008, 'given_betas': None, 'original_elbo_weight': 0, 'v_posterior': 0, 'l_simple_weight': 1, 'use_positional_encodings': False, 'learn_logvar': False, 'logvar_init': 0, 'beta_schedule': 'linear', 'loss_type': 'l2', 'channels_last': True, 'concat_mode': True, 'cond_stage_forward': No
0: ne, 'text_embedding_dropout_rate': 0.0, 'fused_opt': True, 'inductor': False, 'inductor_cudagraphs': False, 'capture_cudagraph_iters': 15, 'unet_config': {'_target_': 'nemo.collections.multimodal.modules.stable_diffusion.diffusionmodules.openaimodel.UNetModel', 'from_pretrained': None, 'from_NeMo': None, 'image_size': 32, 'in_channels': 4, 'out_channels': 4, 'model_channels': 320, 'attention_resolutions': [4, 2, 1], 'num_res_blocks': 2, 'channel_mult': [1, 2, 4, 4], 'num_head_channels': 64, 'use_spatial_transformer': True, 'use_linear_in_transformer': True, 'transformer_depth': 1, 'context_dim': 1024, 'use_checkpoint': False, 'legacy': False, 'use_flash_attention': True, 'resblock_gn_groups': 16, 'unet_precision': 'fp16', 'timesteps': 1000}, 'first_stage_config': {'_target_': 'nemo.collections.multimodal.models.text_to_image.stable_diffusion.ldm.autoencoder.AutoencoderKL', 'from_pretrained': None, 'embed_dim': 4, 'monitor': 'val/rec_loss', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 256, 'in
0: _channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0}, 'lossconfig': {'target': 'torch.nn.Identity'}}, 'cond_stage_config': {'_target_': 'nemo.collections.multimodal.modules.stable_diffusion.encoders.modules.FrozenOpenCLIPEmbedder', 'arch': 'ViT-H-14', 'version': 'laion2b_s32b_b79k', 'freeze': True, 'layer': 'penultimate', 'cache_dir': '/checkpoints/clip'}, 'seed': 9456, 'resume_from_checkpoint': None, 'apex_transformer_log_level': 30, 'gradient_as_bucket_view': True, 'ddp_overlap': False, 'nsys_profile': {'enabled': False, 'start_step': 10, 'end_step': 10, 'ranks': [0], 'gen_shape': False}, 'data': {'num_workers': 16, 'train': {'dataset_path': '/datasets/laion-400m/webdataset-moments-filtered-encoded/*.tar', 'augmentations': {'resize_smallest_side': 512, 'center_crop_h_w': '512, 512', 'horizontal_flip': False}, 'filterings': None}, 'webdataset': {'infinite_sampler': True, 'local_root_path': '/datasets/laion-400m/webdataset-moments-filtere
0: d-encoded'}}, 'optim': {'name': 'distributed_fused_adam', 'lr': 2.56e-05, 'weight_decay': 0.0, 'betas': [0.9, 0.999], 'sched': {'name': 'WarmupHoldPolicy', 'warmup_steps': 1000, 'hold_steps': 10000000000000}, 'bucket_cap_mb': 288, 'overlap_grad_sync': True, 'overlap_param_sync': False, 'contiguous_grad_buffer': True, 'contiguous_param_buffer': True, 'store_params': True, 'dtype': 'torch.float32', 'grad_sync_dtype': 'torch.float16', 'param_sync_dtype': 'torch.float16', 'capturable': True, 'distribute_within_nodes': True}, 'target': 'nemo.collections.multimodal.models.text_to_image.stable_diffusion.ldm.ddpm.MegatronLatentDiffusion', 'nemo_version': '2.0.0b0'}. Set this in model_parallel_config if using pipeline parallelism.
0: [NeMo I 2024-05-04 07:02:12 ddpm:130] LatentDiffusion: Running in v-prediction mode
0: [NeMo I 2024-05-04 07:02:12 attention:436] constructing SpatialTransformer of depth 1 w/ 320 channels and 5 heads
0: [NeMo I 2024-05-04 07:02:12 attention:436] constructing SpatialTransformer of depth 1 w/ 320 channels and 5 heads
0: [NeMo I 2024-05-04 07:02:12 attention:436] constructing SpatialTransformer of depth 1 w/ 640 channels and 10 heads
0: [NeMo I 2024-05-04 07:02:12 attention:436] constructing SpatialTransformer of depth 1 w/ 640 channels and 10 heads
0: [NeMo I 2024-05-04 07:02:12 attention:436] constructing SpatialTransformer of depth 1 w/ 1280 channels and 20 heads
0: [NeMo I 2024-05-04 07:02:13 attention:436] constructing SpatialTransformer of depth 1 w/ 1280 channels and 20 heads
0: [NeMo I 2024-05-04 07:02:13 attention:436] constructing SpatialTransformer of depth 1 w/ 1280 channels and 20 heads
0: [NeMo I 2024-05-04 07:02:14 attention:436] constructing SpatialTransformer of depth 1 w/ 1280 channels and 20 heads
0: [NeMo I 2024-05-04 07:02:15 attention:436] constructing SpatialTransformer of depth 1 w/ 1280 channels and 20 heads
0: [NeMo I 2024-05-04 07:02:15 attention:436] constructing SpatialTransformer of depth 1 w/ 1280 channels and 20 heads
1: Computed feature activations of size torch.Size([7500, 2048])
1: making attention of type 'vanilla' with 512 in_channels
1: Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
1: making attention of type 'vanilla' with 512 in_channels
1: Downloading clip with ViT-H-14 laion2b_s32b_b79k /checkpoints/clip
1: Loaded ViT-H-14 model config.
2: Computed feature activations of size torch.Size([7500, 2048])
2: making attention of type 'vanilla' with 512 in_channels
2: Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
2: making attention of type 'vanilla' with 512 in_channels
2: Downloading clip with ViT-H-14 laion2b_s32b_b79k /checkpoints/clip
2: Loaded ViT-H-14 model config.
0: [NeMo I 2024-05-04 07:02:15 attention:436] constructing SpatialTransformer of depth 1 w/ 640 channels and 10 heads
3: Computed feature activations of size torch.Size([7500, 2048])
3: making attention of type 'vanilla' with 512 in_channels
3: Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
3: making attention of type 'vanilla' with 512 in_channels
3: Downloading clip with ViT-H-14 laion2b_s32b_b79k /checkpoints/clip
3: Loaded ViT-H-14 model config.
0: [NeMo I 2024-05-04 07:02:16 attention:436] constructing SpatialTransformer of depth 1 w/ 640 channels and 10 heads
0: [NeMo I 2024-05-04 07:02:16 attention:436] constructing SpatialTransformer of depth 1 w/ 640 channels and 10 heads
0: [NeMo I 2024-05-04 07:02:16 attention:436] constructing SpatialTransformer of depth 1 w/ 320 channels and 5 heads
0: [NeMo I 2024-05-04 07:02:16 attention:436] constructing SpatialTransformer of depth 1 w/ 320 channels and 5 heads
0: [NeMo I 2024-05-04 07:02:16 attention:436] constructing SpatialTransformer of depth 1 w/ 320 channels and 5 heads
0: [NeMo I 2024-05-04 07:02:16 utils:92] DiffusionWrapper has 865.91 M params.
0: [NeMo I 2024-05-04 07:02:16 ddpm:168] Use system random generator since CUDA graph enabled
0: making attention of type 'vanilla' with 512 in_channels
0: Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
0: making attention of type 'vanilla' with 512 in_channels
0: Downloading clip with ViT-H-14 laion2b_s32b_b79k /checkpoints/clip
0: Loaded ViT-H-14 model config.
1: Loading pretrained ViT-H-14 weights (laion2b_s32b_b79k).
2: Loading pretrained ViT-H-14 weights (laion2b_s32b_b79k).
3: Loading pretrained ViT-H-14 weights (laion2b_s32b_b79k).
0: Loading pretrained ViT-H-14 weights (laion2b_s32b_b79k).
0: [NeMo I 2024-05-04 07:02:26 ddpm:260] Loading /checkpoints/sd/512-base-ema.ckpt
0: [NeMo I 2024-05-04 07:02:26 ddpm:261] It has 1242 entries
0: [NeMo I 2024-05-04 07:02:26 ddpm:262] Existing model has 1240 entries
0: [NeMo I 2024-05-04 07:02:26 ddpm:296] Deleted 686 keys from `model.diffusion_model` state_dict.
0: [NeMo I 2024-05-04 07:02:26 ddpm:301] Restored from /checkpoints/sd/512-base-ema.ckpt with 686 missing and 2 unexpected keys
0: [NeMo I 2024-05-04 07:02:26 ddpm:303] Missing Keys: ['model.diffusion_model.time_embed.0.weight', 'model.diffusion_model.time_embed.0.bias', 'model.diffusion_model.time_embed.2.weight', 'model.diffusion_model.time_embed.2.bias', 'model.diffusion_model.input_blocks.0.0.weight', 'model.diffusion_model.input_blocks.0.0.bias', 'model.diffusion_model.input_blocks.1.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.1.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.1.0.in_layers.1.weight', 'model.diffusion_model.input_blocks.1.0.in_layers.1.bias', 'model.diffusion_model.input_blocks.1.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.1.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.1.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.1.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.1.0.out_layers.2.weight', 'model.diffusion_model.input_blocks.1.0.out_layers.2.bias', 'model.diffusion_model.input_blocks.1.1.norm.weight', 'model.diffusion_model.input_blocks.1.1
0: .norm.bias', 'model.diffusion_model.input_blocks.1.1.proj_in.weight', 'model.diffusion_model.input_blocks.1.1.proj_in.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_k.weight', 'mod
0: el.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.1.1.proj_out.weight', 'model.diffusion_model.input_blocks.1.1.proj_out.bias', 'model.diffusion_model.input_blocks.2.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.2.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.2.0.in_layers.1.weight', 'model.diffusion_model.input_block
0: s.2.0.in_layers.1.bias', 'model.diffusion_model.input_blocks.2.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.2.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.2.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.2.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.2.0.out_layers.2.weight', 'model.diffusion_model.input_blocks.2.0.out_layers.2.bias', 'model.diffusion_model.input_blocks.2.1.norm.weight', 'model.diffusion_model.input_blocks.2.1.norm.bias', 'model.diffusion_model.input_blocks.2.1.proj_in.weight', 'model.diffusion_model.input_blocks.2.1.proj_in.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.bias', 'mod
0: el.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2.bi
0: as', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.2.1.proj_out.weight', 'model.diffusion_model.input_blocks.2.1.proj_out.bias', 'model.diffusion_model.input_blocks.3.0.op.weight', 'model.diffusion_model.input_blocks.3.0.op.bias', 'model.diffusion_model.input_blocks.4.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.4.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.4.0.in_layers.1.weight', 'model.diffusion_model.input_blocks.4.0.in_layers.1.bias', 'model.diffusion_model.input_blocks.4.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.4.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.4.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.4.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.4.0.out_layers.2.weight', 'model.diffusion_model.input_blocks.4.0.out_layers.2.bias', 'model.diffusion_model.input_blocks.4.0.skip_co
0: nnection.weight', 'model.diffusion_model.input_blocks.4.0.skip_connection.bias', 'model.diffusion_model.input_blocks.4.1.norm.weight', 'model.diffusion_model.input_blocks.4.1.norm.bias', 'model.diffusion_model.input_blocks.4.1.proj_in.weight', 'model.diffusion_model.input_blocks.4.1.proj_in.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2
0: .bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.4.1.proj_out.weight', 'model.diffusion_model.input_blocks.4.1.proj_out.bias', 'model.diffusion_model.input_blocks.5.0.i
0: n_layers.0.weight', 'model.diffusion_model.input_blocks.5.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.5.0.in_layers.1.weight', 'model.diffusion_model.input_blocks.5.0.in_layers.1.bias', 'model.diffusion_model.input_blocks.5.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.5.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.5.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.5.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.5.0.out_layers.2.weight', 'model.diffusion_model.input_blocks.5.0.out_layers.2.bias', 'model.diffusion_model.input_blocks.5.1.norm.weight', 'model.diffusion_model.input_blocks.5.1.norm.bias', 'model.diffusion_model.input_blocks.5.1.proj_in.weight', 'model.diffusion_model.input_blocks.5.1.proj_in.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_v.weight'
0: , 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.5.1.trans
0: former_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.5.1.proj_out.weight', 'model.diffusion_model.input_blocks.5.1.proj_out.bias', 'model.diffusion_model.input_blocks.6.0.op.weight', 'model.diffusion_model.input_blocks.6.0.op.bias', 'model.diffusion_model.input_blocks.7.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.7.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.7.0.in_layers.1.weight', 'model.diffusion_model.input_blocks.7.0.in_layers.1.bias', 'model.diffusion_model.input_blocks.7.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.7.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.7.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.7.0.out_layers.0.bi
0: as', 'model.diffusion_model.input_blocks.7.0.out_layers.2.weight', 'model.diffusion_model.input_blocks.7.0.out_layers.2.bias', 'model.diffusion_model.input_blocks.7.0.skip_connection.weight', 'model.diffusion_model.input_blocks.7.0.skip_connection.bias', 'model.diffusion_model.input_blocks.7.1.norm.weight', 'model.diffusion_model.input_blocks.7.1.norm.bias', 'model.diffusion_model.input_blocks.7.1.proj_in.weight', 'model.diffusion_model.input_blocks.7.1.proj_in.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.7.1.transformer_bloc
0: ks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blo
0: cks.0.norm3.bias', 'model.diffusion_model.input_blocks.7.1.proj_out.weight', 'model.diffusion_model.input_blocks.7.1.proj_out.bias', 'model.diffusion_model.input_blocks.8.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.8.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.8.0.in_layers.1.weight', 'model.diffusion_model.input_blocks.8.0.in_layers.1.bias', 'model.diffusion_model.input_blocks.8.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.8.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.8.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.8.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.8.0.out_layers.2.weight', 'model.diffusion_model.input_blocks.8.0.out_layers.2.bias', 'model.diffusion_model.input_blocks.8.1.norm.weight', 'model.diffusion_model.input_blocks.8.1.norm.bias', 'model.diffusion_model.input_blocks.8.1.proj_in.weight', 'model.diffusion_model.input_blocks.8.1.proj_in.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.
0: to_q.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_b
0: locks.8.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.8.1.proj_out.weight', 'model.diffusion_model.input_blocks.8.1.proj_out.bias', 'model.diffusion_model.input_blocks.9.0.op.weight', 'model.diffusion_model.input_blocks.9.0.op.bias', 'model.diffusion_model.input_blocks.10.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.10.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.10.0.in_layers.1.weight', 'model.diffusion_model.input_blocks.10.0.in_layers.1.bias', 'model.diffusion_model.input_blocks.10.0.emb_layers.1.weight'
0: , 'model.diffusion_model.input_blocks.10.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.10.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.10.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.10.0.out_layers.2.weight', 'model.diffusion_model.input_blocks.10.0.out_layers.2.bias', 'model.diffusion_model.input_blocks.11.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.11.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.11.0.in_layers.1.weight', 'model.diffusion_model.input_blocks.11.0.in_layers.1.bias', 'model.diffusion_model.input_blocks.11.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.11.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.11.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.11.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.11.0.out_layers.2.weight', 'model.diffusion_model.input_blocks.11.0.out_layers.2.bias', 'model.diffusion_model.middle_block.0.in_layers.0.weight', 'model.diffusion_model.middle_block.0.
0: in_layers.0.bias', 'model.diffusion_model.middle_block.0.in_layers.1.weight', 'model.diffusion_model.middle_block.0.in_layers.1.bias', 'model.diffusion_model.middle_block.0.emb_layers.1.weight', 'model.diffusion_model.middle_block.0.emb_layers.1.bias', 'model.diffusion_model.middle_block.0.out_layers.0.weight', 'model.diffusion_model.middle_block.0.out_layers.0.bias', 'model.diffusion_model.middle_block.0.out_layers.2.weight', 'model.diffusion_model.middle_block.0.out_layers.2.bias', 'model.diffusion_model.middle_block.1.norm.weight', 'model.diffusion_model.middle_block.1.norm.bias', 'model.diffusion_model.middle_block.1.proj_in.weight', 'model.diffusion_model.middle_block.1.proj_in.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.weight', 'mode
0: l.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm2.weight', 'model.diffus
0: ion_model.middle_block.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.middle_block.1.proj_out.weight', 'model.diffusion_model.middle_block.1.proj_out.bias', 'model.diffusion_model.middle_block.2.in_layers.0.weight', 'model.diffusion_model.middle_block.2.in_layers.0.bias', 'model.diffusion_model.middle_block.2.in_layers.1.weight', 'model.diffusion_model.middle_block.2.in_layers.1.bias', 'model.diffusion_model.middle_block.2.emb_layers.1.weight', 'model.diffusion_model.middle_block.2.emb_layers.1.bias', 'model.diffusion_model.middle_block.2.out_layers.0.weight', 'model.diffusion_model.middle_block.2.out_layers.0.bias', 'model.diffusion_model.middle_block.2.out_layers.2.weight', 'model.diffusion_model.middle_block.2.out_layers.2.bias', 'model.diffusion_model.output_blocks.0.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.0.0.in_layers.0.bias', '
0: model.diffusion_model.output_blocks.0.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.0.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.0.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.0.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.0.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.0.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.0.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.0.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.0.0.skip_connection.weight', 'model.diffusion_model.output_blocks.0.0.skip_connection.bias', 'model.diffusion_model.output_blocks.1.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.1.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.1.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.1.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.1.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.1.0.emb_layers.1.bias', 'model.diffusion_model.output_blo
0: cks.1.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.1.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.1.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.1.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.1.0.skip_connection.weight', 'model.diffusion_model.output_blocks.1.0.skip_connection.bias', 'model.diffusion_model.output_blocks.2.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.2.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.2.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.2.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.2.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.2.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.2.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.2.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.2.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.2.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.2.0.skip_connection.weight
0: ', 'model.diffusion_model.output_blocks.2.0.skip_connection.bias', 'model.diffusion_model.output_blocks.2.1.conv.weight', 'model.diffusion_model.output_blocks.2.1.conv.bias', 'model.diffusion_model.output_blocks.3.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.3.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.3.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.3.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.3.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.3.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.3.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.3.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.3.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.3.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.3.0.skip_connection.weight', 'model.diffusion_model.output_blocks.3.0.skip_connection.bias', 'model.diffusion_model.output_blocks.3.1.norm.weight', 'model.diffusion_model.output_blocks.3.1.norm.bi
0: as', 'model.diffusion_model.output_blocks.3.1.proj_in.weight', 'model.diffusion_model.output_blocks.3.1.proj_in.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_k.weight',
0:  'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.3.1.proj_out.weight', 'model.diffusion_model.output_blocks.3.1.proj_out.bias', 'model.diffusion_model.output_blocks.4.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.4.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.4.0.in_layers.1.weight', 'model.diffusio
0: n_model.output_blocks.4.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.4.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.4.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.4.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.4.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.4.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.4.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.4.0.skip_connection.weight', 'model.diffusion_model.output_blocks.4.0.skip_connection.bias', 'model.diffusion_model.output_blocks.4.1.norm.weight', 'model.diffusion_model.output_blocks.4.1.norm.bias', 'model.diffusion_model.output_blocks.4.1.proj_in.weight', 'model.diffusion_model.output_blocks.4.1.proj_in.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_v.weight', 'model.di
0: ffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.4.1.tra
0: nsformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.4.1.proj_out.weight', 'model.diffusion_model.output_blocks.4.1.proj_out.bias', 'model.diffusion_model.output_blocks.5.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.5.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.5.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.5.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.5.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.5.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.5.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.5.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.5.0.out_layers.2.weight', 'model.diffusion_m
0: odel.output_blocks.5.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.5.0.skip_connection.weight', 'model.diffusion_model.output_blocks.5.0.skip_connection.bias', 'model.diffusion_model.output_blocks.5.1.norm.weight', 'model.diffusion_model.output_blocks.5.1.norm.bias', 'model.diffusion_model.output_blocks.5.1.proj_in.weight', 'model.diffusion_model.output_blocks.5.1.proj_in.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.5.1.tran
0: sformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.5.
0: 1.proj_out.weight', 'model.diffusion_model.output_blocks.5.1.proj_out.bias', 'model.diffusion_model.output_blocks.5.2.conv.weight', 'model.diffusion_model.output_blocks.5.2.conv.bias', 'model.diffusion_model.output_blocks.6.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.6.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.6.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.6.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.6.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.6.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.6.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.6.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.6.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.6.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.6.0.skip_connection.weight', 'model.diffusion_model.output_blocks.6.0.skip_connection.bias', 'model.diffusion_model.output_blocks.6.1.norm.weight', 'model.diffusion_model.output_blocks.6
0: .1.norm.bias', 'model.diffusion_model.output_blocks.6.1.proj_in.weight', 'model.diffusion_model.output_blocks.6.1.proj_in.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_
0: k.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.6.1.proj_out.weight', 'model.diffusion_model.output_blocks.6.1.proj_out.bias', 'model.diffusion_model.output_blocks.7.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.7.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.7.0.in_layers.1.weight', 'mode
0: l.diffusion_model.output_blocks.7.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.7.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.7.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.7.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.7.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.7.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.7.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.7.0.skip_connection.weight', 'model.diffusion_model.output_blocks.7.0.skip_connection.bias', 'model.diffusion_model.output_blocks.7.1.norm.weight', 'model.diffusion_model.output_blocks.7.1.norm.bias', 'model.diffusion_model.output_blocks.7.1.proj_in.weight', 'model.diffusion_model.output_blocks.7.1.proj_in.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_v.weight',
0:  'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_bloc
0: ks.7.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.7.1.proj_out.weight', 'model.diffusion_model.output_blocks.7.1.proj_out.bias', 'model.diffusion_model.output_blocks.8.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.8.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.8.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.8.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.8.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.8.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.8.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.8.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.8.0.out_layers.2.weight', 'model.d
0: iffusion_model.output_blocks.8.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.8.0.skip_connection.weight', 'model.diffusion_model.output_blocks.8.0.skip_connection.bias', 'model.diffusion_model.output_blocks.8.1.norm.weight', 'model.diffusion_model.output_blocks.8.1.norm.bias', 'model.diffusion_model.output_blocks.8.1.proj_in.weight', 'model.diffusion_model.output_blocks.8.1.proj_in.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_block
0: s.8.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output
0: _blocks.8.1.proj_out.weight', 'model.diffusion_model.output_blocks.8.1.proj_out.bias', 'model.diffusion_model.output_blocks.8.2.conv.weight', 'model.diffusion_model.output_blocks.8.2.conv.bias', 'model.diffusion_model.output_blocks.9.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.9.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.9.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.9.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.9.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.9.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.9.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.9.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.9.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.9.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.9.0.skip_connection.weight', 'model.diffusion_model.output_blocks.9.0.skip_connection.bias', 'model.diffusion_model.output_blocks.9.1.norm.weight', 'model.diffusion_model.outpu
0: t_blocks.9.1.norm.bias', 'model.diffusion_model.output_blocks.9.1.proj_in.weight', 'model.diffusion_model.output_blocks.9.1.proj_in.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0
0: .attn2.to_k.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.9.1.proj_out.weight', 'model.diffusion_model.output_blocks.9.1.proj_out.bias', 'model.diffusion_model.output_blocks.10.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.10.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.10.0.in_layers.1.w
0: eight', 'model.diffusion_model.output_blocks.10.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.10.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.10.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.10.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.10.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.10.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.10.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.10.0.skip_connection.weight', 'model.diffusion_model.output_blocks.10.0.skip_connection.bias', 'model.diffusion_model.output_blocks.10.1.norm.weight', 'model.diffusion_model.output_blocks.10.1.norm.bias', 'model.diffusion_model.output_blocks.10.1.proj_in.weight', 'model.diffusion_model.output_blocks.10.1.proj_in.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.10.1.transformer
0: _blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.we
0: ight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.10.1.proj_out.weight', 'model.diffusion_model.output_blocks.10.1.proj_out.bias', 'model.diffusion_model.output_blocks.11.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.11.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.11.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.11.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.11.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.11.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.11.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.11.0.out_layers.0.bias', 'model.diffusio
0: n_model.output_blocks.11.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.11.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.11.0.skip_connection.weight', 'model.diffusion_model.output_blocks.11.0.skip_connection.bias', 'model.diffusion_model.output_blocks.11.1.norm.weight', 'model.diffusion_model.output_blocks.11.1.norm.bias', 'model.diffusion_model.output_blocks.11.1.proj_in.weight', 'model.diffusion_model.output_blocks.11.1.proj_in.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.11.1.transf
0: ormer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.weight', 'model.diffusion_mode
0: l.output_blocks.11.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.11.1.proj_out.weight', 'model.diffusion_model.output_blocks.11.1.proj_out.bias', 'model.diffusion_model.out.0.weight', 'model.diffusion_model.out.0.bias', 'model.diffusion_model.out.1.weight', 'model.diffusion_model.out.1.bias']
0: [NeMo I 2024-05-04 07:02:26 ddpm:305] Unexpected Keys: ['model_ema.decay', 'model_ema.num_updates']
0: Global ID: 0, local ID: 0, world size: 4
0: Rank 0 before barrier
1: Global ID: 1, local ID: 1, world size: 4
1: Rank 1 before barrier
2: Global ID: 2, local ID: 2, world size: 4
2: Rank 2 before barrier
3: Global ID: 3, local ID: 3, world size: 4
3: Rank 3 before barrier
0: :::MLLOG {"namespace": "", "time_ms": 1714773748035, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 127, "samples_count": 1536000}}
0: Assigned 7500 prompts for this worker.
0: :::MLLOG {"namespace": "", "time_ms": 1714775999773, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 184, "samples_count": 1536000}}
1: Assigned 7500 prompts for this worker.
3: Assigned 7500 prompts for this worker.
2: Assigned 7500 prompts for this worker.
0: Calculating FID activations:   0%|          | 0/235 [00:00<?, ?it/s]Calculating FID activations:   0%|          | 1/235 [00:00<02:58,  1.31it/s]Calculating FID activations:   1%|          | 2/235 [00:00<01:26,  2.68it/s]Calculating FID activations:   3%|▎         | 6/235 [00:01<00:26,  8.59it/s]Calculating FID activations:   4%|▍         | 10/235 [00:01<00:17, 13.05it/s]Calculating FID activations:   6%|▌         | 14/235 [00:01<00:13, 16.38it/s]Calculating FID activations:   8%|▊         | 18/235 [00:01<00:11, 18.96it/s]Calculating FID activations:   9%|▉         | 22/235 [00:01<00:10, 20.84it/s]Calculating FID activations:  11%|█         | 26/235 [00:01<00:09, 22.16it/s]Calculating FID activations:  13%|█▎        | 30/235 [00:01<00:08, 23.16it/s]Calculating FID activations:  14%|█▍        | 34/235 [00:02<00:08, 23.65it/s]Calculating FID activations:  16%|█▌        | 38/235 [00:02<00:08, 23.93it/s]Calculating FID activations:  18%|█▊        | 42/235 [00:02<00:07, 24.2
0: 8it/s]Calculating FID activations:  20%|█▉        | 46/235 [00:02<00:07, 24.49it/s]Calculating FID activations:  21%|██▏       | 50/235 [00:02<00:07, 24.54it/s]Calculating FID activations:  23%|██▎       | 54/235 [00:02<00:07, 24.86it/s]Calculating FID activations:  25%|██▍       | 58/235 [00:03<00:06, 25.38it/s]Calculating FID activations:  26%|██▋       | 62/235 [00:03<00:06, 25.88it/s]Calculating FID activations:  28%|██▊       | 66/235 [00:03<00:06, 26.18it/s]Calculating FID activations:  30%|██▉       | 70/235 [00:03<00:06, 25.90it/s]Calculating FID activations:  31%|███▏      | 74/235 [00:03<00:06, 24.61it/s]Calculating FID activations:  33%|███▎      | 78/235 [00:03<00:06, 25.70it/s]Calculating FID activations:  35%|███▍      | 82/235 [00:04<00:05, 26.30it/s]Calculating FID activations:  37%|███▋      | 87/235 [00:04<00:04, 31.35it/s]Calculating FID activations:  39%|███▊      | 91/235 [00:04<00:04, 31.64it/s]C
0: alculating FID activations:  42%|████▏     | 98/235 [00:04<00:03, 36.73it/s]Calculating FID activations:  44%|████▍     | 103/235 [00:04<00:03, 39.09it/s]Calculating FID activations:  46%|████▌     | 107/235 [00:04<00:03, 38.72it/s]Calculating FID activations:  48%|████▊     | 112/235 [00:04<00:02, 41.58it/s]Calculating FID activations:  50%|████▉     | 117/235 [00:04<00:02, 43.59it/s]Calculating FID activations:  52%|█████▏    | 122/235 [00:04<00:02, 39.98it/s]Calculating FID activations:  54%|█████▍    | 127/235 [00:05<00:02, 41.94it/s]Calculating FID activations:  56%|█████▌    | 132/235 [00:05<00:02, 43.21it/s]Calculating FID activations:  58%|█████▊    | 137/235 [00:05<00:02, 43.47it/s]Calculating FID activations:  60%|██████    | 142/235 [00:05<00:02, 40.33it/s]Calculating FID activations:  63%|██████▎   | 147/235 [00:05<00:02, 42.23it/s]Calculating FID activations:  65%
0: |██████▍   | 152/235 [00:05<00:01, 43.07it/s]Calculating FID activations:  67%|██████▋   | 157/235 [00:05<00:01, 42.30it/s]Calculating FID activations:  69%|██████▉   | 162/235 [00:05<00:01, 40.63it/s]Calculating FID activations:  71%|███████   | 167/235 [00:05<00:01, 42.31it/s]Calculating FID activations:  73%|███████▎  | 172/235 [00:06<00:01, 42.66it/s]Calculating FID activations:  75%|███████▌  | 177/235 [00:06<00:01, 43.69it/s]Calculating FID activations:  77%|███████▋  | 182/235 [00:06<00:01, 40.95it/s]Calculating FID activations:  80%|███████▉  | 187/235 [00:06<00:01, 42.01it/s]Calculating FID activations:  82%|████████▏ | 192/235 [00:06<00:01, 42.62it/s]Calculating FID activations:  84%|████████▍ | 197/235 [00:06<00:00, 44.55it/s]Calculating FID activations:  86%|████████▌ | 202/235 [00:06<00:00, 40.85it/s]Calculating FI
0: D activations:  88%|████████▊ | 207/235 [00:06<00:00, 41.98it/s]Calculating FID activations:  90%|█████████ | 212/235 [00:07<00:00, 43.43it/s]Calculating FID activations:  92%|█████████▏| 217/235 [00:07<00:00, 43.89it/s]Calculating FID activations:  94%|█████████▍| 222/235 [00:07<00:00, 40.67it/s]Calculating FID activations:  97%|█████████▋| 227/235 [00:07<00:00, 41.82it/s]Calculating FID activations:  99%|█████████▊| 232/235 [00:07<00:00, 43.08it/s]Calculating FID activations: 100%|██████████| 235/235 [00:08<00:00, 29.35it/s]
0: Computed feature activations of size torch.Size([7500, 2048])
0: :::MLLOG {"namespace": "", "time_ms": 1714776038841, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 105.12212153752716, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 228, "samples_count": 1536000, "metric": "FID"}}
0: :::MLLOG {"namespace": "", "time_ms": 1714776146271, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.1470765918493271, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 258, "samples_count": 1536000, "metric": "CLIP"}}
0: Using 16bit Automatic Mixed Precision (AMP)
0: GPU available: True (cuda), used: True
0: TPU available: False, using: 0 TPU cores
0: IPU available: False, using: 0 IPUs
0: HPU available: False, using: 0 HPUs
0: [NeMo W 2024-05-04 07:42:26 utils:296] Loading from .ckpt checkpoint for inference is experimental! It doesn't support models with model parallelism!
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tensor_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: pipeline_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: virtual_pipeline_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: sequence_parallel in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: context_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: use_cpu_initialization in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: gradient_accumulation_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: use_te_rng_tracker in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_overlap_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_overlap_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_overlap_rs_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: overlap_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: batch_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: defer_embedding_wgrad_compute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading_activations in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading_weights in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1161] hidden_size not found in {'precision': 16, 'micro_batch_size': 64, 'global_batch_size': 256, 'linear_start': 0.00085, 'linear_end': 0.012, 'num_timesteps_cond': 1, 'log_every_t': 200, 'timesteps': 1000, 'first_stage_key': 'images_moments', 'cond_stage_key': 'clip_encoded', 'image_size': 64, 'channels': 4, 'cond_stage_trainable': False, 'conditioning_key': 'crossattn', 'monitor': 'val/loss_simple_ema', 'scale_factor': 0.18215, 'use_ema': False, 'scale_by_std': False, 'ckpt_path': '/checkpoints/sd/512-base-ema.ckpt', 'load_vae': True, 'load_unet': False, 'load_encoder': True, 'ignore_keys': [], 'parameterization': 'v', 'clip_denoised': True, 'load_only_unet': False, 'cosine_s': 0.008, 'given_betas': None, 'original_elbo_weight': 0, 'v_posterior': 0, 'l_simple_weight': 1, 'use_positional_encodings': False, 'learn_logvar': False, 'logvar_init': 0, 'beta_schedule': 'linear', 'loss_type': 'l2', 'channels_last': True, 'concat_mode': True, 'cond_stage_forward': No
0: ne, 'text_embedding_dropout_rate': 0.0, 'fused_opt': True, 'inductor': False, 'inductor_cudagraphs': False, 'capture_cudagraph_iters': 15, 'unet_config': {'_target_': 'nemo.collections.multimodal.modules.stable_diffusion.diffusionmodules.openaimodel.UNetModel', 'from_pretrained': None, 'from_NeMo': None, 'image_size': 32, 'in_channels': 4, 'out_channels': 4, 'model_channels': 320, 'attention_resolutions': [4, 2, 1], 'num_res_blocks': 2, 'channel_mult': [1, 2, 4, 4], 'num_head_channels': 64, 'use_spatial_transformer': True, 'use_linear_in_transformer': True, 'transformer_depth': 1, 'context_dim': 1024, 'use_checkpoint': False, 'legacy': False, 'use_flash_attention': True, 'resblock_gn_groups': 16, 'unet_precision': 'fp16', 'timesteps': 1000}, 'first_stage_config': {'_target_': 'nemo.collections.multimodal.models.text_to_image.stable_diffusion.ldm.autoencoder.AutoencoderKL', 'from_pretrained': None, 'embed_dim': 4, 'monitor': 'val/rec_loss', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 256, 'in
0: _channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0}, 'lossconfig': {'target': 'torch.nn.Identity'}}, 'cond_stage_config': {'_target_': 'nemo.collections.multimodal.modules.stable_diffusion.encoders.modules.FrozenOpenCLIPEmbedder', 'arch': 'ViT-H-14', 'version': 'laion2b_s32b_b79k', 'freeze': True, 'layer': 'penultimate', 'cache_dir': '/checkpoints/clip'}, 'seed': 9456, 'resume_from_checkpoint': None, 'apex_transformer_log_level': 30, 'gradient_as_bucket_view': True, 'ddp_overlap': False, 'nsys_profile': {'enabled': False, 'start_step': 10, 'end_step': 10, 'ranks': [0], 'gen_shape': False}, 'data': {'num_workers': 16, 'train': {'dataset_path': '/datasets/laion-400m/webdataset-moments-filtered-encoded/*.tar', 'augmentations': {'resize_smallest_side': 512, 'center_crop_h_w': '512, 512', 'horizontal_flip': False}, 'filterings': None}, 'webdataset': {'infinite_sampler': True, 'local_root_path': '/datasets/laion-400m/webdataset-moments-filtere
0: d-encoded'}}, 'optim': {'name': 'distributed_fused_adam', 'lr': 2.56e-05, 'weight_decay': 0.0, 'betas': [0.9, 0.999], 'sched': {'name': 'WarmupHoldPolicy', 'warmup_steps': 1000, 'hold_steps': 10000000000000}, 'bucket_cap_mb': 288, 'overlap_grad_sync': True, 'overlap_param_sync': False, 'contiguous_grad_buffer': True, 'contiguous_param_buffer': True, 'store_params': True, 'dtype': 'torch.float32', 'grad_sync_dtype': 'torch.float16', 'param_sync_dtype': 'torch.float16', 'capturable': True, 'distribute_within_nodes': True}, 'target': 'nemo.collections.multimodal.models.text_to_image.stable_diffusion.ldm.ddpm.MegatronLatentDiffusion', 'nemo_version': '2.0.0b0'}. Set this in model_parallel_config if using pipeline parallelism.
0: [rank0]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
0: [NeMo I 2024-05-04 07:42:27 megatron_init:265] Rank 0 has data parallel group : [0, 1, 2, 3]
0: [NeMo I 2024-05-04 07:42:27 megatron_init:271] Rank 0 has combined group of data parallel and context parallel : [0, 1, 2, 3]
0: [NeMo I 2024-05-04 07:42:27 megatron_init:276] All data parallel group ranks with context parallel combined: [[0, 1, 2, 3]]
0: [NeMo I 2024-05-04 07:42:27 megatron_init:279] Ranks 0 has data parallel rank: 0
0: [NeMo I 2024-05-04 07:42:27 megatron_init:287] Rank 0 has context parallel group: [0]
0: [NeMo I 2024-05-04 07:42:27 megatron_init:290] All context parallel group ranks: [[0], [1], [2], [3]]
0: [NeMo I 2024-05-04 07:42:27 megatron_init:291] Ranks 0 has context parallel rank: 0
0: [NeMo I 2024-05-04 07:42:27 megatron_init:298] Rank 0 has model parallel group: [0]
0: [NeMo I 2024-05-04 07:42:27 megatron_init:299] All model parallel group ranks: [[0], [1], [2], [3]]
0: [NeMo I 2024-05-04 07:42:27 megatron_init:308] Rank 0 has tensor model parallel group: [0]
0: [NeMo I 2024-05-04 07:42:27 megatron_init:312] All tensor model parallel group ranks: [[0], [1], [2], [3]]
0: [NeMo I 2024-05-04 07:42:27 megatron_init:313] Rank 0 has tensor model parallel rank: 0
0: [NeMo I 2024-05-04 07:42:27 megatron_init:333] Rank 0 has pipeline model parallel group: [0]
0: [NeMo I 2024-05-04 07:42:27 megatron_init:345] Rank 0 has embedding group: [0]
0: [NeMo I 2024-05-04 07:42:27 megatron_init:351] All pipeline model parallel group ranks: [[0], [1], [2], [3]]
0: [NeMo I 2024-05-04 07:42:27 megatron_init:352] Rank 0 has pipeline model parallel rank 0
0: [NeMo I 2024-05-04 07:42:27 megatron_init:353] All embedding group ranks: [[0], [1], [2], [3]]
0: [NeMo I 2024-05-04 07:42:27 megatron_init:354] Rank 0 has embedding rank: 0
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tensor_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: pipeline_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: virtual_pipeline_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: sequence_parallel in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: context_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: use_cpu_initialization in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: gradient_accumulation_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: use_te_rng_tracker in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_overlap_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_overlap_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_overlap_rs_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: overlap_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: batch_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: defer_embedding_wgrad_compute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading_activations in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading_weights in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 07:42:27 megatron_base_model:1161] hidden_size not found in {'precision': 16, 'micro_batch_size': 64, 'global_batch_size': 256, 'linear_start': 0.00085, 'linear_end': 0.012, 'num_timesteps_cond': 1, 'log_every_t': 200, 'timesteps': 1000, 'first_stage_key': 'images_moments', 'cond_stage_key': 'clip_encoded', 'image_size': 64, 'channels': 4, 'cond_stage_trainable': False, 'conditioning_key': 'crossattn', 'monitor': 'val/loss_simple_ema', 'scale_factor': 0.18215, 'use_ema': False, 'scale_by_std': False, 'ckpt_path': '/checkpoints/sd/512-base-ema.ckpt', 'load_vae': True, 'load_unet': False, 'load_encoder': True, 'ignore_keys': [], 'parameterization': 'v', 'clip_denoised': True, 'load_only_unet': False, 'cosine_s': 0.008, 'given_betas': None, 'original_elbo_weight': 0, 'v_posterior': 0, 'l_simple_weight': 1, 'use_positional_encodings': False, 'learn_logvar': False, 'logvar_init': 0, 'beta_schedule': 'linear', 'loss_type': 'l2', 'channels_last': True, 'concat_mode': True, 'cond_stage_forward': No
0: ne, 'text_embedding_dropout_rate': 0.0, 'fused_opt': True, 'inductor': False, 'inductor_cudagraphs': False, 'capture_cudagraph_iters': 15, 'unet_config': {'_target_': 'nemo.collections.multimodal.modules.stable_diffusion.diffusionmodules.openaimodel.UNetModel', 'from_pretrained': None, 'from_NeMo': None, 'image_size': 32, 'in_channels': 4, 'out_channels': 4, 'model_channels': 320, 'attention_resolutions': [4, 2, 1], 'num_res_blocks': 2, 'channel_mult': [1, 2, 4, 4], 'num_head_channels': 64, 'use_spatial_transformer': True, 'use_linear_in_transformer': True, 'transformer_depth': 1, 'context_dim': 1024, 'use_checkpoint': False, 'legacy': False, 'use_flash_attention': True, 'resblock_gn_groups': 16, 'unet_precision': 'fp16', 'timesteps': 1000}, 'first_stage_config': {'_target_': 'nemo.collections.multimodal.models.text_to_image.stable_diffusion.ldm.autoencoder.AutoencoderKL', 'from_pretrained': None, 'embed_dim': 4, 'monitor': 'val/rec_loss', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 256, 'in
0: _channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0}, 'lossconfig': {'target': 'torch.nn.Identity'}}, 'cond_stage_config': {'_target_': 'nemo.collections.multimodal.modules.stable_diffusion.encoders.modules.FrozenOpenCLIPEmbedder', 'arch': 'ViT-H-14', 'version': 'laion2b_s32b_b79k', 'freeze': True, 'layer': 'penultimate', 'cache_dir': '/checkpoints/clip'}, 'seed': 9456, 'resume_from_checkpoint': None, 'apex_transformer_log_level': 30, 'gradient_as_bucket_view': True, 'ddp_overlap': False, 'nsys_profile': {'enabled': False, 'start_step': 10, 'end_step': 10, 'ranks': [0], 'gen_shape': False}, 'data': {'num_workers': 16, 'train': {'dataset_path': '/datasets/laion-400m/webdataset-moments-filtered-encoded/*.tar', 'augmentations': {'resize_smallest_side': 512, 'center_crop_h_w': '512, 512', 'horizontal_flip': False}, 'filterings': None}, 'webdataset': {'infinite_sampler': True, 'local_root_path': '/datasets/laion-400m/webdataset-moments-filtere
0: d-encoded'}}, 'optim': {'name': 'distributed_fused_adam', 'lr': 2.56e-05, 'weight_decay': 0.0, 'betas': [0.9, 0.999], 'sched': {'name': 'WarmupHoldPolicy', 'warmup_steps': 1000, 'hold_steps': 10000000000000}, 'bucket_cap_mb': 288, 'overlap_grad_sync': True, 'overlap_param_sync': False, 'contiguous_grad_buffer': True, 'contiguous_param_buffer': True, 'store_params': True, 'dtype': 'torch.float32', 'grad_sync_dtype': 'torch.float16', 'param_sync_dtype': 'torch.float16', 'capturable': True, 'distribute_within_nodes': True}, 'target': 'nemo.collections.multimodal.models.text_to_image.stable_diffusion.ldm.ddpm.MegatronLatentDiffusion', 'nemo_version': '2.0.0b0'}. Set this in model_parallel_config if using pipeline parallelism.
0: [NeMo I 2024-05-04 07:42:27 ddpm:130] LatentDiffusion: Running in v-prediction mode
0: [NeMo I 2024-05-04 07:42:27 attention:436] constructing SpatialTransformer of depth 1 w/ 320 channels and 5 heads
0: [NeMo I 2024-05-04 07:42:27 attention:436] constructing SpatialTransformer of depth 1 w/ 320 channels and 5 heads
0: [NeMo I 2024-05-04 07:42:27 attention:436] constructing SpatialTransformer of depth 1 w/ 640 channels and 10 heads
0: [NeMo I 2024-05-04 07:42:28 attention:436] constructing SpatialTransformer of depth 1 w/ 640 channels and 10 heads
3: [rank3]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
1: [rank1]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
2: [rank2]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
0: [NeMo I 2024-05-04 07:42:28 attention:436] constructing SpatialTransformer of depth 1 w/ 1280 channels and 20 heads
0: [NeMo I 2024-05-04 07:42:28 attention:436] constructing SpatialTransformer of depth 1 w/ 1280 channels and 20 heads
0: [NeMo I 2024-05-04 07:42:29 attention:436] constructing SpatialTransformer of depth 1 w/ 1280 channels and 20 heads
0: [NeMo I 2024-05-04 07:42:30 attention:436] constructing SpatialTransformer of depth 1 w/ 1280 channels and 20 heads
0: [NeMo I 2024-05-04 07:42:30 attention:436] constructing SpatialTransformer of depth 1 w/ 1280 channels and 20 heads
0: [NeMo I 2024-05-04 07:42:30 attention:436] constructing SpatialTransformer of depth 1 w/ 1280 channels and 20 heads
0: [NeMo I 2024-05-04 07:42:31 attention:436] constructing SpatialTransformer of depth 1 w/ 640 channels and 10 heads
0: [NeMo I 2024-05-04 07:42:31 attention:436] constructing SpatialTransformer of depth 1 w/ 640 channels and 10 heads
0: [NeMo I 2024-05-04 07:42:31 attention:436] constructing SpatialTransformer of depth 1 w/ 640 channels and 10 heads
0: [NeMo I 2024-05-04 07:42:31 attention:436] constructing SpatialTransformer of depth 1 w/ 320 channels and 5 heads
0: [NeMo I 2024-05-04 07:42:31 attention:436] constructing SpatialTransformer of depth 1 w/ 320 channels and 5 heads
0: [NeMo I 2024-05-04 07:42:31 attention:436] constructing SpatialTransformer of depth 1 w/ 320 channels and 5 heads
0: [NeMo I 2024-05-04 07:42:31 utils:92] DiffusionWrapper has 865.91 M params.
0: [NeMo I 2024-05-04 07:42:31 ddpm:168] Use system random generator since CUDA graph enabled
0: making attention of type 'vanilla' with 512 in_channels
0: Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
0: making attention of type 'vanilla' with 512 in_channels
0: Downloading clip with ViT-H-14 laion2b_s32b_b79k /checkpoints/clip
0: Loaded ViT-H-14 model config.
1: Computed feature activations of size torch.Size([7500, 2048])
1: making attention of type 'vanilla' with 512 in_channels
1: Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
1: making attention of type 'vanilla' with 512 in_channels
1: Downloading clip with ViT-H-14 laion2b_s32b_b79k /checkpoints/clip
1: Loaded ViT-H-14 model config.
2: Computed feature activations of size torch.Size([7500, 2048])
2: making attention of type 'vanilla' with 512 in_channels
2: Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
2: making attention of type 'vanilla' with 512 in_channels
2: Downloading clip with ViT-H-14 laion2b_s32b_b79k /checkpoints/clip
2: Loaded ViT-H-14 model config.
3: Computed feature activations of size torch.Size([7500, 2048])
3: making attention of type 'vanilla' with 512 in_channels
3: Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
3: making attention of type 'vanilla' with 512 in_channels
3: Downloading clip with ViT-H-14 laion2b_s32b_b79k /checkpoints/clip
3: Loaded ViT-H-14 model config.
0: Loading pretrained ViT-H-14 weights (laion2b_s32b_b79k).
1: Loading pretrained ViT-H-14 weights (laion2b_s32b_b79k).
2: Loading pretrained ViT-H-14 weights (laion2b_s32b_b79k).
3: Loading pretrained ViT-H-14 weights (laion2b_s32b_b79k).
0: [NeMo I 2024-05-04 07:42:40 ddpm:260] Loading /checkpoints/sd/512-base-ema.ckpt
0: [NeMo I 2024-05-04 07:42:40 ddpm:261] It has 1242 entries
0: [NeMo I 2024-05-04 07:42:40 ddpm:262] Existing model has 1240 entries
0: [NeMo I 2024-05-04 07:42:40 ddpm:296] Deleted 686 keys from `model.diffusion_model` state_dict.
0: [NeMo I 2024-05-04 07:42:40 ddpm:301] Restored from /checkpoints/sd/512-base-ema.ckpt with 686 missing and 2 unexpected keys
0: [NeMo I 2024-05-04 07:42:40 ddpm:303] Missing Keys: ['model.diffusion_model.time_embed.0.weight', 'model.diffusion_model.time_embed.0.bias', 'model.diffusion_model.time_embed.2.weight', 'model.diffusion_model.time_embed.2.bias', 'model.diffusion_model.input_blocks.0.0.weight', 'model.diffusion_model.input_blocks.0.0.bias', 'model.diffusion_model.input_blocks.1.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.1.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.1.0.in_layers.1.weight', 'model.diffusion_model.input_blocks.1.0.in_layers.1.bias', 'model.diffusion_model.input_blocks.1.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.1.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.1.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.1.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.1.0.out_layers.2.weight', 'model.diffusion_model.input_blocks.1.0.out_layers.2.bias', 'model.diffusion_model.input_blocks.1.1.norm.weight', 'model.diffusion_model.input_blocks.1.1
0: .norm.bias', 'model.diffusion_model.input_blocks.1.1.proj_in.weight', 'model.diffusion_model.input_blocks.1.1.proj_in.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_k.weight', 'mod
0: el.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.1.1.proj_out.weight', 'model.diffusion_model.input_blocks.1.1.proj_out.bias', 'model.diffusion_model.input_blocks.2.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.2.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.2.0.in_layers.1.weight', 'model.diffusion_model.input_block
0: s.2.0.in_layers.1.bias', 'model.diffusion_model.input_blocks.2.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.2.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.2.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.2.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.2.0.out_layers.2.weight', 'model.diffusion_model.input_blocks.2.0.out_layers.2.bias', 'model.diffusion_model.input_blocks.2.1.norm.weight', 'model.diffusion_model.input_blocks.2.1.norm.bias', 'model.diffusion_model.input_blocks.2.1.proj_in.weight', 'model.diffusion_model.input_blocks.2.1.proj_in.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.bias', 'mod
0: el.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2.bi
0: as', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.2.1.proj_out.weight', 'model.diffusion_model.input_blocks.2.1.proj_out.bias', 'model.diffusion_model.input_blocks.3.0.op.weight', 'model.diffusion_model.input_blocks.3.0.op.bias', 'model.diffusion_model.input_blocks.4.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.4.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.4.0.in_layers.1.weight', 'model.diffusion_model.input_blocks.4.0.in_layers.1.bias', 'model.diffusion_model.input_blocks.4.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.4.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.4.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.4.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.4.0.out_layers.2.weight', 'model.diffusion_model.input_blocks.4.0.out_layers.2.bias', 'model.diffusion_model.input_blocks.4.0.skip_co
0: nnection.weight', 'model.diffusion_model.input_blocks.4.0.skip_connection.bias', 'model.diffusion_model.input_blocks.4.1.norm.weight', 'model.diffusion_model.input_blocks.4.1.norm.bias', 'model.diffusion_model.input_blocks.4.1.proj_in.weight', 'model.diffusion_model.input_blocks.4.1.proj_in.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2
0: .bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.4.1.proj_out.weight', 'model.diffusion_model.input_blocks.4.1.proj_out.bias', 'model.diffusion_model.input_blocks.5.0.i
0: n_layers.0.weight', 'model.diffusion_model.input_blocks.5.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.5.0.in_layers.1.weight', 'model.diffusion_model.input_blocks.5.0.in_layers.1.bias', 'model.diffusion_model.input_blocks.5.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.5.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.5.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.5.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.5.0.out_layers.2.weight', 'model.diffusion_model.input_blocks.5.0.out_layers.2.bias', 'model.diffusion_model.input_blocks.5.1.norm.weight', 'model.diffusion_model.input_blocks.5.1.norm.bias', 'model.diffusion_model.input_blocks.5.1.proj_in.weight', 'model.diffusion_model.input_blocks.5.1.proj_in.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_v.weight'
0: , 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.5.1.trans
0: former_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.5.1.proj_out.weight', 'model.diffusion_model.input_blocks.5.1.proj_out.bias', 'model.diffusion_model.input_blocks.6.0.op.weight', 'model.diffusion_model.input_blocks.6.0.op.bias', 'model.diffusion_model.input_blocks.7.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.7.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.7.0.in_layers.1.weight', 'model.diffusion_model.input_blocks.7.0.in_layers.1.bias', 'model.diffusion_model.input_blocks.7.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.7.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.7.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.7.0.out_layers.0.bi
0: as', 'model.diffusion_model.input_blocks.7.0.out_layers.2.weight', 'model.diffusion_model.input_blocks.7.0.out_layers.2.bias', 'model.diffusion_model.input_blocks.7.0.skip_connection.weight', 'model.diffusion_model.input_blocks.7.0.skip_connection.bias', 'model.diffusion_model.input_blocks.7.1.norm.weight', 'model.diffusion_model.input_blocks.7.1.norm.bias', 'model.diffusion_model.input_blocks.7.1.proj_in.weight', 'model.diffusion_model.input_blocks.7.1.proj_in.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.7.1.transformer_bloc
0: ks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blo
0: cks.0.norm3.bias', 'model.diffusion_model.input_blocks.7.1.proj_out.weight', 'model.diffusion_model.input_blocks.7.1.proj_out.bias', 'model.diffusion_model.input_blocks.8.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.8.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.8.0.in_layers.1.weight', 'model.diffusion_model.input_blocks.8.0.in_layers.1.bias', 'model.diffusion_model.input_blocks.8.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.8.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.8.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.8.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.8.0.out_layers.2.weight', 'model.diffusion_model.input_blocks.8.0.out_layers.2.bias', 'model.diffusion_model.input_blocks.8.1.norm.weight', 'model.diffusion_model.input_blocks.8.1.norm.bias', 'model.diffusion_model.input_blocks.8.1.proj_in.weight', 'model.diffusion_model.input_blocks.8.1.proj_in.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.
0: to_q.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_b
0: locks.8.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.8.1.proj_out.weight', 'model.diffusion_model.input_blocks.8.1.proj_out.bias', 'model.diffusion_model.input_blocks.9.0.op.weight', 'model.diffusion_model.input_blocks.9.0.op.bias', 'model.diffusion_model.input_blocks.10.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.10.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.10.0.in_layers.1.weight', 'model.diffusion_model.input_blocks.10.0.in_layers.1.bias', 'model.diffusion_model.input_blocks.10.0.emb_layers.1.weight'
0: , 'model.diffusion_model.input_blocks.10.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.10.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.10.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.10.0.out_layers.2.weight', 'model.diffusion_model.input_blocks.10.0.out_layers.2.bias', 'model.diffusion_model.input_blocks.11.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.11.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.11.0.in_layers.1.weight', 'model.diffusion_model.input_blocks.11.0.in_layers.1.bias', 'model.diffusion_model.input_blocks.11.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.11.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.11.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.11.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.11.0.out_layers.2.weight', 'model.diffusion_model.input_blocks.11.0.out_layers.2.bias', 'model.diffusion_model.middle_block.0.in_layers.0.weight', 'model.diffusion_model.middle_block.0.
0: in_layers.0.bias', 'model.diffusion_model.middle_block.0.in_layers.1.weight', 'model.diffusion_model.middle_block.0.in_layers.1.bias', 'model.diffusion_model.middle_block.0.emb_layers.1.weight', 'model.diffusion_model.middle_block.0.emb_layers.1.bias', 'model.diffusion_model.middle_block.0.out_layers.0.weight', 'model.diffusion_model.middle_block.0.out_layers.0.bias', 'model.diffusion_model.middle_block.0.out_layers.2.weight', 'model.diffusion_model.middle_block.0.out_layers.2.bias', 'model.diffusion_model.middle_block.1.norm.weight', 'model.diffusion_model.middle_block.1.norm.bias', 'model.diffusion_model.middle_block.1.proj_in.weight', 'model.diffusion_model.middle_block.1.proj_in.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.weight', 'mode
0: l.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm2.weight', 'model.diffus
0: ion_model.middle_block.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.middle_block.1.proj_out.weight', 'model.diffusion_model.middle_block.1.proj_out.bias', 'model.diffusion_model.middle_block.2.in_layers.0.weight', 'model.diffusion_model.middle_block.2.in_layers.0.bias', 'model.diffusion_model.middle_block.2.in_layers.1.weight', 'model.diffusion_model.middle_block.2.in_layers.1.bias', 'model.diffusion_model.middle_block.2.emb_layers.1.weight', 'model.diffusion_model.middle_block.2.emb_layers.1.bias', 'model.diffusion_model.middle_block.2.out_layers.0.weight', 'model.diffusion_model.middle_block.2.out_layers.0.bias', 'model.diffusion_model.middle_block.2.out_layers.2.weight', 'model.diffusion_model.middle_block.2.out_layers.2.bias', 'model.diffusion_model.output_blocks.0.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.0.0.in_layers.0.bias', '
0: model.diffusion_model.output_blocks.0.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.0.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.0.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.0.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.0.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.0.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.0.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.0.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.0.0.skip_connection.weight', 'model.diffusion_model.output_blocks.0.0.skip_connection.bias', 'model.diffusion_model.output_blocks.1.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.1.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.1.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.1.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.1.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.1.0.emb_layers.1.bias', 'model.diffusion_model.output_blo
0: cks.1.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.1.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.1.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.1.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.1.0.skip_connection.weight', 'model.diffusion_model.output_blocks.1.0.skip_connection.bias', 'model.diffusion_model.output_blocks.2.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.2.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.2.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.2.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.2.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.2.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.2.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.2.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.2.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.2.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.2.0.skip_connection.weight
0: ', 'model.diffusion_model.output_blocks.2.0.skip_connection.bias', 'model.diffusion_model.output_blocks.2.1.conv.weight', 'model.diffusion_model.output_blocks.2.1.conv.bias', 'model.diffusion_model.output_blocks.3.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.3.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.3.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.3.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.3.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.3.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.3.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.3.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.3.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.3.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.3.0.skip_connection.weight', 'model.diffusion_model.output_blocks.3.0.skip_connection.bias', 'model.diffusion_model.output_blocks.3.1.norm.weight', 'model.diffusion_model.output_blocks.3.1.norm.bi
0: as', 'model.diffusion_model.output_blocks.3.1.proj_in.weight', 'model.diffusion_model.output_blocks.3.1.proj_in.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_k.weight',
0:  'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.3.1.proj_out.weight', 'model.diffusion_model.output_blocks.3.1.proj_out.bias', 'model.diffusion_model.output_blocks.4.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.4.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.4.0.in_layers.1.weight', 'model.diffusio
0: n_model.output_blocks.4.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.4.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.4.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.4.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.4.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.4.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.4.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.4.0.skip_connection.weight', 'model.diffusion_model.output_blocks.4.0.skip_connection.bias', 'model.diffusion_model.output_blocks.4.1.norm.weight', 'model.diffusion_model.output_blocks.4.1.norm.bias', 'model.diffusion_model.output_blocks.4.1.proj_in.weight', 'model.diffusion_model.output_blocks.4.1.proj_in.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_v.weight', 'model.di
0: ffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.4.1.tra
0: nsformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.4.1.proj_out.weight', 'model.diffusion_model.output_blocks.4.1.proj_out.bias', 'model.diffusion_model.output_blocks.5.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.5.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.5.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.5.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.5.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.5.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.5.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.5.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.5.0.out_layers.2.weight', 'model.diffusion_m
0: odel.output_blocks.5.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.5.0.skip_connection.weight', 'model.diffusion_model.output_blocks.5.0.skip_connection.bias', 'model.diffusion_model.output_blocks.5.1.norm.weight', 'model.diffusion_model.output_blocks.5.1.norm.bias', 'model.diffusion_model.output_blocks.5.1.proj_in.weight', 'model.diffusion_model.output_blocks.5.1.proj_in.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.5.1.tran
0: sformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.5.
0: 1.proj_out.weight', 'model.diffusion_model.output_blocks.5.1.proj_out.bias', 'model.diffusion_model.output_blocks.5.2.conv.weight', 'model.diffusion_model.output_blocks.5.2.conv.bias', 'model.diffusion_model.output_blocks.6.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.6.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.6.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.6.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.6.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.6.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.6.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.6.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.6.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.6.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.6.0.skip_connection.weight', 'model.diffusion_model.output_blocks.6.0.skip_connection.bias', 'model.diffusion_model.output_blocks.6.1.norm.weight', 'model.diffusion_model.output_blocks.6
0: .1.norm.bias', 'model.diffusion_model.output_blocks.6.1.proj_in.weight', 'model.diffusion_model.output_blocks.6.1.proj_in.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_
0: k.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.6.1.proj_out.weight', 'model.diffusion_model.output_blocks.6.1.proj_out.bias', 'model.diffusion_model.output_blocks.7.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.7.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.7.0.in_layers.1.weight', 'mode
0: l.diffusion_model.output_blocks.7.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.7.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.7.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.7.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.7.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.7.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.7.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.7.0.skip_connection.weight', 'model.diffusion_model.output_blocks.7.0.skip_connection.bias', 'model.diffusion_model.output_blocks.7.1.norm.weight', 'model.diffusion_model.output_blocks.7.1.norm.bias', 'model.diffusion_model.output_blocks.7.1.proj_in.weight', 'model.diffusion_model.output_blocks.7.1.proj_in.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_v.weight',
0:  'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_bloc
0: ks.7.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.7.1.proj_out.weight', 'model.diffusion_model.output_blocks.7.1.proj_out.bias', 'model.diffusion_model.output_blocks.8.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.8.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.8.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.8.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.8.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.8.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.8.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.8.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.8.0.out_layers.2.weight', 'model.d
0: iffusion_model.output_blocks.8.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.8.0.skip_connection.weight', 'model.diffusion_model.output_blocks.8.0.skip_connection.bias', 'model.diffusion_model.output_blocks.8.1.norm.weight', 'model.diffusion_model.output_blocks.8.1.norm.bias', 'model.diffusion_model.output_blocks.8.1.proj_in.weight', 'model.diffusion_model.output_blocks.8.1.proj_in.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_block
0: s.8.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output
0: _blocks.8.1.proj_out.weight', 'model.diffusion_model.output_blocks.8.1.proj_out.bias', 'model.diffusion_model.output_blocks.8.2.conv.weight', 'model.diffusion_model.output_blocks.8.2.conv.bias', 'model.diffusion_model.output_blocks.9.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.9.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.9.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.9.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.9.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.9.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.9.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.9.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.9.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.9.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.9.0.skip_connection.weight', 'model.diffusion_model.output_blocks.9.0.skip_connection.bias', 'model.diffusion_model.output_blocks.9.1.norm.weight', 'model.diffusion_model.outpu
0: t_blocks.9.1.norm.bias', 'model.diffusion_model.output_blocks.9.1.proj_in.weight', 'model.diffusion_model.output_blocks.9.1.proj_in.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0
0: .attn2.to_k.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.9.1.proj_out.weight', 'model.diffusion_model.output_blocks.9.1.proj_out.bias', 'model.diffusion_model.output_blocks.10.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.10.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.10.0.in_layers.1.w
0: eight', 'model.diffusion_model.output_blocks.10.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.10.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.10.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.10.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.10.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.10.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.10.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.10.0.skip_connection.weight', 'model.diffusion_model.output_blocks.10.0.skip_connection.bias', 'model.diffusion_model.output_blocks.10.1.norm.weight', 'model.diffusion_model.output_blocks.10.1.norm.bias', 'model.diffusion_model.output_blocks.10.1.proj_in.weight', 'model.diffusion_model.output_blocks.10.1.proj_in.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.10.1.transformer
0: _blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.we
0: ight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.10.1.proj_out.weight', 'model.diffusion_model.output_blocks.10.1.proj_out.bias', 'model.diffusion_model.output_blocks.11.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.11.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.11.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.11.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.11.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.11.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.11.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.11.0.out_layers.0.bias', 'model.diffusio
0: n_model.output_blocks.11.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.11.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.11.0.skip_connection.weight', 'model.diffusion_model.output_blocks.11.0.skip_connection.bias', 'model.diffusion_model.output_blocks.11.1.norm.weight', 'model.diffusion_model.output_blocks.11.1.norm.bias', 'model.diffusion_model.output_blocks.11.1.proj_in.weight', 'model.diffusion_model.output_blocks.11.1.proj_in.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.11.1.transf
0: ormer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.weight', 'model.diffusion_mode
0: l.output_blocks.11.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.11.1.proj_out.weight', 'model.diffusion_model.output_blocks.11.1.proj_out.bias', 'model.diffusion_model.out.0.weight', 'model.diffusion_model.out.0.bias', 'model.diffusion_model.out.1.weight', 'model.diffusion_model.out.1.bias']
0: [NeMo I 2024-05-04 07:42:40 ddpm:305] Unexpected Keys: ['model_ema.decay', 'model_ema.num_updates']
0: Global ID: 0, local ID: 0, world size: 4
0: Rank 0 before barrier
1: Global ID: 1, local ID: 1, world size: 4
1: Rank 1 before barrier
2: Global ID: 2, local ID: 2, world size: 4
2: Rank 2 before barrier
3: Global ID: 3, local ID: 3, world size: 4
3: Rank 3 before barrier
0: :::MLLOG {"namespace": "", "time_ms": 1714776163235, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 127, "samples_count": 2048000}}
0: Assigned 7500 prompts for this worker.
0: :::MLLOG {"namespace": "", "time_ms": 1714778424674, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 184, "samples_count": 2048000}}
3: Assigned 7500 prompts for this worker.
1: Assigned 7500 prompts for this worker.
2: Assigned 7500 prompts for this worker.
0: Calculating FID activations:   0%|          | 0/235 [00:00<?, ?it/s]Calculating FID activations:   0%|          | 1/235 [00:00<03:51,  1.01it/s]Calculating FID activations:   2%|▏         | 5/235 [00:01<00:40,  5.74it/s]Calculating FID activations:   4%|▍         | 9/235 [00:01<00:22, 10.00it/s]Calculating FID activations:   6%|▌         | 13/235 [00:01<00:16, 13.76it/s]Calculating FID activations:   7%|▋         | 17/235 [00:01<00:12, 17.52it/s]Calculating FID activations:   9%|▉         | 21/235 [00:01<00:11, 18.20it/s]Calculating FID activations:  11%|█         | 25/235 [00:01<00:09, 22.01it/s]Calculating FID activations:  12%|█▏        | 29/235 [00:02<00:09, 21.92it/s]Calculating FID activations:  14%|█▍        | 33/235 [00:02<00:08, 23.89it/s]Calculating FID activations:  16%|█▌        | 37/235 [00:02<00:08, 23.31it/s]Calculating FID activations:  17%|█▋        | 41/235 [00:02<00:07, 25.21it/s]Calculating FID activations:  19%|█▉        | 45/235 [00:02<00:07, 
0: 24.18it/s]Calculating FID activations:  21%|██        | 49/235 [00:02<00:07, 25.51it/s]Calculating FID activations:  23%|██▎       | 53/235 [00:02<00:07, 24.36it/s]Calculating FID activations:  24%|██▍       | 57/235 [00:03<00:06, 26.93it/s]Calculating FID activations:  26%|██▌       | 61/235 [00:03<00:06, 26.25it/s]Calculating FID activations:  28%|██▊       | 65/235 [00:03<00:06, 26.13it/s]Calculating FID activations:  29%|██▉       | 69/235 [00:03<00:06, 25.90it/s]Calculating FID activations:  31%|███       | 73/235 [00:03<00:06, 25.67it/s]Calculating FID activations:  33%|███▎      | 77/235 [00:03<00:06, 25.76it/s]Calculating FID activations:  34%|███▍      | 81/235 [00:04<00:06, 25.60it/s]Calculating FID activations:  36%|███▌      | 85/235 [00:04<00:05, 25.47it/s]Calculating FID activations:  38%|███▊      | 89/235 [00:04<00:05, 25.57it/s]Calculating FID activations:  40%|████      | 94/235 [00:04<00:04, 30.30it/
0: s]Calculating FID activations:  42%|████▏     | 99/235 [00:04<00:03, 34.11it/s]Calculating FID activations:  45%|████▍     | 105/235 [00:04<00:03, 36.43it/s]Calculating FID activations:  47%|████▋     | 110/235 [00:04<00:03, 38.56it/s]Calculating FID activations:  49%|████▉     | 115/235 [00:04<00:02, 40.75it/s]Calculating FID activations:  51%|█████     | 120/235 [00:05<00:02, 42.51it/s]Calculating FID activations:  53%|█████▎    | 125/235 [00:05<00:02, 40.20it/s]Calculating FID activations:  55%|█████▌    | 130/235 [00:05<00:02, 41.43it/s]Calculating FID activations:  57%|█████▋    | 135/235 [00:05<00:02, 43.08it/s]Calculating FID activations:  60%|█████▉    | 140/235 [00:05<00:02, 43.93it/s]Calculating FID activations:  62%|██████▏   | 145/235 [00:05<00:02, 40.84it/s]Calculating FID activations:  64%|██████▍   | 150/235 [00:05<00:01, 42.91it/s]Calculating FID activations
0: :  66%|██████▌   | 155/235 [00:05<00:01, 43.42it/s]Calculating FID activations:  68%|██████▊   | 160/235 [00:05<00:01, 43.88it/s]Calculating FID activations:  70%|███████   | 165/235 [00:06<00:01, 41.11it/s]Calculating FID activations:  72%|███████▏  | 170/235 [00:06<00:01, 43.25it/s]Calculating FID activations:  74%|███████▍  | 175/235 [00:06<00:01, 43.90it/s]Calculating FID activations:  77%|███████▋  | 180/235 [00:06<00:01, 44.73it/s]Calculating FID activations:  79%|███████▊  | 185/235 [00:06<00:01, 41.98it/s]Calculating FID activations:  81%|████████  | 190/235 [00:06<00:01, 43.34it/s]Calculating FID activations:  83%|████████▎ | 195/235 [00:06<00:00, 44.08it/s]Calculating FID activations:  85%|████████▌ | 200/235 [00:06<00:00, 45.17it/s]Calculating FID activations:  87%|████████▋ | 205/235 [00:07<00:00, 40.73it/s]Calcul
0: ating FID activations:  89%|████████▉ | 210/235 [00:07<00:00, 42.60it/s]Calculating FID activations:  91%|█████████▏| 215/235 [00:07<00:00, 44.02it/s]Calculating FID activations:  94%|█████████▎| 220/235 [00:07<00:00, 44.47it/s]Calculating FID activations:  96%|█████████▌| 225/235 [00:07<00:00, 41.37it/s]Calculating FID activations:  98%|█████████▊| 230/235 [00:07<00:00, 42.70it/s]Calculating FID activations: 100%|██████████| 235/235 [00:08<00:00, 28.61it/s]
0: Computed feature activations of size torch.Size([7500, 2048])
0: :::MLLOG {"namespace": "", "time_ms": 1714778451122, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 97.61794870217852, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 228, "samples_count": 2048000, "metric": "FID"}}
0: :::MLLOG {"namespace": "", "time_ms": 1714778559598, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.15083372592926025, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 258, "samples_count": 2048000, "metric": "CLIP"}}
0: Using 16bit Automatic Mixed Precision (AMP)
0: GPU available: True (cuda), used: True
0: TPU available: False, using: 0 TPU cores
0: IPU available: False, using: 0 IPUs
0: HPU available: False, using: 0 HPUs
0: [NeMo W 2024-05-04 08:22:39 utils:296] Loading from .ckpt checkpoint for inference is experimental! It doesn't support models with model parallelism!
1: [rank1]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
2: [rank2]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tensor_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: pipeline_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: virtual_pipeline_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: sequence_parallel in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: context_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: use_cpu_initialization in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: gradient_accumulation_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: use_te_rng_tracker in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_overlap_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_overlap_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_overlap_rs_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: overlap_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: batch_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: defer_embedding_wgrad_compute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading_activations in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading_weights in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1161] hidden_size not found in {'precision': 16, 'micro_batch_size': 64, 'global_batch_size': 256, 'linear_start': 0.00085, 'linear_end': 0.012, 'num_timesteps_cond': 1, 'log_every_t': 200, 'timesteps': 1000, 'first_stage_key': 'images_moments', 'cond_stage_key': 'clip_encoded', 'image_size': 64, 'channels': 4, 'cond_stage_trainable': False, 'conditioning_key': 'crossattn', 'monitor': 'val/loss_simple_ema', 'scale_factor': 0.18215, 'use_ema': False, 'scale_by_std': False, 'ckpt_path': '/checkpoints/sd/512-base-ema.ckpt', 'load_vae': True, 'load_unet': False, 'load_encoder': True, 'ignore_keys': [], 'parameterization': 'v', 'clip_denoised': True, 'load_only_unet': False, 'cosine_s': 0.008, 'given_betas': None, 'original_elbo_weight': 0, 'v_posterior': 0, 'l_simple_weight': 1, 'use_positional_encodings': False, 'learn_logvar': False, 'logvar_init': 0, 'beta_schedule': 'linear', 'loss_type': 'l2', 'channels_last': True, 'concat_mode': True, 'cond_stage_forward': No
0: ne, 'text_embedding_dropout_rate': 0.0, 'fused_opt': True, 'inductor': False, 'inductor_cudagraphs': False, 'capture_cudagraph_iters': 15, 'unet_config': {'_target_': 'nemo.collections.multimodal.modules.stable_diffusion.diffusionmodules.openaimodel.UNetModel', 'from_pretrained': None, 'from_NeMo': None, 'image_size': 32, 'in_channels': 4, 'out_channels': 4, 'model_channels': 320, 'attention_resolutions': [4, 2, 1], 'num_res_blocks': 2, 'channel_mult': [1, 2, 4, 4], 'num_head_channels': 64, 'use_spatial_transformer': True, 'use_linear_in_transformer': True, 'transformer_depth': 1, 'context_dim': 1024, 'use_checkpoint': False, 'legacy': False, 'use_flash_attention': True, 'resblock_gn_groups': 16, 'unet_precision': 'fp16', 'timesteps': 1000}, 'first_stage_config': {'_target_': 'nemo.collections.multimodal.models.text_to_image.stable_diffusion.ldm.autoencoder.AutoencoderKL', 'from_pretrained': None, 'embed_dim': 4, 'monitor': 'val/rec_loss', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 256, 'in
0: _channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0}, 'lossconfig': {'target': 'torch.nn.Identity'}}, 'cond_stage_config': {'_target_': 'nemo.collections.multimodal.modules.stable_diffusion.encoders.modules.FrozenOpenCLIPEmbedder', 'arch': 'ViT-H-14', 'version': 'laion2b_s32b_b79k', 'freeze': True, 'layer': 'penultimate', 'cache_dir': '/checkpoints/clip'}, 'seed': 9456, 'resume_from_checkpoint': None, 'apex_transformer_log_level': 30, 'gradient_as_bucket_view': True, 'ddp_overlap': False, 'nsys_profile': {'enabled': False, 'start_step': 10, 'end_step': 10, 'ranks': [0], 'gen_shape': False}, 'data': {'num_workers': 16, 'train': {'dataset_path': '/datasets/laion-400m/webdataset-moments-filtered-encoded/*.tar', 'augmentations': {'resize_smallest_side': 512, 'center_crop_h_w': '512, 512', 'horizontal_flip': False}, 'filterings': None}, 'webdataset': {'infinite_sampler': True, 'local_root_path': '/datasets/laion-400m/webdataset-moments-filtere
0: d-encoded'}}, 'optim': {'name': 'distributed_fused_adam', 'lr': 2.56e-05, 'weight_decay': 0.0, 'betas': [0.9, 0.999], 'sched': {'name': 'WarmupHoldPolicy', 'warmup_steps': 1000, 'hold_steps': 10000000000000}, 'bucket_cap_mb': 288, 'overlap_grad_sync': True, 'overlap_param_sync': False, 'contiguous_grad_buffer': True, 'contiguous_param_buffer': True, 'store_params': True, 'dtype': 'torch.float32', 'grad_sync_dtype': 'torch.float16', 'param_sync_dtype': 'torch.float16', 'capturable': True, 'distribute_within_nodes': True}, 'target': 'nemo.collections.multimodal.models.text_to_image.stable_diffusion.ldm.ddpm.MegatronLatentDiffusion', 'nemo_version': '2.0.0b0'}. Set this in model_parallel_config if using pipeline parallelism.
0: [rank0]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
0: [NeMo I 2024-05-04 08:22:41 megatron_init:265] Rank 0 has data parallel group : [0, 1, 2, 3]
0: [NeMo I 2024-05-04 08:22:41 megatron_init:271] Rank 0 has combined group of data parallel and context parallel : [0, 1, 2, 3]
0: [NeMo I 2024-05-04 08:22:41 megatron_init:276] All data parallel group ranks with context parallel combined: [[0, 1, 2, 3]]
0: [NeMo I 2024-05-04 08:22:41 megatron_init:279] Ranks 0 has data parallel rank: 0
0: [NeMo I 2024-05-04 08:22:41 megatron_init:287] Rank 0 has context parallel group: [0]
0: [NeMo I 2024-05-04 08:22:41 megatron_init:290] All context parallel group ranks: [[0], [1], [2], [3]]
0: [NeMo I 2024-05-04 08:22:41 megatron_init:291] Ranks 0 has context parallel rank: 0
0: [NeMo I 2024-05-04 08:22:41 megatron_init:298] Rank 0 has model parallel group: [0]
0: [NeMo I 2024-05-04 08:22:41 megatron_init:299] All model parallel group ranks: [[0], [1], [2], [3]]
0: [NeMo I 2024-05-04 08:22:41 megatron_init:308] Rank 0 has tensor model parallel group: [0]
0: [NeMo I 2024-05-04 08:22:41 megatron_init:312] All tensor model parallel group ranks: [[0], [1], [2], [3]]
0: [NeMo I 2024-05-04 08:22:41 megatron_init:313] Rank 0 has tensor model parallel rank: 0
0: [NeMo I 2024-05-04 08:22:41 megatron_init:333] Rank 0 has pipeline model parallel group: [0]
0: [NeMo I 2024-05-04 08:22:41 megatron_init:345] Rank 0 has embedding group: [0]
0: [NeMo I 2024-05-04 08:22:41 megatron_init:351] All pipeline model parallel group ranks: [[0], [1], [2], [3]]
0: [NeMo I 2024-05-04 08:22:41 megatron_init:352] Rank 0 has pipeline model parallel rank 0
0: [NeMo I 2024-05-04 08:22:41 megatron_init:353] All embedding group ranks: [[0], [1], [2], [3]]
0: [NeMo I 2024-05-04 08:22:41 megatron_init:354] Rank 0 has embedding rank: 0
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tensor_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: pipeline_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: virtual_pipeline_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: sequence_parallel in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: context_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: expert_model_parallel_size in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: use_cpu_initialization in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: finalize_model_grads_func in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: gradient_accumulation_fusion in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: use_te_rng_tracker in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_bulk_wgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_bulk_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_overlap_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_overlap_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_overlap_rs_dgrad in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_split_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_atomic_ag in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_split_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: tp_comm_atomic_rs in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: overlap_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: batch_p2p_comm in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: defer_embedding_wgrad_compute in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: pipeline_model_parallel_split_rank in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading_num_layers in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: _cpu_offloading_context in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading_activations in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: cpu_offloading_weights in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1150] The model: MegatronLatentDiffusion() does not have field.name: barrier_with_L1_time in its cfg. Add this key to cfg or config_mapping to make to make it configurable.
0: [NeMo W 2024-05-04 08:22:41 megatron_base_model:1161] hidden_size not found in {'precision': 16, 'micro_batch_size': 64, 'global_batch_size': 256, 'linear_start': 0.00085, 'linear_end': 0.012, 'num_timesteps_cond': 1, 'log_every_t': 200, 'timesteps': 1000, 'first_stage_key': 'images_moments', 'cond_stage_key': 'clip_encoded', 'image_size': 64, 'channels': 4, 'cond_stage_trainable': False, 'conditioning_key': 'crossattn', 'monitor': 'val/loss_simple_ema', 'scale_factor': 0.18215, 'use_ema': False, 'scale_by_std': False, 'ckpt_path': '/checkpoints/sd/512-base-ema.ckpt', 'load_vae': True, 'load_unet': False, 'load_encoder': True, 'ignore_keys': [], 'parameterization': 'v', 'clip_denoised': True, 'load_only_unet': False, 'cosine_s': 0.008, 'given_betas': None, 'original_elbo_weight': 0, 'v_posterior': 0, 'l_simple_weight': 1, 'use_positional_encodings': False, 'learn_logvar': False, 'logvar_init': 0, 'beta_schedule': 'linear', 'loss_type': 'l2', 'channels_last': True, 'concat_mode': True, 'cond_stage_forward': No
0: ne, 'text_embedding_dropout_rate': 0.0, 'fused_opt': True, 'inductor': False, 'inductor_cudagraphs': False, 'capture_cudagraph_iters': 15, 'unet_config': {'_target_': 'nemo.collections.multimodal.modules.stable_diffusion.diffusionmodules.openaimodel.UNetModel', 'from_pretrained': None, 'from_NeMo': None, 'image_size': 32, 'in_channels': 4, 'out_channels': 4, 'model_channels': 320, 'attention_resolutions': [4, 2, 1], 'num_res_blocks': 2, 'channel_mult': [1, 2, 4, 4], 'num_head_channels': 64, 'use_spatial_transformer': True, 'use_linear_in_transformer': True, 'transformer_depth': 1, 'context_dim': 1024, 'use_checkpoint': False, 'legacy': False, 'use_flash_attention': True, 'resblock_gn_groups': 16, 'unet_precision': 'fp16', 'timesteps': 1000}, 'first_stage_config': {'_target_': 'nemo.collections.multimodal.models.text_to_image.stable_diffusion.ldm.autoencoder.AutoencoderKL', 'from_pretrained': None, 'embed_dim': 4, 'monitor': 'val/rec_loss', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 256, 'in
0: _channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0}, 'lossconfig': {'target': 'torch.nn.Identity'}}, 'cond_stage_config': {'_target_': 'nemo.collections.multimodal.modules.stable_diffusion.encoders.modules.FrozenOpenCLIPEmbedder', 'arch': 'ViT-H-14', 'version': 'laion2b_s32b_b79k', 'freeze': True, 'layer': 'penultimate', 'cache_dir': '/checkpoints/clip'}, 'seed': 9456, 'resume_from_checkpoint': None, 'apex_transformer_log_level': 30, 'gradient_as_bucket_view': True, 'ddp_overlap': False, 'nsys_profile': {'enabled': False, 'start_step': 10, 'end_step': 10, 'ranks': [0], 'gen_shape': False}, 'data': {'num_workers': 16, 'train': {'dataset_path': '/datasets/laion-400m/webdataset-moments-filtered-encoded/*.tar', 'augmentations': {'resize_smallest_side': 512, 'center_crop_h_w': '512, 512', 'horizontal_flip': False}, 'filterings': None}, 'webdataset': {'infinite_sampler': True, 'local_root_path': '/datasets/laion-400m/webdataset-moments-filtere
0: d-encoded'}}, 'optim': {'name': 'distributed_fused_adam', 'lr': 2.56e-05, 'weight_decay': 0.0, 'betas': [0.9, 0.999], 'sched': {'name': 'WarmupHoldPolicy', 'warmup_steps': 1000, 'hold_steps': 10000000000000}, 'bucket_cap_mb': 288, 'overlap_grad_sync': True, 'overlap_param_sync': False, 'contiguous_grad_buffer': True, 'contiguous_param_buffer': True, 'store_params': True, 'dtype': 'torch.float32', 'grad_sync_dtype': 'torch.float16', 'param_sync_dtype': 'torch.float16', 'capturable': True, 'distribute_within_nodes': True}, 'target': 'nemo.collections.multimodal.models.text_to_image.stable_diffusion.ldm.ddpm.MegatronLatentDiffusion', 'nemo_version': '2.0.0b0'}. Set this in model_parallel_config if using pipeline parallelism.
0: [NeMo I 2024-05-04 08:22:41 ddpm:130] LatentDiffusion: Running in v-prediction mode
3: [rank3]:[W init.cpp:767] Warning: nvfuser is no longer supported in torch script, use _jit_set_nvfuser_enabled is deprecated and a no-op (function operator())
0: [NeMo I 2024-05-04 08:22:41 attention:436] constructing SpatialTransformer of depth 1 w/ 320 channels and 5 heads
0: [NeMo I 2024-05-04 08:22:41 attention:436] constructing SpatialTransformer of depth 1 w/ 320 channels and 5 heads
0: [NeMo I 2024-05-04 08:22:41 attention:436] constructing SpatialTransformer of depth 1 w/ 640 channels and 10 heads
0: [NeMo I 2024-05-04 08:22:41 attention:436] constructing SpatialTransformer of depth 1 w/ 640 channels and 10 heads
0: [NeMo I 2024-05-04 08:22:41 attention:436] constructing SpatialTransformer of depth 1 w/ 1280 channels and 20 heads
0: [NeMo I 2024-05-04 08:22:42 attention:436] constructing SpatialTransformer of depth 1 w/ 1280 channels and 20 heads
0: [NeMo I 2024-05-04 08:22:42 attention:436] constructing SpatialTransformer of depth 1 w/ 1280 channels and 20 heads
0: [NeMo I 2024-05-04 08:22:43 attention:436] constructing SpatialTransformer of depth 1 w/ 1280 channels and 20 heads
0: [NeMo I 2024-05-04 08:22:44 attention:436] constructing SpatialTransformer of depth 1 w/ 1280 channels and 20 heads
0: [NeMo I 2024-05-04 08:22:44 attention:436] constructing SpatialTransformer of depth 1 w/ 1280 channels and 20 heads
0: [NeMo I 2024-05-04 08:22:44 attention:436] constructing SpatialTransformer of depth 1 w/ 640 channels and 10 heads
0: [NeMo I 2024-05-04 08:22:44 attention:436] constructing SpatialTransformer of depth 1 w/ 640 channels and 10 heads
0: [NeMo I 2024-05-04 08:22:45 attention:436] constructing SpatialTransformer of depth 1 w/ 640 channels and 10 heads
0: [NeMo I 2024-05-04 08:22:45 attention:436] constructing SpatialTransformer of depth 1 w/ 320 channels and 5 heads
0: [NeMo I 2024-05-04 08:22:45 attention:436] constructing SpatialTransformer of depth 1 w/ 320 channels and 5 heads
0: [NeMo I 2024-05-04 08:22:45 attention:436] constructing SpatialTransformer of depth 1 w/ 320 channels and 5 heads
0: [NeMo I 2024-05-04 08:22:45 utils:92] DiffusionWrapper has 865.91 M params.
0: [NeMo I 2024-05-04 08:22:45 ddpm:168] Use system random generator since CUDA graph enabled
1: Computed feature activations of size torch.Size([7500, 2048])
1: making attention of type 'vanilla' with 512 in_channels
1: Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
1: making attention of type 'vanilla' with 512 in_channels
1: Downloading clip with ViT-H-14 laion2b_s32b_b79k /checkpoints/clip
1: Loaded ViT-H-14 model config.
2: Computed feature activations of size torch.Size([7500, 2048])
2: making attention of type 'vanilla' with 512 in_channels
2: Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
2: making attention of type 'vanilla' with 512 in_channels
2: Downloading clip with ViT-H-14 laion2b_s32b_b79k /checkpoints/clip
2: Loaded ViT-H-14 model config.
0: making attention of type 'vanilla' with 512 in_channels
0: Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
0: making attention of type 'vanilla' with 512 in_channels
0: Downloading clip with ViT-H-14 laion2b_s32b_b79k /checkpoints/clip
0: Loaded ViT-H-14 model config.
3: Computed feature activations of size torch.Size([7500, 2048])
3: making attention of type 'vanilla' with 512 in_channels
3: Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
3: making attention of type 'vanilla' with 512 in_channels
3: Downloading clip with ViT-H-14 laion2b_s32b_b79k /checkpoints/clip
3: Loaded ViT-H-14 model config.
1: Loading pretrained ViT-H-14 weights (laion2b_s32b_b79k).
0: Loading pretrained ViT-H-14 weights (laion2b_s32b_b79k).
2: Loading pretrained ViT-H-14 weights (laion2b_s32b_b79k).
3: Loading pretrained ViT-H-14 weights (laion2b_s32b_b79k).
0: [NeMo I 2024-05-04 08:22:54 ddpm:260] Loading /checkpoints/sd/512-base-ema.ckpt
0: [NeMo I 2024-05-04 08:22:54 ddpm:261] It has 1242 entries
0: [NeMo I 2024-05-04 08:22:54 ddpm:262] Existing model has 1240 entries
0: [NeMo I 2024-05-04 08:22:54 ddpm:296] Deleted 686 keys from `model.diffusion_model` state_dict.
0: [NeMo I 2024-05-04 08:22:54 ddpm:301] Restored from /checkpoints/sd/512-base-ema.ckpt with 686 missing and 2 unexpected keys
0: [NeMo I 2024-05-04 08:22:54 ddpm:303] Missing Keys: ['model.diffusion_model.time_embed.0.weight', 'model.diffusion_model.time_embed.0.bias', 'model.diffusion_model.time_embed.2.weight', 'model.diffusion_model.time_embed.2.bias', 'model.diffusion_model.input_blocks.0.0.weight', 'model.diffusion_model.input_blocks.0.0.bias', 'model.diffusion_model.input_blocks.1.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.1.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.1.0.in_layers.1.weight', 'model.diffusion_model.input_blocks.1.0.in_layers.1.bias', 'model.diffusion_model.input_blocks.1.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.1.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.1.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.1.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.1.0.out_layers.2.weight', 'model.diffusion_model.input_blocks.1.0.out_layers.2.bias', 'model.diffusion_model.input_blocks.1.1.norm.weight', 'model.diffusion_model.input_blocks.1.1
0: .norm.bias', 'model.diffusion_model.input_blocks.1.1.proj_in.weight', 'model.diffusion_model.input_blocks.1.1.proj_in.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_k.weight', 'mod
0: el.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.1.1.proj_out.weight', 'model.diffusion_model.input_blocks.1.1.proj_out.bias', 'model.diffusion_model.input_blocks.2.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.2.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.2.0.in_layers.1.weight', 'model.diffusion_model.input_block
0: s.2.0.in_layers.1.bias', 'model.diffusion_model.input_blocks.2.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.2.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.2.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.2.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.2.0.out_layers.2.weight', 'model.diffusion_model.input_blocks.2.0.out_layers.2.bias', 'model.diffusion_model.input_blocks.2.1.norm.weight', 'model.diffusion_model.input_blocks.2.1.norm.bias', 'model.diffusion_model.input_blocks.2.1.proj_in.weight', 'model.diffusion_model.input_blocks.2.1.proj_in.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.bias', 'mod
0: el.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2.bi
0: as', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.2.1.proj_out.weight', 'model.diffusion_model.input_blocks.2.1.proj_out.bias', 'model.diffusion_model.input_blocks.3.0.op.weight', 'model.diffusion_model.input_blocks.3.0.op.bias', 'model.diffusion_model.input_blocks.4.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.4.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.4.0.in_layers.1.weight', 'model.diffusion_model.input_blocks.4.0.in_layers.1.bias', 'model.diffusion_model.input_blocks.4.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.4.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.4.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.4.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.4.0.out_layers.2.weight', 'model.diffusion_model.input_blocks.4.0.out_layers.2.bias', 'model.diffusion_model.input_blocks.4.0.skip_co
0: nnection.weight', 'model.diffusion_model.input_blocks.4.0.skip_connection.bias', 'model.diffusion_model.input_blocks.4.1.norm.weight', 'model.diffusion_model.input_blocks.4.1.norm.bias', 'model.diffusion_model.input_blocks.4.1.proj_in.weight', 'model.diffusion_model.input_blocks.4.1.proj_in.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2
0: .bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.4.1.proj_out.weight', 'model.diffusion_model.input_blocks.4.1.proj_out.bias', 'model.diffusion_model.input_blocks.5.0.i
0: n_layers.0.weight', 'model.diffusion_model.input_blocks.5.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.5.0.in_layers.1.weight', 'model.diffusion_model.input_blocks.5.0.in_layers.1.bias', 'model.diffusion_model.input_blocks.5.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.5.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.5.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.5.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.5.0.out_layers.2.weight', 'model.diffusion_model.input_blocks.5.0.out_layers.2.bias', 'model.diffusion_model.input_blocks.5.1.norm.weight', 'model.diffusion_model.input_blocks.5.1.norm.bias', 'model.diffusion_model.input_blocks.5.1.proj_in.weight', 'model.diffusion_model.input_blocks.5.1.proj_in.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_v.weight'
0: , 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.5.1.trans
0: former_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.5.1.proj_out.weight', 'model.diffusion_model.input_blocks.5.1.proj_out.bias', 'model.diffusion_model.input_blocks.6.0.op.weight', 'model.diffusion_model.input_blocks.6.0.op.bias', 'model.diffusion_model.input_blocks.7.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.7.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.7.0.in_layers.1.weight', 'model.diffusion_model.input_blocks.7.0.in_layers.1.bias', 'model.diffusion_model.input_blocks.7.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.7.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.7.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.7.0.out_layers.0.bi
0: as', 'model.diffusion_model.input_blocks.7.0.out_layers.2.weight', 'model.diffusion_model.input_blocks.7.0.out_layers.2.bias', 'model.diffusion_model.input_blocks.7.0.skip_connection.weight', 'model.diffusion_model.input_blocks.7.0.skip_connection.bias', 'model.diffusion_model.input_blocks.7.1.norm.weight', 'model.diffusion_model.input_blocks.7.1.norm.bias', 'model.diffusion_model.input_blocks.7.1.proj_in.weight', 'model.diffusion_model.input_blocks.7.1.proj_in.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.7.1.transformer_bloc
0: ks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blo
0: cks.0.norm3.bias', 'model.diffusion_model.input_blocks.7.1.proj_out.weight', 'model.diffusion_model.input_blocks.7.1.proj_out.bias', 'model.diffusion_model.input_blocks.8.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.8.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.8.0.in_layers.1.weight', 'model.diffusion_model.input_blocks.8.0.in_layers.1.bias', 'model.diffusion_model.input_blocks.8.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.8.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.8.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.8.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.8.0.out_layers.2.weight', 'model.diffusion_model.input_blocks.8.0.out_layers.2.bias', 'model.diffusion_model.input_blocks.8.1.norm.weight', 'model.diffusion_model.input_blocks.8.1.norm.bias', 'model.diffusion_model.input_blocks.8.1.proj_in.weight', 'model.diffusion_model.input_blocks.8.1.proj_in.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.
0: to_q.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_b
0: locks.8.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.8.1.proj_out.weight', 'model.diffusion_model.input_blocks.8.1.proj_out.bias', 'model.diffusion_model.input_blocks.9.0.op.weight', 'model.diffusion_model.input_blocks.9.0.op.bias', 'model.diffusion_model.input_blocks.10.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.10.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.10.0.in_layers.1.weight', 'model.diffusion_model.input_blocks.10.0.in_layers.1.bias', 'model.diffusion_model.input_blocks.10.0.emb_layers.1.weight'
0: , 'model.diffusion_model.input_blocks.10.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.10.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.10.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.10.0.out_layers.2.weight', 'model.diffusion_model.input_blocks.10.0.out_layers.2.bias', 'model.diffusion_model.input_blocks.11.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.11.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.11.0.in_layers.1.weight', 'model.diffusion_model.input_blocks.11.0.in_layers.1.bias', 'model.diffusion_model.input_blocks.11.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.11.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.11.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.11.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.11.0.out_layers.2.weight', 'model.diffusion_model.input_blocks.11.0.out_layers.2.bias', 'model.diffusion_model.middle_block.0.in_layers.0.weight', 'model.diffusion_model.middle_block.0.
0: in_layers.0.bias', 'model.diffusion_model.middle_block.0.in_layers.1.weight', 'model.diffusion_model.middle_block.0.in_layers.1.bias', 'model.diffusion_model.middle_block.0.emb_layers.1.weight', 'model.diffusion_model.middle_block.0.emb_layers.1.bias', 'model.diffusion_model.middle_block.0.out_layers.0.weight', 'model.diffusion_model.middle_block.0.out_layers.0.bias', 'model.diffusion_model.middle_block.0.out_layers.2.weight', 'model.diffusion_model.middle_block.0.out_layers.2.bias', 'model.diffusion_model.middle_block.1.norm.weight', 'model.diffusion_model.middle_block.1.norm.bias', 'model.diffusion_model.middle_block.1.proj_in.weight', 'model.diffusion_model.middle_block.1.proj_in.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.weight', 'mode
0: l.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm2.weight', 'model.diffus
0: ion_model.middle_block.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.middle_block.1.proj_out.weight', 'model.diffusion_model.middle_block.1.proj_out.bias', 'model.diffusion_model.middle_block.2.in_layers.0.weight', 'model.diffusion_model.middle_block.2.in_layers.0.bias', 'model.diffusion_model.middle_block.2.in_layers.1.weight', 'model.diffusion_model.middle_block.2.in_layers.1.bias', 'model.diffusion_model.middle_block.2.emb_layers.1.weight', 'model.diffusion_model.middle_block.2.emb_layers.1.bias', 'model.diffusion_model.middle_block.2.out_layers.0.weight', 'model.diffusion_model.middle_block.2.out_layers.0.bias', 'model.diffusion_model.middle_block.2.out_layers.2.weight', 'model.diffusion_model.middle_block.2.out_layers.2.bias', 'model.diffusion_model.output_blocks.0.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.0.0.in_layers.0.bias', '
0: model.diffusion_model.output_blocks.0.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.0.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.0.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.0.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.0.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.0.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.0.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.0.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.0.0.skip_connection.weight', 'model.diffusion_model.output_blocks.0.0.skip_connection.bias', 'model.diffusion_model.output_blocks.1.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.1.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.1.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.1.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.1.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.1.0.emb_layers.1.bias', 'model.diffusion_model.output_blo
0: cks.1.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.1.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.1.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.1.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.1.0.skip_connection.weight', 'model.diffusion_model.output_blocks.1.0.skip_connection.bias', 'model.diffusion_model.output_blocks.2.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.2.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.2.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.2.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.2.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.2.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.2.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.2.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.2.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.2.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.2.0.skip_connection.weight
0: ', 'model.diffusion_model.output_blocks.2.0.skip_connection.bias', 'model.diffusion_model.output_blocks.2.1.conv.weight', 'model.diffusion_model.output_blocks.2.1.conv.bias', 'model.diffusion_model.output_blocks.3.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.3.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.3.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.3.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.3.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.3.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.3.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.3.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.3.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.3.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.3.0.skip_connection.weight', 'model.diffusion_model.output_blocks.3.0.skip_connection.bias', 'model.diffusion_model.output_blocks.3.1.norm.weight', 'model.diffusion_model.output_blocks.3.1.norm.bi
0: as', 'model.diffusion_model.output_blocks.3.1.proj_in.weight', 'model.diffusion_model.output_blocks.3.1.proj_in.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_k.weight',
0:  'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.3.1.proj_out.weight', 'model.diffusion_model.output_blocks.3.1.proj_out.bias', 'model.diffusion_model.output_blocks.4.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.4.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.4.0.in_layers.1.weight', 'model.diffusio
0: n_model.output_blocks.4.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.4.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.4.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.4.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.4.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.4.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.4.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.4.0.skip_connection.weight', 'model.diffusion_model.output_blocks.4.0.skip_connection.bias', 'model.diffusion_model.output_blocks.4.1.norm.weight', 'model.diffusion_model.output_blocks.4.1.norm.bias', 'model.diffusion_model.output_blocks.4.1.proj_in.weight', 'model.diffusion_model.output_blocks.4.1.proj_in.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_v.weight', 'model.di
0: ffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.4.1.tra
0: nsformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.4.1.proj_out.weight', 'model.diffusion_model.output_blocks.4.1.proj_out.bias', 'model.diffusion_model.output_blocks.5.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.5.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.5.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.5.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.5.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.5.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.5.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.5.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.5.0.out_layers.2.weight', 'model.diffusion_m
0: odel.output_blocks.5.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.5.0.skip_connection.weight', 'model.diffusion_model.output_blocks.5.0.skip_connection.bias', 'model.diffusion_model.output_blocks.5.1.norm.weight', 'model.diffusion_model.output_blocks.5.1.norm.bias', 'model.diffusion_model.output_blocks.5.1.proj_in.weight', 'model.diffusion_model.output_blocks.5.1.proj_in.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.5.1.tran
0: sformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.5.
0: 1.proj_out.weight', 'model.diffusion_model.output_blocks.5.1.proj_out.bias', 'model.diffusion_model.output_blocks.5.2.conv.weight', 'model.diffusion_model.output_blocks.5.2.conv.bias', 'model.diffusion_model.output_blocks.6.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.6.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.6.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.6.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.6.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.6.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.6.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.6.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.6.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.6.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.6.0.skip_connection.weight', 'model.diffusion_model.output_blocks.6.0.skip_connection.bias', 'model.diffusion_model.output_blocks.6.1.norm.weight', 'model.diffusion_model.output_blocks.6
0: .1.norm.bias', 'model.diffusion_model.output_blocks.6.1.proj_in.weight', 'model.diffusion_model.output_blocks.6.1.proj_in.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_
0: k.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.6.1.proj_out.weight', 'model.diffusion_model.output_blocks.6.1.proj_out.bias', 'model.diffusion_model.output_blocks.7.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.7.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.7.0.in_layers.1.weight', 'mode
0: l.diffusion_model.output_blocks.7.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.7.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.7.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.7.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.7.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.7.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.7.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.7.0.skip_connection.weight', 'model.diffusion_model.output_blocks.7.0.skip_connection.bias', 'model.diffusion_model.output_blocks.7.1.norm.weight', 'model.diffusion_model.output_blocks.7.1.norm.bias', 'model.diffusion_model.output_blocks.7.1.proj_in.weight', 'model.diffusion_model.output_blocks.7.1.proj_in.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_v.weight',
0:  'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_bloc
0: ks.7.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.7.1.proj_out.weight', 'model.diffusion_model.output_blocks.7.1.proj_out.bias', 'model.diffusion_model.output_blocks.8.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.8.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.8.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.8.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.8.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.8.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.8.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.8.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.8.0.out_layers.2.weight', 'model.d
0: iffusion_model.output_blocks.8.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.8.0.skip_connection.weight', 'model.diffusion_model.output_blocks.8.0.skip_connection.bias', 'model.diffusion_model.output_blocks.8.1.norm.weight', 'model.diffusion_model.output_blocks.8.1.norm.bias', 'model.diffusion_model.output_blocks.8.1.proj_in.weight', 'model.diffusion_model.output_blocks.8.1.proj_in.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_block
0: s.8.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output
0: _blocks.8.1.proj_out.weight', 'model.diffusion_model.output_blocks.8.1.proj_out.bias', 'model.diffusion_model.output_blocks.8.2.conv.weight', 'model.diffusion_model.output_blocks.8.2.conv.bias', 'model.diffusion_model.output_blocks.9.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.9.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.9.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.9.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.9.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.9.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.9.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.9.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.9.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.9.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.9.0.skip_connection.weight', 'model.diffusion_model.output_blocks.9.0.skip_connection.bias', 'model.diffusion_model.output_blocks.9.1.norm.weight', 'model.diffusion_model.outpu
0: t_blocks.9.1.norm.bias', 'model.diffusion_model.output_blocks.9.1.proj_in.weight', 'model.diffusion_model.output_blocks.9.1.proj_in.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0
0: .attn2.to_k.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.9.1.proj_out.weight', 'model.diffusion_model.output_blocks.9.1.proj_out.bias', 'model.diffusion_model.output_blocks.10.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.10.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.10.0.in_layers.1.w
0: eight', 'model.diffusion_model.output_blocks.10.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.10.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.10.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.10.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.10.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.10.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.10.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.10.0.skip_connection.weight', 'model.diffusion_model.output_blocks.10.0.skip_connection.bias', 'model.diffusion_model.output_blocks.10.1.norm.weight', 'model.diffusion_model.output_blocks.10.1.norm.bias', 'model.diffusion_model.output_blocks.10.1.proj_in.weight', 'model.diffusion_model.output_blocks.10.1.proj_in.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.10.1.transformer
0: _blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.we
0: ight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.10.1.proj_out.weight', 'model.diffusion_model.output_blocks.10.1.proj_out.bias', 'model.diffusion_model.output_blocks.11.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.11.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.11.0.in_layers.1.weight', 'model.diffusion_model.output_blocks.11.0.in_layers.1.bias', 'model.diffusion_model.output_blocks.11.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.11.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.11.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.11.0.out_layers.0.bias', 'model.diffusio
0: n_model.output_blocks.11.0.out_layers.2.weight', 'model.diffusion_model.output_blocks.11.0.out_layers.2.bias', 'model.diffusion_model.output_blocks.11.0.skip_connection.weight', 'model.diffusion_model.output_blocks.11.0.skip_connection.bias', 'model.diffusion_model.output_blocks.11.1.norm.weight', 'model.diffusion_model.output_blocks.11.1.norm.bias', 'model.diffusion_model.output_blocks.11.1.proj_in.weight', 'model.diffusion_model.output_blocks.11.1.proj_in.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.11.1.transf
0: ormer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.weight', 'model.diffusion_mode
0: l.output_blocks.11.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.11.1.proj_out.weight', 'model.diffusion_model.output_blocks.11.1.proj_out.bias', 'model.diffusion_model.out.0.weight', 'model.diffusion_model.out.0.bias', 'model.diffusion_model.out.1.weight', 'model.diffusion_model.out.1.bias']
0: [NeMo I 2024-05-04 08:22:54 ddpm:305] Unexpected Keys: ['model_ema.decay', 'model_ema.num_updates']
0: Global ID: 0, local ID: 0, world size: 4
0: Rank 0 before barrier
1: Global ID: 1, local ID: 1, world size: 4
1: Rank 1 before barrier
2: Global ID: 2, local ID: 2, world size: 4
2: Rank 2 before barrier
3: Global ID: 3, local ID: 3, world size: 4
3: Rank 3 before barrier
0: :::MLLOG {"namespace": "", "time_ms": 1714778576674, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 127, "samples_count": 2560000}}
0: Assigned 7500 prompts for this worker.
0: :::MLLOG {"namespace": "", "time_ms": 1714780835938, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 184, "samples_count": 2560000}}
1: Assigned 7500 prompts for this worker.
2: Assigned 7500 prompts for this worker.
3: Assigned 7500 prompts for this worker.
0: Calculating FID activations:   0%|          | 0/235 [00:00<?, ?it/s]Calculating FID activations:   0%|          | 1/235 [00:00<03:44,  1.04it/s]Calculating FID activations:   2%|▏         | 5/235 [00:01<00:40,  5.74it/s]Calculating FID activations:   4%|▍         | 9/235 [00:01<00:21, 10.30it/s]Calculating FID activations:   6%|▌         | 13/235 [00:01<00:16, 13.79it/s]Calculating FID activations:   7%|▋         | 17/235 [00:01<00:13, 16.74it/s]Calculating FID activations:   9%|▉         | 21/235 [00:01<00:11, 18.87it/s]Calculating FID activations:  11%|█         | 25/235 [00:01<00:10, 20.61it/s]Calculating FID activations:  12%|█▏        | 29/235 [00:02<00:08, 22.99it/s]Calculating FID activations:  14%|█▍        | 33/235 [00:02<00:08, 23.70it/s]Calculating FID activations:  16%|█▌        | 37/235 [00:02<00:08, 24.06it/s]Calculating FID activations:  17%|█▋        | 41/235 [00:02<00:08, 24.00it/s]Calculating FID activations:  19%|█▉        | 45/235 [00:02<00:07, 
0: 23.89it/s]Calculating FID activations:  21%|██        | 49/235 [00:02<00:07, 24.32it/s]Calculating FID activations:  23%|██▎       | 53/235 [00:02<00:07, 24.39it/s]Calculating FID activations:  24%|██▍       | 57/235 [00:03<00:07, 24.78it/s]Calculating FID activations:  26%|██▌       | 61/235 [00:03<00:06, 25.23it/s]Calculating FID activations:  28%|██▊       | 65/235 [00:03<00:06, 25.45it/s]Calculating FID activations:  29%|██▉       | 69/235 [00:03<00:06, 25.56it/s]Calculating FID activations:  31%|███       | 73/235 [00:03<00:06, 25.45it/s]Calculating FID activations:  33%|███▎      | 77/235 [00:03<00:06, 25.29it/s]Calculating FID activations:  34%|███▍      | 81/235 [00:04<00:06, 25.20it/s]Calculating FID activations:  36%|███▌      | 85/235 [00:04<00:05, 25.00it/s]Calculating FID activations:  38%|███▊      | 89/235 [00:04<00:05, 26.60it/s]Calculating FID activations:  40%|████      | 94/235 [00:04<00:04, 31.31it/
0: s]Calculating FID activations:  42%|████▏     | 99/235 [00:04<00:03, 34.98it/s]Calculating FID activations:  44%|████▍     | 103/235 [00:04<00:03, 36.22it/s]Calculating FID activations:  46%|████▌     | 108/235 [00:04<00:03, 38.83it/s]Calculating FID activations:  48%|████▊     | 113/235 [00:04<00:03, 38.66it/s]Calculating FID activations:  50%|█████     | 118/235 [00:05<00:02, 40.89it/s]Calculating FID activations:  52%|█████▏    | 123/235 [00:05<00:02, 42.38it/s]Calculating FID activations:  54%|█████▍    | 128/235 [00:05<00:02, 42.46it/s]Calculating FID activations:  57%|█████▋    | 133/235 [00:05<00:02, 40.83it/s]Calculating FID activations:  59%|█████▊    | 138/235 [00:05<00:02, 42.19it/s]Calculating FID activations:  61%|██████    | 143/235 [00:05<00:02, 43.55it/s]Calculating FID activations:  63%|██████▎   | 148/235 [00:05<00:01, 43.90it/s]Calculating FID activations: 
0:  65%|██████▌   | 153/235 [00:05<00:02, 41.00it/s]Calculating FID activations:  67%|██████▋   | 158/235 [00:05<00:01, 42.64it/s]Calculating FID activations:  69%|██████▉   | 163/235 [00:06<00:01, 42.15it/s]Calculating FID activations:  72%|███████▏  | 169/235 [00:06<00:01, 41.34it/s]Calculating FID activations:  74%|███████▍  | 174/235 [00:06<00:01, 43.24it/s]Calculating FID activations:  76%|███████▌  | 179/235 [00:06<00:01, 43.31it/s]Calculating FID activations:  78%|███████▊  | 184/235 [00:06<00:01, 44.45it/s]Calculating FID activations:  80%|████████  | 189/235 [00:06<00:01, 41.54it/s]Calculating FID activations:  83%|████████▎ | 194/235 [00:06<00:00, 42.85it/s]Calculating FID activations:  85%|████████▍ | 199/235 [00:06<00:00, 43.05it/s]Calculating FID activations:  87%|████████▋ | 204/235 [00:07<00:00, 43.96it/s]Calculat
0: ing FID activations:  89%|████████▉ | 209/235 [00:07<00:00, 41.17it/s]Calculating FID activations:  91%|█████████ | 214/235 [00:07<00:00, 42.98it/s]Calculating FID activations:  93%|█████████▎| 219/235 [00:07<00:00, 44.31it/s]Calculating FID activations:  95%|█████████▌| 224/235 [00:07<00:00, 44.67it/s]Calculating FID activations:  97%|█████████▋| 229/235 [00:07<00:00, 41.62it/s]Calculating FID activations: 100%|█████████▉| 234/235 [00:07<00:00, 43.67it/s]Calculating FID activations: 100%|██████████| 235/235 [00:08<00:00, 28.87it/s]
0: Computed feature activations of size torch.Size([7500, 2048])
0: :::MLLOG {"namespace": "", "time_ms": 1714780870246, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 87.60290807521773, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 228, "samples_count": 2560000, "metric": "FID"}}
0: :::MLLOG {"namespace": "", "time_ms": 1714780977485, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.1588035374879837, "metadata": {"file": "/workspace/sd/infer_and_eval.py", "lineno": 258, "samples_count": 2560000, "metric": "CLIP"}}
2: Computed feature activations of size torch.Size([7500, 2048])
0: :::MLLOG {"namespace": "", "time_ms": 1714767767762, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", "lineno": 186, "status": "success", "step_num": 10000}}
1: Computed feature activations of size torch.Size([7500, 2048])
3: Computed feature activations of size torch.Size([7500, 2048])
0: ENDING TIMING RUN AT 2024-05-04 09:03:04 AM
0: RESULT,stable_diffusion,18683,miwa,2024-05-04 03:51:41 AM
2: ENDING TIMING RUN AT 2024-05-04 09:03:05 AM
2: RESULT,stable_diffusion,18684,miwa,2024-05-04 03:51:41 AM
3: ENDING TIMING RUN AT 2024-05-04 09:03:05 AM
3: RESULT,stable_diffusion,18684,miwa,2024-05-04 03:51:41 AM
1: ENDING TIMING RUN AT 2024-05-04 09:03:06 AM
1: RESULT,stable_diffusion,18685,miwa,2024-05-04 03:51:41 AM
