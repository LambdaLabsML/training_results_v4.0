+ echo 'Beginning trial 5 of 5'
Beginning trial 5 of 5
+ echo ':::DLPAL /mnt/weka/MLPerf/smc_nvidia_v4/version.4.29/nvdlfwea+mlperfv40+ssd+20240416.pytorch.sqsh 4957 8 5FWKQ04,8PVMF14,9QVMF14,862KF14,BQVMF14,CRVMF14,GNVMF14,JQVMF14 "SMC_MLPERF_CLUSTER2" SMCH100_008x08x004'
:::DLPAL /mnt/weka/MLPerf/smc_nvidia_v4/version.4.29/nvdlfwea+mlperfv40+ssd+20240416.pytorch.sqsh 4957 8 5FWKQ04,8PVMF14,9QVMF14,862KF14,BQVMF14,CRVMF14,GNVMF14,JQVMF14 "SMC_MLPERF_CLUSTER2" SMCH100_008x08x004
++ srun --ntasks=1 --container-name=single_stage_detector_4957 mlperf-sysjson.sh
srun: warning: can't run 1 processes on 8 nodes, setting nnodes to 1
+ echo ':::SYSJSON {"submitter":"SMC","division":"closed","status":"cloud","system_name":"SMC-H100","number_of_nodes":"8","host_processors_per_node":"2","host_processor_model_name":"Intel(R) Xeon(R) Platinum 8462Y+","host_processor_core_count":"32","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"2.0 TB","host_storage_type":"NVMe SSD","host_storage_capacity":"2x 1.92TB NVMe SSD + 8x 3.84TB NVMe U.2","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"8","accelerator_model_name":"NVIDIA H100 80GB HBM3","accelerator_host_interconnect":"Infiniband NDR","accelerator_frequency":"","accelerator_on-chip_memories":"80 GB","accelerator_memory_configuration":"HBM3","accelerator_memory_capacity":"81559 MiB","accelerator_interconnect":"NVLINK Gen4 900 GB/s + NVSWITCH Gen3","accelerator_interconnect_topology":"NVLINE + NVSWITCH","cooling":"SMC IMMERSION COOLING TECHNOLOGY","hw_notes":"","framework":"PyTorch NVIDIA Release 24.04","other_software_stack":{"cuda_version":"12.4.1.003","cuda_driver_version":"550.54.15","nccl_version":"2.21.5","cublas_version":"12.4.5.8","cudnn_version":"9.1.0.70","trt_version":"8.6.3.1+cuda12.2.2.009","dali_version":"1.36.0","mofed_version":"5.4-rdmacore39.0","openmpi_version":"4.1.7","kernel_version":"Linux 5.15.0-92-generic","nvidia_kernel_driver":"550.54.15"},"operating_system":"Ubuntu 22.04.4 LTS","sw_notes":""}'
:::SYSJSON {"submitter":"SMC","division":"closed","status":"cloud","system_name":"SMC-H100","number_of_nodes":"8","host_processors_per_node":"2","host_processor_model_name":"Intel(R) Xeon(R) Platinum 8462Y+","host_processor_core_count":"32","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"2.0 TB","host_storage_type":"NVMe SSD","host_storage_capacity":"2x 1.92TB NVMe SSD + 8x 3.84TB NVMe U.2","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"8","accelerator_model_name":"NVIDIA H100 80GB HBM3","accelerator_host_interconnect":"Infiniband NDR","accelerator_frequency":"","accelerator_on-chip_memories":"80 GB","accelerator_memory_configuration":"HBM3","accelerator_memory_capacity":"81559 MiB","accelerator_interconnect":"NVLINK Gen4 900 GB/s + NVSWITCH Gen3","accelerator_interconnect_topology":"NVLINE + NVSWITCH","cooling":"SMC IMMERSION COOLING TECHNOLOGY","hw_notes":"","framework":"PyTorch NVIDIA Release 24.04","other_software_stack":{"cuda_version":"12.4.1.003","cuda_driver_version":"550.54.15","nccl_version":"2.21.5","cublas_version":"12.4.5.8","cudnn_version":"9.1.0.70","trt_version":"8.6.3.1+cuda12.2.2.009","dali_version":"1.36.0","mofed_version":"5.4-rdmacore39.0","openmpi_version":"4.1.7","kernel_version":"Linux 5.15.0-92-generic","nvidia_kernel_driver":"550.54.15"},"operating_system":"Ubuntu 22.04.4 LTS","sw_notes":""}
+ srun -N1 -n1 --container-name=single_stage_detector_4957 python -c ''
+ '[' 1 -eq 1 ']'
+ srun --ntasks=8 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on 5FWKQ04
Clearing cache on 9QVMF14
Clearing cache on CRVMF14
Clearing cache on GNVMF14
Clearing cache on 8PVMF14
Clearing cache on JQVMF14
Clearing cache on 862KF14
Clearing cache on BQVMF14
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=8 --container-name=single_stage_detector_4957 python -c '
from mlperf_logger import mllogger
mllogger.event(key=mllogger.constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1715261491498, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1715261491503, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1715261491543, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1715261491572, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1715261491593, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1715261491810, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1715261491871, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1715261492226, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
+ sleep 30
+ srun --ntasks=64 --ntasks-per-node=8 --container-name=single_stage_detector_4957 --container-mounts=/raid/data/ssd:/datasets/open-images-v6,/mnt/weka/MLPerf/smc_run_v4/logs/ssd:/results,/raid/data/ssd//TORCH_HOME:/root/.cache/torch --container-workdir=/workspace/ssd --container-env=MASTER_PORT,MASTER_ADDR slurm2pytorch ./run_and_time.sh
STARTING TIMING RUN AT 2024-05-09 09:32:05 PM
RANK 17: LOCAL_RANK 1, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 17, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:05 PM
STARTING TIMING RUN AT 2024-05-09 09:32:05 PM
RANK 53: LOCAL_RANK 5, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 53, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:05 PM
RANK 51: LOCAL_RANK 3, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 51, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:05 PM
RANK 22: LOCAL_RANK 6, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 22, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
RANK 46: LOCAL_RANK 6, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 46, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:05 PM
RANK 42: LOCAL_RANK 2, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 42, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:05 PM
STARTING TIMING RUN AT 2024-05-09 09:32:05 PM
RANK 18: LOCAL_RANK 2, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 18, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:05 PM
RANK 44: LOCAL_RANK 4, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 44, SLURM_LOCALID 4, OMP_NUM_THREADS 1
RANK 45: LOCAL_RANK 5, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 45, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:05 PM
RANK 23: LOCAL_RANK 7, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 23, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:05 PM
RANK 43: LOCAL_RANK 3, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 43, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:05 PM
RANK 49: LOCAL_RANK 1, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 49, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:05 PM
RANK 54: LOCAL_RANK 6, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 54, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:05 PM
RANK 48: LOCAL_RANK 0, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 48, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:05 PM
RANK 50: LOCAL_RANK 2, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 50, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 52: LOCAL_RANK 4, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 52, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 32: LOCAL_RANK 0, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 32, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 41: LOCAL_RANK 1, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 41, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
RANK 47: LOCAL_RANK 7, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 47, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 40: LOCAL_RANK 0, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 40, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 16: LOCAL_RANK 0, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 16, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 37: LOCAL_RANK 5, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 37, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 38: LOCAL_RANK 6, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 38, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 20: LOCAL_RANK 4, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 20, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 26: LOCAL_RANK 2, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 26, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 39: LOCAL_RANK 7, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 39, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 35: LOCAL_RANK 3, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 35, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 55: LOCAL_RANK 7, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 55, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 27: LOCAL_RANK 3, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 27, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 25: LOCAL_RANK 1, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 25, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 33: LOCAL_RANK 1, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 33, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 58: LOCAL_RANK 2, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 58, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 36: LOCAL_RANK 4, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 36, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 56: LOCAL_RANK 0, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 56, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 0: LOCAL_RANK 0, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 0, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 2: LOCAL_RANK 2, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 2, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 21: LOCAL_RANK 5, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 21, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 7: LOCAL_RANK 7, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 7, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 1: LOCAL_RANK 1, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 1, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 59: LOCAL_RANK 3, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 59, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 57: LOCAL_RANK 1, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 57, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 24: LOCAL_RANK 0, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 24, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 3: LOCAL_RANK 3, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 3, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 4: LOCAL_RANK 4, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 4, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
RANK 6: LOCAL_RANK 6, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 6, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 19: LOCAL_RANK 3, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 19, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 61: LOCAL_RANK 5, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 61, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
RANK 62: LOCAL_RANK 6, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 62, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 15: LOCAL_RANK 7, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 15, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 60: LOCAL_RANK 4, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 60, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 28: LOCAL_RANK 4, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 28, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 31: LOCAL_RANK 7, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 31, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 29: LOCAL_RANK 5, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 29, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 30: LOCAL_RANK 6, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 30, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 8: LOCAL_RANK 0, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 8, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 13: LOCAL_RANK 5, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 13, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 34: LOCAL_RANK 2, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 34, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 12: LOCAL_RANK 4, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 12, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 14: LOCAL_RANK 6, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 14, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 10: LOCAL_RANK 2, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 10, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 9: LOCAL_RANK 1, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 9, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
RANK 11: LOCAL_RANK 3, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 11, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 63: LOCAL_RANK 7, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 63, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2024-05-09 09:32:06 PM
RANK 5: LOCAL_RANK 5, MASTER_ADDR 5FWKQ04, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 4957, SLURM_NTASKS 64, SLURM_PROCID 5, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=32
| distributed init (rank 40): env://
| distributed init (rank 0): env://
| distributed init (rank 24): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 16): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 48): env://
| distributed init (rank 56): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 23): env://
| distributed init (rank 17): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 42): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 18): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 41): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 21): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 20): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 19): env://
| distributed init (rank 22): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 32): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 8): env://
| distributed init (rank 43): env://
| distributed init (rank 45): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 2): env://
| distributed init (rank 44): env://
| distributed init (rank 46): env://
| distributed init (rank 47): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 7): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 4): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 58): env://
| distributed init (rank 61): env://
| distributed init (rank 63): env://
| distributed init (rank 57): env://
| distributed init (rank 3): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 5): env://
| distributed init (rank 60): env://
| distributed init (rank 62): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 6): env://
| distributed init (rank 1): env://
| distributed init (rank 59): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 30): env://
| distributed init (rank 31): env://
| distributed init (rank 26): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 28): env://
| distributed init (rank 53): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 55): env://
| distributed init (rank 54): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 29): env://
| distributed init (rank 25): env://
| distributed init (rank 27): env://
| distributed init (rank 52): env://
| distributed init (rank 51): env://
| distributed init (rank 49): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 50): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 11): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 10): env://
| distributed init (rank 14): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 38): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 34): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 9): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 13): env://
| distributed init (rank 12): env://
| distributed init (rank 15): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 39): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
| distributed init (rank 33): env://
| distributed init (rank 35): env://
| distributed init (rank 37): env://
| distributed init (rank 36): env://
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)
:::MLLOG {"namespace": "", "time_ms": 1715261553840, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "ssd", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 350}}
:::MLLOG {"namespace": "", "time_ms": 1715261553840, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "SUBMISSION_ORG_PLACEHOLDER", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 350}}
:::MLLOG {"namespace": "", "time_ms": 1715261553840, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 350}}
:::MLLOG {"namespace": "", "time_ms": 1715261553840, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 350}}
:::MLLOG {"namespace": "", "time_ms": 1715261553841, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "8xSUBMISSION_PLATFORM_PLACEHOLDER", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 350}}
:::MLLOG {"namespace": "", "time_ms": 1715261553841, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 351}}
:::MLLOG {"namespace": "", "time_ms": 1715261553855, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586074, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553877, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586073, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553877, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586076, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553877, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586075, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553877, "event_type": "POINT_IN_TIME", "key": "local_batch_size", "value": 4, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 369}}
:::MLLOG {"namespace": "", "time_ms": 1715261553877, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586077, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553877, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586078, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553877, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586079, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553877, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586080, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553877, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 256, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 370}}
:::MLLOG {"namespace": "", "time_ms": 1715261553877, "event_type": "POINT_IN_TIME", "key": "epoch_count", "value": 6, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 371}}
:::MLLOG {"namespace": "", "time_ms": 1715261553877, "event_type": "POINT_IN_TIME", "key": "first_epoch_num", "value": 0, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 372}}
Namespace(backbone='resnext50_32x4d', trainable_backbone_layers=3, sync_bn=False, data_layout='channels_last', amp=True, async_coco=True, async_coco_check_freq=20, num_eval_ranks=64, dataset='openimages-mlperf', dataset_path='/datasets/open-images-v6', num_classes=None, train_data_path=None, train_annotations_file=None, val_data_path=None, val_annotations_file=None, image_size=[800, 800], data_augmentation='hflip', epochs=6, max_iters_per_epoch=None, max_eval_iters_per_epoch=None, start_epoch=0, output_dir=None, target_map=0.34, resume='', pretrained=False, batch_size=4, eval_batch_size=32, lr=0.0001, warmup_epochs=1, warmup_factor=0.001, workers=4, print_freq=20, eval_print_freq=20, test_only=False, seed=3253586073, device='cuda', cocoeval='nvidia', coco_threads=8, world_size=64, dist_url='env://', frozen_bn_opt=True, frozen_bn_fp16=True, jit=True, cuda_graphs=True, cuda_graphs_eval=False, cls_head_pad=True, reg_head_pad=True, cuda_graphs_syn=True, model_warmup_epochs=16, master_weights=True, dali=True, dali_matched_idxs=True, dali_eval=True, dali_eval_cache=False, dali_prefetch_queue_depth=2, dali_cpu_decode=False, dali_pinned_memory_size=268435456, dali_cmn=0, dali_cmn_hint=0, dali_decoder_hint_height=7360, dali_decoder_hint_width=7360, dali_decoder_hw_load=0.65, dali_input_batch_multiplier=1, dali_eval_cmn_hint=0, dali_eval_decoder_hint_height=0, dali_eval_decoder_hint_width=0, dali_eval_decoder_hw_load=0.65, dali_eval_input_batch_multiplier=1, dali_sync=False, dali_resize_first=False, apex_adam=True, apex_focal_loss=True, apex_backbone_fusion=True, apex_head_fusion=True, broadcast_buffers=False, fp16_allreduce=False, ddp_bucket_sz=25, ddp_first_bucket_sz=None, no_gradient_as_bucket_view=False, max_boxes=1000, cudnn_bench=False, deterministic=False, not_graphed_prologues=False, metric_loss=False, syn_dataset=False, sync_after_graph_replay=False, allreduce_barrier=False, skip_eval=False, cuda_profiler=False, cuda_profiler_eval=False, cuda_profiler_start=-1, cuda_profiler_stop=-1, power_benchmark=False, power_sustain_time=600, rank=0, gpu=0, distributed=True, dist_backend='nccl', ranks=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63], num_train_ranks=64, train_ranks=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63], eval_ranks=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63], train_rank=0, eval_rank=0)
Getting dataset information
Creating model
:::MLLOG {"namespace": "", "time_ms": 1715261553884, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586114, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553884, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586115, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553884, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586116, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553884, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586117, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553884, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586118, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553884, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586119, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553884, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586120, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553884, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586113, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553885, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586129, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553885, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586097, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553885, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586089, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553885, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586098, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553885, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586130, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553885, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586099, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553885, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586131, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553885, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586100, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553885, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586132, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553885, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586101, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553885, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586133, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553885, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586102, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553885, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586134, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553885, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586103, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553885, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586135, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553885, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586104, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553885, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586136, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553885, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586090, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553885, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586091, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553885, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586092, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553885, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586093, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553885, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586094, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553885, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586095, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553885, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586096, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553888, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586122, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553888, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586124, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553888, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586125, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553888, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586126, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553888, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586121, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553888, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586123, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553888, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586127, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553888, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586128, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553888, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586081, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553888, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586105, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553888, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586082, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553888, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586083, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553888, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586084, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553888, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586085, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553888, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586086, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553888, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586087, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553888, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586088, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553888, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586106, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553888, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586107, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553888, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586108, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553888, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586110, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553888, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586112, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553888, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586109, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553888, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3253586111, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 366}}
:::MLLOG {"namespace": "", "time_ms": 1715261553885, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 209, "tensor": "module.backbone.fpn.extra_blocks.p6.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261553901, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 211, "tensor": "module.backbone.fpn.extra_blocks.p6.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1715261553901, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 209, "tensor": "module.backbone.fpn.extra_blocks.p7.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261553903, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 211, "tensor": "module.backbone.fpn.extra_blocks.p7.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554016, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554016, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554016, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554016, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554017, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554017, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554017, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554017, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554017, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554017, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554017, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554018, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554018, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554018, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554019, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554019, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554020, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554020, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554020, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554021, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554021, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554022, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.3.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554022, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.3.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554022, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.3.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554023, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554024, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554024, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554026, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554028, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554030, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554031, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554032, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554034, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554035, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554037, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.3.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554039, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.3.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554039, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.3.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554041, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.4.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554043, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.4.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554043, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.4.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554045, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.5.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554047, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.5.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554048, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.5.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554050, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554053, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554055, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554062, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554070, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554077, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554078, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554086, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554093, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554095, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554180, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.inner_blocks.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554181, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.inner_blocks.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554181, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.inner_blocks.1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554182, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.inner_blocks.1.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554182, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.inner_blocks.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554184, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.inner_blocks.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554184, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.layer_blocks.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554186, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.layer_blocks.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554186, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.layer_blocks.1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554188, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.layer_blocks.1.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554188, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.layer_blocks.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554190, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.layer_blocks.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554208, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554211, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554211, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554213, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554213, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.4.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554215, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.4.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554215, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.6.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554217, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.6.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554241, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 148, "tensor": "module.head.classification_head.cls_logits.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554260, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 150, "tensor": "module.head.classification_head.cls_logits.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554269, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 317, "tensor": "module.head.regression_head.bbox_reg.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554269, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 319, "tensor": "module.head.regression_head.bbox_reg.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554269, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 324, "tensor": "module.head.regression_head.conv.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554272, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 326, "tensor": "module.head.regression_head.conv.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554272, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 324, "tensor": "module.head.regression_head.conv.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554274, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 326, "tensor": "module.head.regression_head.conv.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554274, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 324, "tensor": "module.head.regression_head.conv.4.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554276, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 326, "tensor": "module.head.regression_head.conv.4.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554276, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 324, "tensor": "module.head.regression_head.conv.6.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1715261554279, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 326, "tensor": "module.head.regression_head.conv.6.bias"}}
Casting convolutional layers to half
[rank25]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank0]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank27]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank31]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank24]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank26]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank28]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank29]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank30]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank16]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank17]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank18]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank19]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank20]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank21]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank22]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank23]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank6]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank7]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank4]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank5]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank58]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank1]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank2]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank3]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank8]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank61]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank62]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank63]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank56]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank57]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank59]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank60]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank10]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank11]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank12]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank14]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank15]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank9]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank13]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank49]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank50]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank54]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank48]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank51]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank52]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank53]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank55]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank41]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank42]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank44]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank46]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank47]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank40]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank43]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank45]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank34]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank35]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank36]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank38]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank39]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank32]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank33]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
[rank37]:[W Utils.hpp:108] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarString)
:::MLLOG {"namespace": "", "time_ms": 1715261554370, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "adam", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 448}}
:::MLLOG {"namespace": "", "time_ms": 1715261554370, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.0001, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 449}}
:::MLLOG {"namespace": "", "time_ms": 1715261554370, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 450}}
:::MLLOG {"namespace": "", "time_ms": 1715261554370, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_epochs", "value": 1, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 451}}
:::MLLOG {"namespace": "", "time_ms": 1715261554370, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_factor", "value": 0.001, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 452}}
:::MLLOG {"namespace": "", "time_ms": 1715261554370, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 453}}
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3553.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Model eval warmup
Time: 40.56851363182068 sec
Creating Dali training dataloader
Creating Dali eval dataloader
CUDA graph capture for training
CUDA graphs: data preprocessing complete
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:414: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
CUDA graphs: warmup iterations complete
CUDA graphs: capture complete
CUDA graph capture for training complete
:::MLLOG {"namespace": "", "time_ms": 1715261618483, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 573}}
:::MLLOG {"namespace": "", "time_ms": 1715261618484, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 577}}
:::MLLOG {"namespace": "", "time_ms": 1715261618484, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 4572, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 625}}
:::MLLOG {"namespace": "", "time_ms": 1715261618484, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 13, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 628}}
Running ...
:::MLLOG {"namespace": "", "time_ms": 1715261618484, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 0, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 0}}
Epoch: [0]  [   0/4572]  eta: 0:01:27    time: 0.0191  data: 0.0001  max mem: 13772
Epoch: [0]  [  20/4572]  eta: 0:01:31    time: 0.0201  data: 0.0183  max mem: 13772
Epoch: [0]  [  40/4572]  eta: 0:01:31    time: 0.0201  data: 0.0182  max mem: 13772
Epoch: [0]  [  60/4572]  eta: 0:01:30    time: 0.0202  data: 0.0179  max mem: 13772
Epoch: [0]  [  80/4572]  eta: 0:01:30    time: 0.0204  data: 0.0185  max mem: 13772
Epoch: [0]  [ 100/4572]  eta: 0:01:31    time: 0.0216  data: 0.0193  max mem: 13772
Epoch: [0]  [ 120/4572]  eta: 0:01:30    time: 0.0197  data: 0.0174  max mem: 13772
Epoch: [0]  [ 140/4572]  eta: 0:01:29    time: 0.0197  data: 0.0179  max mem: 13772
Epoch: [0]  [ 160/4572]  eta: 0:01:29    time: 0.0202  data: 0.0179  max mem: 13772
Epoch: [0]  [ 180/4572]  eta: 0:01:28    time: 0.0197  data: 0.0174  max mem: 13772
Epoch: [0]  [ 200/4572]  eta: 0:01:28    time: 0.0196  data: 0.0178  max mem: 13772
Epoch: [0]  [ 220/4572]  eta: 0:01:27    time: 0.0197  data: 0.0174  max mem: 13772
Epoch: [0]  [ 240/4572]  eta: 0:01:26    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [0]  [ 260/4572]  eta: 0:01:26    time: 0.0197  data: 0.0179  max mem: 13772
Epoch: [0]  [ 280/4572]  eta: 0:01:25    time: 0.0197  data: 0.0173  max mem: 13772
Epoch: [0]  [ 300/4572]  eta: 0:01:25    time: 0.0203  data: 0.0180  max mem: 13772
Epoch: [0]  [ 320/4572]  eta: 0:01:25    time: 0.0196  data: 0.0172  max mem: 13772
Epoch: [0]  [ 340/4572]  eta: 0:01:24    time: 0.0196  data: 0.0178  max mem: 13772
Epoch: [0]  [ 360/4572]  eta: 0:01:24    time: 0.0196  data: 0.0172  max mem: 13772
Epoch: [0]  [ 380/4572]  eta: 0:01:24    time: 0.0241  data: 0.0174  max mem: 13772
Epoch: [0]  [ 400/4572]  eta: 0:01:24    time: 0.0200  data: 0.0182  max mem: 13772
Epoch: [0]  [ 420/4572]  eta: 0:01:23    time: 0.0199  data: 0.0176  max mem: 13772
Epoch: [0]  [ 440/4572]  eta: 0:01:23    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [0]  [ 460/4572]  eta: 0:01:22    time: 0.0198  data: 0.0175  max mem: 13772
Epoch: [0]  [ 480/4572]  eta: 0:01:22    time: 0.0196  data: 0.0177  max mem: 13772
Epoch: [0]  [ 500/4572]  eta: 0:01:21    time: 0.0198  data: 0.0172  max mem: 13772
Epoch: [0]  [ 520/4572]  eta: 0:01:21    time: 0.0200  data: 0.0177  max mem: 13772
Epoch: [0]  [ 540/4572]  eta: 0:01:20    time: 0.0197  data: 0.0174  max mem: 13772
Epoch: [0]  [ 560/4572]  eta: 0:01:20    time: 0.0198  data: 0.0174  max mem: 13772
Epoch: [0]  [ 580/4572]  eta: 0:01:19    time: 0.0196  data: 0.0177  max mem: 13772
Epoch: [0]  [ 600/4572]  eta: 0:01:19    time: 0.0205  data: 0.0186  max mem: 13772
Epoch: [0]  [ 620/4572]  eta: 0:01:19    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [0]  [ 640/4572]  eta: 0:01:18    time: 0.0199  data: 0.0176  max mem: 13772
Epoch: [0]  [ 660/4572]  eta: 0:01:18    time: 0.0196  data: 0.0172  max mem: 13772
Epoch: [0]  [ 680/4572]  eta: 0:01:17    time: 0.0196  data: 0.0177  max mem: 13772
Epoch: [0]  [ 700/4572]  eta: 0:01:17    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [0]  [ 720/4572]  eta: 0:01:16    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [0]  [ 740/4572]  eta: 0:01:16    time: 0.0203  data: 0.0180  max mem: 13772
Epoch: [0]  [ 760/4572]  eta: 0:01:16    time: 0.0196  data: 0.0178  max mem: 13772
Epoch: [0]  [ 780/4572]  eta: 0:01:15    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [0]  [ 800/4572]  eta: 0:01:15    time: 0.0200  data: 0.0182  max mem: 13772
Epoch: [0]  [ 820/4572]  eta: 0:01:14    time: 0.0199  data: 0.0176  max mem: 13772
Epoch: [0]  [ 840/4572]  eta: 0:01:14    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [0]  [ 860/4572]  eta: 0:01:14    time: 0.0195  data: 0.0177  max mem: 13772
Epoch: [0]  [ 880/4572]  eta: 0:01:13    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [0]  [ 900/4572]  eta: 0:01:13    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [0]  [ 920/4572]  eta: 0:01:12    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [0]  [ 940/4572]  eta: 0:01:12    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [0]  [ 960/4572]  eta: 0:01:11    time: 0.0199  data: 0.0175  max mem: 13772
Epoch: [0]  [ 980/4572]  eta: 0:01:11    time: 0.0196  data: 0.0172  max mem: 13772
Epoch: [0]  [1000/4572]  eta: 0:01:11    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [0]  [1020/4572]  eta: 0:01:10    time: 0.0197  data: 0.0178  max mem: 13772
Epoch: [0]  [1040/4572]  eta: 0:01:10    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [0]  [1060/4572]  eta: 0:01:09    time: 0.0198  data: 0.0174  max mem: 13772
Epoch: [0]  [1080/4572]  eta: 0:01:09    time: 0.0198  data: 0.0175  max mem: 13772
Epoch: [0]  [1100/4572]  eta: 0:01:09    time: 0.0204  data: 0.0180  max mem: 13772
Epoch: [0]  [1120/4572]  eta: 0:01:08    time: 0.0196  data: 0.0178  max mem: 13772
Epoch: [0]  [1140/4572]  eta: 0:01:08    time: 0.0196  data: 0.0178  max mem: 13772
Epoch: [0]  [1160/4572]  eta: 0:01:07    time: 0.0199  data: 0.0172  max mem: 13772
Epoch: [0]  [1180/4572]  eta: 0:01:07    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [0]  [1200/4572]  eta: 0:01:06    time: 0.0195  data: 0.0177  max mem: 13772
Epoch: [0]  [1220/4572]  eta: 0:01:06    time: 0.0197  data: 0.0173  max mem: 13772
Epoch: [0]  [1240/4572]  eta: 0:01:06    time: 0.0197  data: 0.0178  max mem: 13772
Epoch: [0]  [1260/4572]  eta: 0:01:05    time: 0.0200  data: 0.0177  max mem: 13772
Epoch: [0]  [1280/4572]  eta: 0:01:05    time: 0.0196  data: 0.0177  max mem: 13772
Epoch: [0]  [1300/4572]  eta: 0:01:04    time: 0.0195  data: 0.0177  max mem: 13772
Epoch: [0]  [1320/4572]  eta: 0:01:04    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [0]  [1340/4572]  eta: 0:01:04    time: 0.0196  data: 0.0177  max mem: 13772
Epoch: [0]  [1360/4572]  eta: 0:01:03    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [0]  [1380/4572]  eta: 0:01:03    time: 0.0197  data: 0.0178  max mem: 13772
Epoch: [0]  [1400/4572]  eta: 0:01:02    time: 0.0197  data: 0.0173  max mem: 13772
Epoch: [0]  [1420/4572]  eta: 0:01:02    time: 0.0199  data: 0.0172  max mem: 13772
Epoch: [0]  [1440/4572]  eta: 0:01:02    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [0]  [1460/4572]  eta: 0:01:01    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [0]  [1480/4572]  eta: 0:01:01    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [0]  [1500/4572]  eta: 0:01:01    time: 0.0245  data: 0.0221  max mem: 13772
Epoch: [0]  [1520/4572]  eta: 0:01:00    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [0]  [1540/4572]  eta: 0:01:00    time: 0.0199  data: 0.0180  max mem: 13772
Epoch: [0]  [1560/4572]  eta: 0:00:59    time: 0.0196  data: 0.0172  max mem: 13772
Epoch: [0]  [1580/4572]  eta: 0:00:59    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [0]  [1600/4572]  eta: 0:00:59    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [0]  [1620/4572]  eta: 0:00:58    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [0]  [1640/4572]  eta: 0:00:58    time: 0.0198  data: 0.0175  max mem: 13772
Epoch: [0]  [1660/4572]  eta: 0:00:57    time: 0.0198  data: 0.0174  max mem: 13772
Epoch: [0]  [1680/4572]  eta: 0:00:57    time: 0.0197  data: 0.0173  max mem: 13772
Epoch: [0]  [1700/4572]  eta: 0:00:57    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [0]  [1720/4572]  eta: 0:00:56    time: 0.0197  data: 0.0178  max mem: 13772
Epoch: [0]  [1740/4572]  eta: 0:00:56    time: 0.0196  data: 0.0176  max mem: 13772
Epoch: [0]  [1760/4572]  eta: 0:00:55    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [0]  [1780/4572]  eta: 0:00:55    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [0]  [1800/4572]  eta: 0:00:54    time: 0.0196  data: 0.0177  max mem: 13772
Epoch: [0]  [1820/4572]  eta: 0:00:54    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [0]  [1840/4572]  eta: 0:00:54    time: 0.0197  data: 0.0173  max mem: 13772
Epoch: [0]  [1860/4572]  eta: 0:00:53    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [0]  [1880/4572]  eta: 0:00:53    time: 0.0195  data: 0.0169  max mem: 13772
Epoch: [0]  [1900/4572]  eta: 0:00:52    time: 0.0205  data: 0.0181  max mem: 13772
Epoch: [0]  [1920/4572]  eta: 0:00:52    time: 0.0196  data: 0.0172  max mem: 13772
Epoch: [0]  [1940/4572]  eta: 0:00:52    time: 0.0200  data: 0.0176  max mem: 13772
Epoch: [0]  [1960/4572]  eta: 0:00:51    time: 0.0196  data: 0.0172  max mem: 13772
Epoch: [0]  [1980/4572]  eta: 0:00:51    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [0]  [2000/4572]  eta: 0:00:51    time: 0.0203  data: 0.0179  max mem: 13772
Epoch: [0]  [2020/4572]  eta: 0:00:50    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [0]  [2040/4572]  eta: 0:00:50    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [0]  [2060/4572]  eta: 0:00:49    time: 0.0200  data: 0.0182  max mem: 13772
Epoch: [0]  [2080/4572]  eta: 0:00:49    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [0]  [2100/4572]  eta: 0:00:49    time: 0.0198  data: 0.0175  max mem: 13772
Epoch: [0]  [2120/4572]  eta: 0:00:48    time: 0.0195  data: 0.0177  max mem: 13772
Epoch: [0]  [2140/4572]  eta: 0:00:48    time: 0.0201  data: 0.0177  max mem: 13772
Epoch: [0]  [2160/4572]  eta: 0:00:47    time: 0.0202  data: 0.0178  max mem: 13772
Epoch: [0]  [2180/4572]  eta: 0:00:47    time: 0.0204  data: 0.0181  max mem: 13772
Epoch: [0]  [2200/4572]  eta: 0:00:47    time: 0.0197  data: 0.0173  max mem: 13772
Epoch: [0]  [2220/4572]  eta: 0:00:46    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [0]  [2240/4572]  eta: 0:00:46    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [0]  [2260/4572]  eta: 0:00:45    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [0]  [2280/4572]  eta: 0:00:45    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [0]  [2300/4572]  eta: 0:00:45    time: 0.0198  data: 0.0179  max mem: 13772
Epoch: [0]  [2320/4572]  eta: 0:00:44    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [0]  [2340/4572]  eta: 0:00:44    time: 0.0201  data: 0.0177  max mem: 13772
Epoch: [0]  [2360/4572]  eta: 0:00:43    time: 0.0197  data: 0.0174  max mem: 13772
Epoch: [0]  [2380/4572]  eta: 0:00:43    time: 0.0196  data: 0.0172  max mem: 13772
Epoch: [0]  [2400/4572]  eta: 0:00:43    time: 0.0196  data: 0.0172  max mem: 13772
Epoch: [0]  [2420/4572]  eta: 0:00:42    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [0]  [2440/4572]  eta: 0:00:42    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [0]  [2460/4572]  eta: 0:00:41    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [0]  [2480/4572]  eta: 0:00:41    time: 0.0196  data: 0.0177  max mem: 13772
Epoch: [0]  [2500/4572]  eta: 0:00:41    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [0]  [2520/4572]  eta: 0:00:40    time: 0.0196  data: 0.0172  max mem: 13772
Epoch: [0]  [2540/4572]  eta: 0:00:40    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [0]  [2560/4572]  eta: 0:00:39    time: 0.0196  data: 0.0172  max mem: 13772
Epoch: [0]  [2580/4572]  eta: 0:00:39    time: 0.0196  data: 0.0172  max mem: 13772
Epoch: [0]  [2600/4572]  eta: 0:00:39    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [0]  [2620/4572]  eta: 0:00:38    time: 0.0196  data: 0.0177  max mem: 13772
Epoch: [0]  [2640/4572]  eta: 0:00:38    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [0]  [2660/4572]  eta: 0:00:37    time: 0.0201  data: 0.0177  max mem: 13772
Epoch: [0]  [2680/4572]  eta: 0:00:37    time: 0.0198  data: 0.0174  max mem: 13772
Epoch: [0]  [2700/4572]  eta: 0:00:37    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [0]  [2720/4572]  eta: 0:00:36    time: 0.0196  data: 0.0172  max mem: 13772
Epoch: [0]  [2740/4572]  eta: 0:00:36    time: 0.0211  data: 0.0192  max mem: 13772
Epoch: [0]  [2760/4572]  eta: 0:00:35    time: 0.0196  data: 0.0171  max mem: 13772
Epoch: [0]  [2780/4572]  eta: 0:00:35    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [0]  [2800/4572]  eta: 0:00:35    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [0]  [2820/4572]  eta: 0:00:34    time: 0.0198  data: 0.0175  max mem: 13772
Epoch: [0]  [2840/4572]  eta: 0:00:34    time: 0.0198  data: 0.0175  max mem: 13772
Epoch: [0]  [2860/4572]  eta: 0:00:33    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [0]  [2880/4572]  eta: 0:00:33    time: 0.0195  data: 0.0169  max mem: 13772
Epoch: [0]  [2900/4572]  eta: 0:00:33    time: 0.0197  data: 0.0172  max mem: 13772
Epoch: [0]  [2920/4572]  eta: 0:00:32    time: 0.0195  data: 0.0170  max mem: 13772
Epoch: [0]  [2940/4572]  eta: 0:00:32    time: 0.0195  data: 0.0175  max mem: 13772
Epoch: [0]  [2960/4572]  eta: 0:00:31    time: 0.0195  data: 0.0175  max mem: 13772
Epoch: [0]  [2980/4572]  eta: 0:00:31    time: 0.0204  data: 0.0178  max mem: 13772
Epoch: [0]  [3000/4572]  eta: 0:00:31    time: 0.0195  data: 0.0169  max mem: 13772
Epoch: [0]  [3020/4572]  eta: 0:00:30    time: 0.0195  data: 0.0169  max mem: 13772
Epoch: [0]  [3040/4572]  eta: 0:00:30    time: 0.0198  data: 0.0173  max mem: 13772
Epoch: [0]  [3060/4572]  eta: 0:00:29    time: 0.0195  data: 0.0170  max mem: 13772
Epoch: [0]  [3080/4572]  eta: 0:00:29    time: 0.0195  data: 0.0170  max mem: 13772
Epoch: [0]  [3100/4572]  eta: 0:00:29    time: 0.0198  data: 0.0173  max mem: 13772
Epoch: [0]  [3120/4572]  eta: 0:00:28    time: 0.0208  data: 0.0183  max mem: 13772
Epoch: [0]  [3140/4572]  eta: 0:00:28    time: 0.0195  data: 0.0170  max mem: 13772
Epoch: [0]  [3160/4572]  eta: 0:00:27    time: 0.0195  data: 0.0169  max mem: 13772
Epoch: [0]  [3180/4572]  eta: 0:00:27    time: 0.0195  data: 0.0169  max mem: 13772
Epoch: [0]  [3200/4572]  eta: 0:00:27    time: 0.0195  data: 0.0170  max mem: 13772
Epoch: [0]  [3220/4572]  eta: 0:00:26    time: 0.0198  data: 0.0172  max mem: 13772
Epoch: [0]  [3240/4572]  eta: 0:00:26    time: 0.0198  data: 0.0172  max mem: 13772
Epoch: [0]  [3260/4572]  eta: 0:00:25    time: 0.0204  data: 0.0170  max mem: 13772
Epoch: [0]  [3280/4572]  eta: 0:00:25    time: 0.0195  data: 0.0170  max mem: 13772
Epoch: [0]  [3300/4572]  eta: 0:00:25    time: 0.0199  data: 0.0170  max mem: 13772
Epoch: [0]  [3320/4572]  eta: 0:00:24    time: 0.0198  data: 0.0173  max mem: 13772
Epoch: [0]  [3340/4572]  eta: 0:00:24    time: 0.0195  data: 0.0170  max mem: 13772
Epoch: [0]  [3360/4572]  eta: 0:00:23    time: 0.0198  data: 0.0178  max mem: 13772
Epoch: [0]  [3380/4572]  eta: 0:00:23    time: 0.0196  data: 0.0171  max mem: 13772
Epoch: [0]  [3400/4572]  eta: 0:00:23    time: 0.0199  data: 0.0173  max mem: 13772
Epoch: [0]  [3420/4572]  eta: 0:00:22    time: 0.0198  data: 0.0173  max mem: 13772
Epoch: [0]  [3440/4572]  eta: 0:00:22    time: 0.0195  data: 0.0170  max mem: 13772
Epoch: [0]  [3460/4572]  eta: 0:00:21    time: 0.0197  data: 0.0172  max mem: 13772
Epoch: [0]  [3480/4572]  eta: 0:00:21    time: 0.0197  data: 0.0177  max mem: 13772
Epoch: [0]  [3500/4572]  eta: 0:00:21    time: 0.0195  data: 0.0170  max mem: 13772
Epoch: [0]  [3520/4572]  eta: 0:00:20    time: 0.0195  data: 0.0175  max mem: 13772
Epoch: [0]  [3540/4572]  eta: 0:00:20    time: 0.0198  data: 0.0173  max mem: 13772
Epoch: [0]  [3560/4572]  eta: 0:00:20    time: 0.0196  data: 0.0171  max mem: 13772
Epoch: [0]  [3580/4572]  eta: 0:00:19    time: 0.0195  data: 0.0170  max mem: 13772
Epoch: [0]  [3600/4572]  eta: 0:00:19    time: 0.0197  data: 0.0171  max mem: 13772
Epoch: [0]  [3620/4572]  eta: 0:00:18    time: 0.0201  data: 0.0175  max mem: 13772
Epoch: [0]  [3640/4572]  eta: 0:00:18    time: 0.0195  data: 0.0169  max mem: 13772
Epoch: [0]  [3660/4572]  eta: 0:00:18    time: 0.0195  data: 0.0170  max mem: 13772
Epoch: [0]  [3680/4572]  eta: 0:00:17    time: 0.0198  data: 0.0172  max mem: 13772
Epoch: [0]  [3700/4572]  eta: 0:00:17    time: 0.0199  data: 0.0172  max mem: 13772
Epoch: [0]  [3720/4572]  eta: 0:00:16    time: 0.0206  data: 0.0181  max mem: 13772
Epoch: [0]  [3740/4572]  eta: 0:00:16    time: 0.0196  data: 0.0171  max mem: 13772
Epoch: [0]  [3760/4572]  eta: 0:00:16    time: 0.0195  data: 0.0170  max mem: 13772
Epoch: [0]  [3780/4572]  eta: 0:00:15    time: 0.0195  data: 0.0170  max mem: 13772
Epoch: [0]  [3800/4572]  eta: 0:00:15    time: 0.0195  data: 0.0169  max mem: 13772
Epoch: [0]  [3820/4572]  eta: 0:00:14    time: 0.0195  data: 0.0170  max mem: 13772
Epoch: [0]  [3840/4572]  eta: 0:00:14    time: 0.0196  data: 0.0171  max mem: 13772
Epoch: [0]  [3860/4572]  eta: 0:00:14    time: 0.0195  data: 0.0170  max mem: 13772
Epoch: [0]  [3880/4572]  eta: 0:00:13    time: 0.0196  data: 0.0171  max mem: 13772
Epoch: [0]  [3900/4572]  eta: 0:00:13    time: 0.0195  data: 0.0169  max mem: 13772
Epoch: [0]  [3920/4572]  eta: 0:00:12    time: 0.0196  data: 0.0171  max mem: 13772
Epoch: [0]  [3940/4572]  eta: 0:00:12    time: 0.0198  data: 0.0172  max mem: 13772
Epoch: [0]  [3960/4572]  eta: 0:00:12    time: 0.0197  data: 0.0177  max mem: 13772
Epoch: [0]  [3980/4572]  eta: 0:00:11    time: 0.0195  data: 0.0169  max mem: 13772
Epoch: [0]  [4000/4572]  eta: 0:00:11    time: 0.0195  data: 0.0170  max mem: 13772
Epoch: [0]  [4020/4572]  eta: 0:00:10    time: 0.0195  data: 0.0170  max mem: 13772
Epoch: [0]  [4040/4572]  eta: 0:00:10    time: 0.0199  data: 0.0174  max mem: 13772
Epoch: [0]  [4060/4572]  eta: 0:00:10    time: 0.0195  data: 0.0170  max mem: 13772
Epoch: [0]  [4080/4572]  eta: 0:00:09    time: 0.0195  data: 0.0175  max mem: 13772
Epoch: [0]  [4100/4572]  eta: 0:00:09    time: 0.0195  data: 0.0175  max mem: 13772
Epoch: [0]  [4120/4572]  eta: 0:00:08    time: 0.0198  data: 0.0174  max mem: 13772
Epoch: [0]  [4140/4572]  eta: 0:00:08    time: 0.0195  data: 0.0170  max mem: 13772
Epoch: [0]  [4160/4572]  eta: 0:00:08    time: 0.0195  data: 0.0175  max mem: 13772
Epoch: [0]  [4180/4572]  eta: 0:00:07    time: 0.0195  data: 0.0169  max mem: 13772
Epoch: [0]  [4200/4572]  eta: 0:00:07    time: 0.0201  data: 0.0176  max mem: 13772
Epoch: [0]  [4220/4572]  eta: 0:00:06    time: 0.0195  data: 0.0169  max mem: 13772
Epoch: [0]  [4240/4572]  eta: 0:00:06    time: 0.0195  data: 0.0175  max mem: 13772
Epoch: [0]  [4260/4572]  eta: 0:00:06    time: 0.0195  data: 0.0170  max mem: 13772
Epoch: [0]  [4280/4572]  eta: 0:00:05    time: 0.0195  data: 0.0170  max mem: 13772
Epoch: [0]  [4300/4572]  eta: 0:00:05    time: 0.0195  data: 0.0169  max mem: 13772
Epoch: [0]  [4320/4572]  eta: 0:00:04    time: 0.0197  data: 0.0176  max mem: 13772
Epoch: [0]  [4340/4572]  eta: 0:00:04    time: 0.0195  data: 0.0169  max mem: 13772
Epoch: [0]  [4360/4572]  eta: 0:00:04    time: 0.0195  data: 0.0170  max mem: 13772
Epoch: [0]  [4380/4572]  eta: 0:00:03    time: 0.0197  data: 0.0172  max mem: 13772
Epoch: [0]  [4400/4572]  eta: 0:00:03    time: 0.0195  data: 0.0170  max mem: 13772
Epoch: [0]  [4420/4572]  eta: 0:00:03    time: 0.0194  data: 0.0169  max mem: 13772
Epoch: [0]  [4440/4572]  eta: 0:00:02    time: 0.0196  data: 0.0170  max mem: 13772
Epoch: [0]  [4460/4572]  eta: 0:00:02    time: 0.0196  data: 0.0170  max mem: 13772
Epoch: [0]  [4480/4572]  eta: 0:00:01    time: 0.0199  data: 0.0170  max mem: 13772
Epoch: [0]  [4500/4572]  eta: 0:00:01    time: 0.0195  data: 0.0170  max mem: 13772
Epoch: [0]  [4520/4572]  eta: 0:00:01    time: 0.0195  data: 0.0169  max mem: 13772
Epoch: [0]  [4540/4572]  eta: 0:00:00    time: 0.0203  data: 0.0178  max mem: 13772
Epoch: [0]  [4560/4572]  eta: 0:00:00    time: 0.0195  data: 0.0170  max mem: 13772
Epoch: [0]  [4571/4572]  eta: 0:00:00    time: 0.0195  data: 0.0170  max mem: 13772
Epoch: [0] Total time: 0:01:30 (0.0198 s / it)
:::MLLOG {"namespace": "", "time_ms": 1715261708824, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 0, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 0}}
:::MLLOG {"namespace": "", "time_ms": 1715261708824, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 202.52345351764242}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 1}}
:::MLLOG {"namespace": "", "time_ms": 1715261708824, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 344, "epoch_num": 1}}
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
Test:  [ 0/13]  eta: 0:00:05  model_time: 0.4027 (0.4027)  evaluator_time: 0.0046 (0.0046)  time: 0.4167  data: 0.0004  max mem: 13772
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
Test:  [12/13]  eta: 0:00:00  model_time: 0.2976 (0.2846)  evaluator_time: 0.0045 (0.0042)  time: 0.2906  data: 0.0010  max mem: 13772
Test: Total time: 0:00:03 (0.2906 s / it)
Averaged stats: model_time: 0.2976 (0.2883)  evaluator_time: 0.0045 (0.0041)
:::MLLOG {"namespace": "", "time_ms": 1715261713102, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 1}}
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
Epoch: [1]  [   0/4571]  eta: 0:01:31    time: 0.0201  data: 0.0007  max mem: 13772
Epoch: [1]  [  20/4571]  eta: 0:01:28    time: 0.0195  data: 0.0169  max mem: 13772
Epoch: [1]  [  40/4571]  eta: 0:01:29    time: 0.0198  data: 0.0179  max mem: 13772
Epoch: [1]  [  60/4571]  eta: 0:01:28    time: 0.0194  data: 0.0175  max mem: 13772
Epoch: [1]  [  80/4571]  eta: 0:01:27    time: 0.0195  data: 0.0175  max mem: 13772
Epoch: [1]  [ 100/4571]  eta: 0:01:27    time: 0.0198  data: 0.0178  max mem: 13772
Epoch: [1]  [ 120/4571]  eta: 0:01:27    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [1]  [ 140/4571]  eta: 0:01:27    time: 0.0203  data: 0.0171  max mem: 13772
Epoch: [1]  [ 160/4571]  eta: 0:01:27    time: 0.0202  data: 0.0178  max mem: 13772
Epoch: [1]  [ 180/4571]  eta: 0:01:26    time: 0.0198  data: 0.0173  max mem: 13772
Epoch: [1]  [ 200/4571]  eta: 0:01:26    time: 0.0194  data: 0.0169  max mem: 13772
Epoch: [1]  [ 220/4571]  eta: 0:01:25    time: 0.0198  data: 0.0174  max mem: 13772
Epoch: [1]  [ 240/4571]  eta: 0:01:25    time: 0.0197  data: 0.0172  max mem: 13772
Epoch: [1]  [ 260/4571]  eta: 0:01:24    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [1]  [ 280/4571]  eta: 0:01:24    time: 0.0196  data: 0.0177  max mem: 13772
Epoch: [1]  [ 300/4571]  eta: 0:01:24    time: 0.0195  data: 0.0175  max mem: 13772
Epoch: [1]  [ 320/4571]  eta: 0:01:23    time: 0.0194  data: 0.0169  max mem: 13772
Epoch: [1]  [ 340/4571]  eta: 0:01:23    time: 0.0200  data: 0.0174  max mem: 13772
Epoch: [1]  [ 360/4571]  eta: 0:01:22    time: 0.0195  data: 0.0169  max mem: 13772
Epoch: [1]  [ 380/4571]  eta: 0:01:22    time: 0.0195  data: 0.0169  max mem: 13772
Epoch: [1]  [ 400/4571]  eta: 0:01:22    time: 0.0197  data: 0.0169  max mem: 13772
Epoch: [1]  [ 420/4571]  eta: 0:01:21    time: 0.0195  data: 0.0167  max mem: 13772
Epoch: [1]  [ 440/4571]  eta: 0:01:21    time: 0.0196  data: 0.0167  max mem: 13772
Epoch: [1]  [ 460/4571]  eta: 0:01:20    time: 0.0194  data: 0.0167  max mem: 13772
Epoch: [1]  [ 480/4571]  eta: 0:01:20    time: 0.0194  data: 0.0165  max mem: 13772
Epoch: [1]  [ 500/4571]  eta: 0:01:19    time: 0.0195  data: 0.0168  max mem: 13772
:::MLLOG {"namespace": "", "time_ms": 1715261723206, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.1993104134231119, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 437, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1715261723206, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 438, "epoch_num": 1}}
Epoch: [1]  [ 520/4571]  eta: 0:01:19    time: 0.0203  data: 0.0182  max mem: 13772
Epoch: [1]  [ 540/4571]  eta: 0:01:19    time: 0.0198  data: 0.0170  max mem: 13772
Epoch: [1]  [ 560/4571]  eta: 0:01:18    time: 0.0195  data: 0.0169  max mem: 13772
Epoch: [1]  [ 580/4571]  eta: 0:01:18    time: 0.0195  data: 0.0170  max mem: 13772
Epoch: [1]  [ 600/4571]  eta: 0:01:18    time: 0.0200  data: 0.0174  max mem: 13772
Epoch: [1]  [ 620/4571]  eta: 0:01:17    time: 0.0195  data: 0.0169  max mem: 13772
Epoch: [1]  [ 640/4571]  eta: 0:01:17    time: 0.0196  data: 0.0170  max mem: 13772
Epoch: [1]  [ 660/4571]  eta: 0:01:16    time: 0.0201  data: 0.0175  max mem: 13772
Epoch: [1]  [ 680/4571]  eta: 0:01:16    time: 0.0195  data: 0.0170  max mem: 13772
Epoch: [1]  [ 700/4571]  eta: 0:01:16    time: 0.0195  data: 0.0170  max mem: 13772
Epoch: [1]  [ 720/4571]  eta: 0:01:15    time: 0.0194  data: 0.0169  max mem: 13772
Epoch: [1]  [ 740/4571]  eta: 0:01:15    time: 0.0198  data: 0.0172  max mem: 13772
Epoch: [1]  [ 760/4571]  eta: 0:01:14    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [1]  [ 780/4571]  eta: 0:01:14    time: 0.0195  data: 0.0169  max mem: 13772
Epoch: [1]  [ 800/4571]  eta: 0:01:14    time: 0.0194  data: 0.0169  max mem: 13772
Epoch: [1]  [ 820/4571]  eta: 0:01:13    time: 0.0198  data: 0.0171  max mem: 13772
Epoch: [1]  [ 840/4571]  eta: 0:01:13    time: 0.0202  data: 0.0177  max mem: 13772
Epoch: [1]  [ 860/4571]  eta: 0:01:12    time: 0.0194  data: 0.0169  max mem: 13772
Epoch: [1]  [ 880/4571]  eta: 0:01:12    time: 0.0195  data: 0.0174  max mem: 13772
Epoch: [1]  [ 900/4571]  eta: 0:01:12    time: 0.0196  data: 0.0172  max mem: 13772
Epoch: [1]  [ 920/4571]  eta: 0:01:11    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [1]  [ 940/4571]  eta: 0:01:11    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [1]  [ 960/4571]  eta: 0:01:10    time: 0.0197  data: 0.0173  max mem: 13772
Epoch: [1]  [ 980/4571]  eta: 0:01:10    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [1]  [1000/4571]  eta: 0:01:10    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [1]  [1020/4571]  eta: 0:01:09    time: 0.0200  data: 0.0176  max mem: 13772
Epoch: [1]  [1040/4571]  eta: 0:01:09    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [1]  [1060/4571]  eta: 0:01:08    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [1]  [1080/4571]  eta: 0:01:08    time: 0.0199  data: 0.0180  max mem: 13772
Epoch: [1]  [1100/4571]  eta: 0:01:08    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [1]  [1120/4571]  eta: 0:01:07    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [1]  [1140/4571]  eta: 0:01:07    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [1]  [1160/4571]  eta: 0:01:06    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [1]  [1180/4571]  eta: 0:01:06    time: 0.0199  data: 0.0176  max mem: 13772
Epoch: [1]  [1200/4571]  eta: 0:01:06    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [1]  [1220/4571]  eta: 0:01:05    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [1]  [1240/4571]  eta: 0:01:05    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [1]  [1260/4571]  eta: 0:01:04    time: 0.0198  data: 0.0178  max mem: 13772
Epoch: [1]  [1280/4571]  eta: 0:01:04    time: 0.0200  data: 0.0182  max mem: 13772
Epoch: [1]  [1300/4571]  eta: 0:01:04    time: 0.0196  data: 0.0172  max mem: 13772
Epoch: [1]  [1320/4571]  eta: 0:01:03    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [1]  [1340/4571]  eta: 0:01:03    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [1]  [1360/4571]  eta: 0:01:03    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [1]  [1380/4571]  eta: 0:01:02    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [1]  [1400/4571]  eta: 0:01:02    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [1]  [1420/4571]  eta: 0:01:01    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [1]  [1440/4571]  eta: 0:01:01    time: 0.0197  data: 0.0173  max mem: 13772
Epoch: [1]  [1460/4571]  eta: 0:01:01    time: 0.0202  data: 0.0178  max mem: 13772
Epoch: [1]  [1480/4571]  eta: 0:01:00    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [1]  [1500/4571]  eta: 0:01:00    time: 0.0197  data: 0.0173  max mem: 13772
Epoch: [1]  [1520/4571]  eta: 0:00:59    time: 0.0194  data: 0.0175  max mem: 13772
Epoch: [1]  [1540/4571]  eta: 0:00:59    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [1]  [1560/4571]  eta: 0:00:59    time: 0.0229  data: 0.0176  max mem: 13772
Epoch: [1]  [1580/4571]  eta: 0:00:58    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [1]  [1600/4571]  eta: 0:00:58    time: 0.0196  data: 0.0175  max mem: 13772
Epoch: [1]  [1620/4571]  eta: 0:00:57    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [1]  [1640/4571]  eta: 0:00:57    time: 0.0196  data: 0.0177  max mem: 13772
Epoch: [1]  [1660/4571]  eta: 0:00:57    time: 0.0199  data: 0.0176  max mem: 13772
Epoch: [1]  [1680/4571]  eta: 0:00:56    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [1]  [1700/4571]  eta: 0:00:56    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [1]  [1720/4571]  eta: 0:00:56    time: 0.0198  data: 0.0179  max mem: 13772
Epoch: [1]  [1740/4571]  eta: 0:00:55    time: 0.0199  data: 0.0175  max mem: 13772
Epoch: [1]  [1760/4571]  eta: 0:00:55    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [1]  [1780/4571]  eta: 0:00:54    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [1]  [1800/4571]  eta: 0:00:54    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [1]  [1820/4571]  eta: 0:00:54    time: 0.0215  data: 0.0197  max mem: 13772
Epoch: [1]  [1840/4571]  eta: 0:00:53    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [1]  [1860/4571]  eta: 0:00:53    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [1]  [1880/4571]  eta: 0:00:52    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [1]  [1900/4571]  eta: 0:00:52    time: 0.0203  data: 0.0175  max mem: 13772
Epoch: [1]  [1920/4571]  eta: 0:00:52    time: 0.0196  data: 0.0172  max mem: 13772
Epoch: [1]  [1940/4571]  eta: 0:00:51    time: 0.0199  data: 0.0179  max mem: 13772
Epoch: [1]  [1960/4571]  eta: 0:00:51    time: 0.0196  data: 0.0172  max mem: 13772
Epoch: [1]  [1980/4571]  eta: 0:00:50    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [1]  [2000/4571]  eta: 0:00:50    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [1]  [2020/4571]  eta: 0:00:50    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [1]  [2040/4571]  eta: 0:00:49    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [1]  [2060/4571]  eta: 0:00:49    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [1]  [2080/4571]  eta: 0:00:48    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [1]  [2100/4571]  eta: 0:00:48    time: 0.0197  data: 0.0179  max mem: 13772
Epoch: [1]  [2120/4571]  eta: 0:00:48    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [1]  [2140/4571]  eta: 0:00:47    time: 0.0198  data: 0.0170  max mem: 13772
Epoch: [1]  [2160/4571]  eta: 0:00:47    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [1]  [2180/4571]  eta: 0:00:47    time: 0.0198  data: 0.0174  max mem: 13772
Epoch: [1]  [2200/4571]  eta: 0:00:46    time: 0.0204  data: 0.0180  max mem: 13772
Epoch: [1]  [2220/4571]  eta: 0:00:46    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [1]  [2240/4571]  eta: 0:00:45    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [1]  [2260/4571]  eta: 0:00:45    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [1]  [2280/4571]  eta: 0:00:45    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [1]  [2300/4571]  eta: 0:00:44    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [1]  [2320/4571]  eta: 0:00:44    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [1]  [2340/4571]  eta: 0:00:43    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [1]  [2360/4571]  eta: 0:00:43    time: 0.0199  data: 0.0180  max mem: 13772
Epoch: [1]  [2380/4571]  eta: 0:00:43    time: 0.0196  data: 0.0177  max mem: 13772
Epoch: [1]  [2400/4571]  eta: 0:00:42    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [1]  [2420/4571]  eta: 0:00:42    time: 0.0194  data: 0.0175  max mem: 13772
Epoch: [1]  [2440/4571]  eta: 0:00:41    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [1]  [2460/4571]  eta: 0:00:41    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [1]  [2480/4571]  eta: 0:00:41    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [1]  [2500/4571]  eta: 0:00:40    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [1]  [2520/4571]  eta: 0:00:40    time: 0.0196  data: 0.0177  max mem: 13772
Epoch: [1]  [2540/4571]  eta: 0:00:39    time: 0.0194  data: 0.0168  max mem: 13772
Epoch: [1]  [2560/4571]  eta: 0:00:39    time: 0.0195  data: 0.0175  max mem: 13772
Epoch: [1]  [2580/4571]  eta: 0:00:39    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [1]  [2600/4571]  eta: 0:00:38    time: 0.0199  data: 0.0173  max mem: 13772
Epoch: [1]  [2620/4571]  eta: 0:00:38    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [1]  [2640/4571]  eta: 0:00:37    time: 0.0198  data: 0.0174  max mem: 13772
Epoch: [1]  [2660/4571]  eta: 0:00:37    time: 0.0196  data: 0.0172  max mem: 13772
Epoch: [1]  [2680/4571]  eta: 0:00:37    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [1]  [2700/4571]  eta: 0:00:36    time: 0.0202  data: 0.0183  max mem: 13772
Epoch: [1]  [2720/4571]  eta: 0:00:36    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [1]  [2740/4571]  eta: 0:00:35    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [1]  [2760/4571]  eta: 0:00:35    time: 0.0197  data: 0.0178  max mem: 13772
Epoch: [1]  [2780/4571]  eta: 0:00:35    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [1]  [2800/4571]  eta: 0:00:34    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [1]  [2820/4571]  eta: 0:00:34    time: 0.0202  data: 0.0179  max mem: 13772
Epoch: [1]  [2840/4571]  eta: 0:00:34    time: 0.0195  data: 0.0169  max mem: 13772
Epoch: [1]  [2860/4571]  eta: 0:00:33    time: 0.0201  data: 0.0175  max mem: 13772
Epoch: [1]  [2880/4571]  eta: 0:00:33    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [1]  [2900/4571]  eta: 0:00:32    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [1]  [2920/4571]  eta: 0:00:32    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [1]  [2940/4571]  eta: 0:00:32    time: 0.0198  data: 0.0179  max mem: 13772
Epoch: [1]  [2960/4571]  eta: 0:00:31    time: 0.0198  data: 0.0179  max mem: 13772
Epoch: [1]  [2980/4571]  eta: 0:00:31    time: 0.0196  data: 0.0178  max mem: 13772
Epoch: [1]  [3000/4571]  eta: 0:00:30    time: 0.0195  data: 0.0169  max mem: 13772
Epoch: [1]  [3020/4571]  eta: 0:00:30    time: 0.0196  data: 0.0178  max mem: 13772
Epoch: [1]  [3040/4571]  eta: 0:00:30    time: 0.0204  data: 0.0185  max mem: 13772
Epoch: [1]  [3060/4571]  eta: 0:00:29    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [1]  [3080/4571]  eta: 0:00:29    time: 0.0194  data: 0.0168  max mem: 13772
Epoch: [1]  [3100/4571]  eta: 0:00:28    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [1]  [3120/4571]  eta: 0:00:28    time: 0.0201  data: 0.0182  max mem: 13772
Epoch: [1]  [3140/4571]  eta: 0:00:28    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [1]  [3160/4571]  eta: 0:00:27    time: 0.0197  data: 0.0178  max mem: 13772
Epoch: [1]  [3180/4571]  eta: 0:00:27    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [1]  [3200/4571]  eta: 0:00:26    time: 0.0199  data: 0.0175  max mem: 13772
Epoch: [1]  [3220/4571]  eta: 0:00:26    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [1]  [3240/4571]  eta: 0:00:26    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [1]  [3260/4571]  eta: 0:00:25    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [1]  [3280/4571]  eta: 0:00:25    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [1]  [3300/4571]  eta: 0:00:24    time: 0.0200  data: 0.0172  max mem: 13772
Epoch: [1]  [3320/4571]  eta: 0:00:24    time: 0.0198  data: 0.0179  max mem: 13772
Epoch: [1]  [3340/4571]  eta: 0:00:24    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [1]  [3360/4571]  eta: 0:00:23    time: 0.0199  data: 0.0175  max mem: 13772
Epoch: [1]  [3380/4571]  eta: 0:00:23    time: 0.0200  data: 0.0175  max mem: 13772
Epoch: [1]  [3400/4571]  eta: 0:00:23    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [1]  [3420/4571]  eta: 0:00:22    time: 0.0200  data: 0.0176  max mem: 13772
Epoch: [1]  [3440/4571]  eta: 0:00:22    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [1]  [3460/4571]  eta: 0:00:21    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [1]  [3480/4571]  eta: 0:00:21    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [1]  [3500/4571]  eta: 0:00:21    time: 0.0195  data: 0.0170  max mem: 13772
Epoch: [1]  [3520/4571]  eta: 0:00:20    time: 0.0199  data: 0.0178  max mem: 13772
Epoch: [1]  [3540/4571]  eta: 0:00:20    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [1]  [3560/4571]  eta: 0:00:19    time: 0.0199  data: 0.0180  max mem: 13772
Epoch: [1]  [3580/4571]  eta: 0:00:19    time: 0.0197  data: 0.0173  max mem: 13772
Epoch: [1]  [3600/4571]  eta: 0:00:19    time: 0.0198  data: 0.0174  max mem: 13772
Epoch: [1]  [3620/4571]  eta: 0:00:18    time: 0.0196  data: 0.0175  max mem: 13772
Epoch: [1]  [3640/4571]  eta: 0:00:18    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [1]  [3660/4571]  eta: 0:00:17    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [1]  [3680/4571]  eta: 0:00:17    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [1]  [3700/4571]  eta: 0:00:17    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [1]  [3720/4571]  eta: 0:00:16    time: 0.0197  data: 0.0178  max mem: 13772
Epoch: [1]  [3740/4571]  eta: 0:00:16    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [1]  [3760/4571]  eta: 0:00:15    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [1]  [3780/4571]  eta: 0:00:15    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [1]  [3800/4571]  eta: 0:00:15    time: 0.0196  data: 0.0172  max mem: 13772
Epoch: [1]  [3820/4571]  eta: 0:00:14    time: 0.0198  data: 0.0174  max mem: 13772
Epoch: [1]  [3840/4571]  eta: 0:00:14    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [1]  [3860/4571]  eta: 0:00:13    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [1]  [3880/4571]  eta: 0:00:13    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [1]  [3900/4571]  eta: 0:00:13    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [1]  [3920/4571]  eta: 0:00:12    time: 0.0199  data: 0.0180  max mem: 13772
Epoch: [1]  [3940/4571]  eta: 0:00:12    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [1]  [3960/4571]  eta: 0:00:11    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [1]  [3980/4571]  eta: 0:00:11    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [1]  [4000/4571]  eta: 0:00:11    time: 0.0197  data: 0.0173  max mem: 13772
Epoch: [1]  [4020/4571]  eta: 0:00:10    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [1]  [4040/4571]  eta: 0:00:10    time: 0.0197  data: 0.0173  max mem: 13772
Epoch: [1]  [4060/4571]  eta: 0:00:10    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [1]  [4080/4571]  eta: 0:00:09    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [1]  [4100/4571]  eta: 0:00:09    time: 0.0202  data: 0.0178  max mem: 13772
Epoch: [1]  [4120/4571]  eta: 0:00:08    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [1]  [4140/4571]  eta: 0:00:08    time: 0.0200  data: 0.0175  max mem: 13772
Epoch: [1]  [4160/4571]  eta: 0:00:08    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [1]  [4180/4571]  eta: 0:00:07    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [1]  [4200/4571]  eta: 0:00:07    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [1]  [4220/4571]  eta: 0:00:06    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [1]  [4240/4571]  eta: 0:00:06    time: 0.0204  data: 0.0185  max mem: 13772
Epoch: [1]  [4260/4571]  eta: 0:00:06    time: 0.0199  data: 0.0181  max mem: 13772
Epoch: [1]  [4280/4571]  eta: 0:00:05    time: 0.0200  data: 0.0176  max mem: 13772
Epoch: [1]  [4300/4571]  eta: 0:00:05    time: 0.0198  data: 0.0178  max mem: 13772
Epoch: [1]  [4320/4571]  eta: 0:00:04    time: 0.0194  data: 0.0175  max mem: 13772
Epoch: [1]  [4340/4571]  eta: 0:00:04    time: 0.0195  data: 0.0177  max mem: 13772
Epoch: [1]  [4360/4571]  eta: 0:00:04    time: 0.0194  data: 0.0175  max mem: 13772
Epoch: [1]  [4380/4571]  eta: 0:00:03    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [1]  [4400/4571]  eta: 0:00:03    time: 0.0197  data: 0.0178  max mem: 13772
Epoch: [1]  [4420/4571]  eta: 0:00:02    time: 0.0196  data: 0.0172  max mem: 13772
Epoch: [1]  [4440/4571]  eta: 0:00:02    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [1]  [4460/4571]  eta: 0:00:02    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [1]  [4480/4571]  eta: 0:00:01    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [1]  [4500/4571]  eta: 0:00:01    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [1]  [4520/4571]  eta: 0:00:01    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [1]  [4540/4571]  eta: 0:00:00    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [1]  [4560/4571]  eta: 0:00:00    time: 0.0199  data: 0.0172  max mem: 13772
Epoch: [1]  [4570/4571]  eta: 0:00:00    time: 0.0206  data: 0.0179  max mem: 13772
Epoch: [1] Total time: 0:01:29 (0.0197 s / it)
:::MLLOG {"namespace": "", "time_ms": 1715261802976, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1715261802976, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 203.49217144795156}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 2}}
:::MLLOG {"namespace": "", "time_ms": 1715261802976, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 344, "epoch_num": 2}}
Test:  [ 0/13]  eta: 0:00:03  model_time: 0.2438 (0.2438)  evaluator_time: 0.0027 (0.0027)  time: 0.2475  data: 0.0009  max mem: 13772
Test:  [12/13]  eta: 0:00:00  model_time: 0.2353 (0.2205)  evaluator_time: 0.0030 (0.0029)  time: 0.2242  data: 0.0007  max mem: 13772
Test: Total time: 0:00:02 (0.2243 s / it)
Averaged stats: model_time: 0.2353 (0.2235)  evaluator_time: 0.0030 (0.0029)
:::MLLOG {"namespace": "", "time_ms": 1715261806232, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 2}}
Epoch: [2]  [   0/4572]  eta: 0:01:31    time: 0.0200  data: 0.0006  max mem: 13772
Epoch: [2]  [  20/4572]  eta: 0:01:39    time: 0.0220  data: 0.0201  max mem: 13772
Epoch: [2]  [  40/4572]  eta: 0:01:33    time: 0.0194  data: 0.0169  max mem: 13772
Epoch: [2]  [  60/4572]  eta: 0:01:31    time: 0.0194  data: 0.0169  max mem: 13772
Epoch: [2]  [  80/4572]  eta: 0:01:30    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [2]  [ 100/4572]  eta: 0:01:29    time: 0.0194  data: 0.0174  max mem: 13772
Epoch: [2]  [ 120/4572]  eta: 0:01:28    time: 0.0195  data: 0.0175  max mem: 13772
Epoch: [2]  [ 140/4572]  eta: 0:01:28    time: 0.0200  data: 0.0174  max mem: 13772
Epoch: [2]  [ 160/4572]  eta: 0:01:27    time: 0.0194  data: 0.0168  max mem: 13772
Epoch: [2]  [ 180/4572]  eta: 0:01:26    time: 0.0195  data: 0.0168  max mem: 13772
Epoch: [2]  [ 200/4572]  eta: 0:01:26    time: 0.0195  data: 0.0166  max mem: 13772
Epoch: [2]  [ 220/4572]  eta: 0:01:25    time: 0.0194  data: 0.0170  max mem: 13772
:::MLLOG {"namespace": "", "time_ms": 1715261810887, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.28676436077499207, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 437, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1715261810888, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 438, "epoch_num": 2}}
Epoch: [2]  [ 240/4572]  eta: 0:01:25    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [2]  [ 260/4572]  eta: 0:01:24    time: 0.0195  data: 0.0170  max mem: 13772
Epoch: [2]  [ 280/4572]  eta: 0:01:24    time: 0.0201  data: 0.0170  max mem: 13772
Epoch: [2]  [ 300/4572]  eta: 0:01:24    time: 0.0196  data: 0.0171  max mem: 13772
Epoch: [2]  [ 320/4572]  eta: 0:01:23    time: 0.0198  data: 0.0179  max mem: 13772
Epoch: [2]  [ 340/4572]  eta: 0:01:23    time: 0.0196  data: 0.0172  max mem: 13772
Epoch: [2]  [ 360/4572]  eta: 0:01:22    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [2]  [ 380/4572]  eta: 0:01:22    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [2]  [ 400/4572]  eta: 0:01:22    time: 0.0197  data: 0.0178  max mem: 13772
Epoch: [2]  [ 420/4572]  eta: 0:01:21    time: 0.0195  data: 0.0170  max mem: 13772
Epoch: [2]  [ 440/4572]  eta: 0:01:21    time: 0.0217  data: 0.0193  max mem: 13772
Epoch: [2]  [ 460/4572]  eta: 0:01:21    time: 0.0198  data: 0.0174  max mem: 13772
Epoch: [2]  [ 480/4572]  eta: 0:01:20    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [2]  [ 500/4572]  eta: 0:01:20    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [2]  [ 520/4572]  eta: 0:01:19    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [2]  [ 540/4572]  eta: 0:01:19    time: 0.0204  data: 0.0185  max mem: 13772
Epoch: [2]  [ 560/4572]  eta: 0:01:19    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [2]  [ 580/4572]  eta: 0:01:18    time: 0.0199  data: 0.0174  max mem: 13772
Epoch: [2]  [ 600/4572]  eta: 0:01:18    time: 0.0195  data: 0.0174  max mem: 13772
Epoch: [2]  [ 620/4572]  eta: 0:01:18    time: 0.0195  data: 0.0175  max mem: 13772
Epoch: [2]  [ 640/4572]  eta: 0:01:17    time: 0.0195  data: 0.0174  max mem: 13772
Epoch: [2]  [ 660/4572]  eta: 0:01:17    time: 0.0196  data: 0.0171  max mem: 13772
Epoch: [2]  [ 680/4572]  eta: 0:01:16    time: 0.0195  data: 0.0170  max mem: 13772
Epoch: [2]  [ 700/4572]  eta: 0:01:16    time: 0.0196  data: 0.0172  max mem: 13772
Epoch: [2]  [ 720/4572]  eta: 0:01:15    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [2]  [ 740/4572]  eta: 0:01:15    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [2]  [ 760/4572]  eta: 0:01:15    time: 0.0200  data: 0.0176  max mem: 13772
Epoch: [2]  [ 780/4572]  eta: 0:01:14    time: 0.0197  data: 0.0173  max mem: 13772
Epoch: [2]  [ 800/4572]  eta: 0:01:14    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [2]  [ 820/4572]  eta: 0:01:13    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [2]  [ 840/4572]  eta: 0:01:13    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [2]  [ 860/4572]  eta: 0:01:13    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [2]  [ 880/4572]  eta: 0:01:12    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [2]  [ 900/4572]  eta: 0:01:12    time: 0.0202  data: 0.0178  max mem: 13772
Epoch: [2]  [ 920/4572]  eta: 0:01:11    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [2]  [ 940/4572]  eta: 0:01:11    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [2]  [ 960/4572]  eta: 0:01:11    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [2]  [ 980/4572]  eta: 0:01:10    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [2]  [1000/4572]  eta: 0:01:10    time: 0.0204  data: 0.0177  max mem: 13772
Epoch: [2]  [1020/4572]  eta: 0:01:09    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [2]  [1040/4572]  eta: 0:01:09    time: 0.0201  data: 0.0182  max mem: 13772
Epoch: [2]  [1060/4572]  eta: 0:01:09    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [2]  [1080/4572]  eta: 0:01:08    time: 0.0200  data: 0.0176  max mem: 13772
Epoch: [2]  [1100/4572]  eta: 0:01:08    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [2]  [1120/4572]  eta: 0:01:07    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [2]  [1140/4572]  eta: 0:01:07    time: 0.0198  data: 0.0174  max mem: 13772
Epoch: [2]  [1160/4572]  eta: 0:01:07    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [2]  [1180/4572]  eta: 0:01:06    time: 0.0196  data: 0.0172  max mem: 13772
Epoch: [2]  [1200/4572]  eta: 0:01:06    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [2]  [1220/4572]  eta: 0:01:05    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [2]  [1240/4572]  eta: 0:01:05    time: 0.0220  data: 0.0197  max mem: 13772
Epoch: [2]  [1260/4572]  eta: 0:01:05    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [2]  [1280/4572]  eta: 0:01:04    time: 0.0195  data: 0.0177  max mem: 13772
Epoch: [2]  [1300/4572]  eta: 0:01:04    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [2]  [1320/4572]  eta: 0:01:04    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [2]  [1340/4572]  eta: 0:01:03    time: 0.0201  data: 0.0171  max mem: 13772
Epoch: [2]  [1360/4572]  eta: 0:01:03    time: 0.0194  data: 0.0172  max mem: 13772
Epoch: [2]  [1380/4572]  eta: 0:01:02    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [2]  [1400/4572]  eta: 0:01:02    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [2]  [1420/4572]  eta: 0:01:02    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [2]  [1440/4572]  eta: 0:01:01    time: 0.0196  data: 0.0177  max mem: 13772
Epoch: [2]  [1460/4572]  eta: 0:01:01    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [2]  [1480/4572]  eta: 0:01:00    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [2]  [1500/4572]  eta: 0:01:00    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [2]  [1520/4572]  eta: 0:01:00    time: 0.0202  data: 0.0179  max mem: 13772
Epoch: [2]  [1540/4572]  eta: 0:00:59    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [2]  [1560/4572]  eta: 0:00:59    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [2]  [1580/4572]  eta: 0:00:58    time: 0.0198  data: 0.0174  max mem: 13772
Epoch: [2]  [1600/4572]  eta: 0:00:58    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [2]  [1620/4572]  eta: 0:00:58    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [2]  [1640/4572]  eta: 0:00:57    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [2]  [1660/4572]  eta: 0:00:57    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [2]  [1680/4572]  eta: 0:00:56    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [2]  [1700/4572]  eta: 0:00:56    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [2]  [1720/4572]  eta: 0:00:56    time: 0.0197  data: 0.0174  max mem: 13772
Epoch: [2]  [1740/4572]  eta: 0:00:55    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [2]  [1760/4572]  eta: 0:00:55    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [2]  [1780/4572]  eta: 0:00:54    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [2]  [1800/4572]  eta: 0:00:54    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [2]  [1820/4572]  eta: 0:00:54    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [2]  [1840/4572]  eta: 0:00:53    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [2]  [1860/4572]  eta: 0:00:53    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [2]  [1880/4572]  eta: 0:00:52    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [2]  [1900/4572]  eta: 0:00:52    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [2]  [1920/4572]  eta: 0:00:52    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [2]  [1940/4572]  eta: 0:00:51    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [2]  [1960/4572]  eta: 0:00:51    time: 0.0197  data: 0.0174  max mem: 13772
Epoch: [2]  [1980/4572]  eta: 0:00:50    time: 0.0197  data: 0.0174  max mem: 13772
Epoch: [2]  [2000/4572]  eta: 0:00:50    time: 0.0195  data: 0.0177  max mem: 13772
Epoch: [2]  [2020/4572]  eta: 0:00:50    time: 0.0196  data: 0.0178  max mem: 13772
Epoch: [2]  [2040/4572]  eta: 0:00:49    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [2]  [2060/4572]  eta: 0:00:49    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [2]  [2080/4572]  eta: 0:00:48    time: 0.0199  data: 0.0176  max mem: 13772
Epoch: [2]  [2100/4572]  eta: 0:00:48    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [2]  [2120/4572]  eta: 0:00:48    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [2]  [2140/4572]  eta: 0:00:47    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [2]  [2160/4572]  eta: 0:00:47    time: 0.0196  data: 0.0172  max mem: 13772
Epoch: [2]  [2180/4572]  eta: 0:00:46    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [2]  [2200/4572]  eta: 0:00:46    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [2]  [2220/4572]  eta: 0:00:46    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [2]  [2240/4572]  eta: 0:00:45    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [2]  [2260/4572]  eta: 0:00:45    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [2]  [2280/4572]  eta: 0:00:44    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [2]  [2300/4572]  eta: 0:00:44    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [2]  [2320/4572]  eta: 0:00:44    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [2]  [2340/4572]  eta: 0:00:43    time: 0.0198  data: 0.0174  max mem: 13772
Epoch: [2]  [2360/4572]  eta: 0:00:43    time: 0.0200  data: 0.0177  max mem: 13772
Epoch: [2]  [2380/4572]  eta: 0:00:43    time: 0.0202  data: 0.0179  max mem: 13772
Epoch: [2]  [2400/4572]  eta: 0:00:42    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [2]  [2420/4572]  eta: 0:00:42    time: 0.0199  data: 0.0175  max mem: 13772
Epoch: [2]  [2440/4572]  eta: 0:00:41    time: 0.0199  data: 0.0175  max mem: 13772
Epoch: [2]  [2460/4572]  eta: 0:00:41    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [2]  [2480/4572]  eta: 0:00:41    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [2]  [2500/4572]  eta: 0:00:40    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [2]  [2520/4572]  eta: 0:00:40    time: 0.0197  data: 0.0179  max mem: 13772
Epoch: [2]  [2540/4572]  eta: 0:00:39    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [2]  [2560/4572]  eta: 0:00:39    time: 0.0200  data: 0.0177  max mem: 13772
Epoch: [2]  [2580/4572]  eta: 0:00:39    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [2]  [2600/4572]  eta: 0:00:38    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [2]  [2620/4572]  eta: 0:00:38    time: 0.0202  data: 0.0184  max mem: 13772
Epoch: [2]  [2640/4572]  eta: 0:00:37    time: 0.0198  data: 0.0175  max mem: 13772
Epoch: [2]  [2660/4572]  eta: 0:00:37    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [2]  [2680/4572]  eta: 0:00:37    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [2]  [2700/4572]  eta: 0:00:36    time: 0.0221  data: 0.0198  max mem: 13772
Epoch: [2]  [2720/4572]  eta: 0:00:36    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [2]  [2740/4572]  eta: 0:00:35    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [2]  [2760/4572]  eta: 0:00:35    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [2]  [2780/4572]  eta: 0:00:35    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [2]  [2800/4572]  eta: 0:00:34    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [2]  [2820/4572]  eta: 0:00:34    time: 0.0199  data: 0.0176  max mem: 13772
Epoch: [2]  [2840/4572]  eta: 0:00:34    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [2]  [2860/4572]  eta: 0:00:33    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [2]  [2880/4572]  eta: 0:00:33    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [2]  [2900/4572]  eta: 0:00:32    time: 0.0197  data: 0.0174  max mem: 13772
Epoch: [2]  [2920/4572]  eta: 0:00:32    time: 0.0198  data: 0.0179  max mem: 13772
Epoch: [2]  [2940/4572]  eta: 0:00:32    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [2]  [2960/4572]  eta: 0:00:31    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [2]  [2980/4572]  eta: 0:00:31    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [2]  [3000/4572]  eta: 0:00:30    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [2]  [3020/4572]  eta: 0:00:30    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [2]  [3040/4572]  eta: 0:00:30    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [2]  [3060/4572]  eta: 0:00:29    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [2]  [3080/4572]  eta: 0:00:29    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [2]  [3100/4572]  eta: 0:00:28    time: 0.0195  data: 0.0177  max mem: 13772
Epoch: [2]  [3120/4572]  eta: 0:00:28    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [2]  [3140/4572]  eta: 0:00:28    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [2]  [3160/4572]  eta: 0:00:27    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [2]  [3180/4572]  eta: 0:00:27    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [2]  [3200/4572]  eta: 0:00:26    time: 0.0202  data: 0.0178  max mem: 13772
Epoch: [2]  [3220/4572]  eta: 0:00:26    time: 0.0203  data: 0.0179  max mem: 13772
Epoch: [2]  [3240/4572]  eta: 0:00:26    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [2]  [3260/4572]  eta: 0:00:25    time: 0.0222  data: 0.0199  max mem: 13772
Epoch: [2]  [3280/4572]  eta: 0:00:25    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [2]  [3300/4572]  eta: 0:00:24    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [2]  [3320/4572]  eta: 0:00:24    time: 0.0198  data: 0.0175  max mem: 13772
Epoch: [2]  [3340/4572]  eta: 0:00:24    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [2]  [3360/4572]  eta: 0:00:23    time: 0.0202  data: 0.0183  max mem: 13772
Epoch: [2]  [3380/4572]  eta: 0:00:23    time: 0.0198  data: 0.0174  max mem: 13772
Epoch: [2]  [3400/4572]  eta: 0:00:23    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [2]  [3420/4572]  eta: 0:00:22    time: 0.0202  data: 0.0179  max mem: 13772
Epoch: [2]  [3440/4572]  eta: 0:00:22    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [2]  [3460/4572]  eta: 0:00:21    time: 0.0195  data: 0.0170  max mem: 13772
Epoch: [2]  [3480/4572]  eta: 0:00:21    time: 0.0222  data: 0.0198  max mem: 13772
Epoch: [2]  [3500/4572]  eta: 0:00:21    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [2]  [3520/4572]  eta: 0:00:20    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [2]  [3540/4572]  eta: 0:00:20    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [2]  [3560/4572]  eta: 0:00:19    time: 0.0197  data: 0.0174  max mem: 13772
Epoch: [2]  [3580/4572]  eta: 0:00:19    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [2]  [3600/4572]  eta: 0:00:19    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [2]  [3620/4572]  eta: 0:00:18    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [2]  [3640/4572]  eta: 0:00:18    time: 0.0222  data: 0.0198  max mem: 13772
Epoch: [2]  [3660/4572]  eta: 0:00:17    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [2]  [3680/4572]  eta: 0:00:17    time: 0.0197  data: 0.0173  max mem: 13772
Epoch: [2]  [3700/4572]  eta: 0:00:17    time: 0.0198  data: 0.0174  max mem: 13772
Epoch: [2]  [3720/4572]  eta: 0:00:16    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [2]  [3740/4572]  eta: 0:00:16    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [2]  [3760/4572]  eta: 0:00:15    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [2]  [3780/4572]  eta: 0:00:15    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [2]  [3800/4572]  eta: 0:00:15    time: 0.0198  data: 0.0174  max mem: 13772
Epoch: [2]  [3820/4572]  eta: 0:00:14    time: 0.0197  data: 0.0173  max mem: 13772
Epoch: [2]  [3840/4572]  eta: 0:00:14    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [2]  [3860/4572]  eta: 0:00:14    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [2]  [3880/4572]  eta: 0:00:13    time: 0.0195  data: 0.0177  max mem: 13772
Epoch: [2]  [3900/4572]  eta: 0:00:13    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [2]  [3920/4572]  eta: 0:00:12    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [2]  [3940/4572]  eta: 0:00:12    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [2]  [3960/4572]  eta: 0:00:12    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [2]  [3980/4572]  eta: 0:00:11    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [2]  [4000/4572]  eta: 0:00:11    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [2]  [4020/4572]  eta: 0:00:10    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [2]  [4040/4572]  eta: 0:00:10    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [2]  [4060/4572]  eta: 0:00:10    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [2]  [4080/4572]  eta: 0:00:09    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [2]  [4100/4572]  eta: 0:00:09    time: 0.0198  data: 0.0180  max mem: 13772
Epoch: [2]  [4120/4572]  eta: 0:00:08    time: 0.0199  data: 0.0175  max mem: 13772
Epoch: [2]  [4140/4572]  eta: 0:00:08    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [2]  [4160/4572]  eta: 0:00:08    time: 0.0197  data: 0.0178  max mem: 13772
Epoch: [2]  [4180/4572]  eta: 0:00:07    time: 0.0199  data: 0.0173  max mem: 13772
Epoch: [2]  [4200/4572]  eta: 0:00:07    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [2]  [4220/4572]  eta: 0:00:06    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [2]  [4240/4572]  eta: 0:00:06    time: 0.0194  data: 0.0175  max mem: 13772
Epoch: [2]  [4260/4572]  eta: 0:00:06    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [2]  [4280/4572]  eta: 0:00:05    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [2]  [4300/4572]  eta: 0:00:05    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [2]  [4320/4572]  eta: 0:00:04    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [2]  [4340/4572]  eta: 0:00:04    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [2]  [4360/4572]  eta: 0:00:04    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [2]  [4380/4572]  eta: 0:00:03    time: 0.0198  data: 0.0179  max mem: 13772
Epoch: [2]  [4400/4572]  eta: 0:00:03    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [2]  [4420/4572]  eta: 0:00:02    time: 0.0199  data: 0.0180  max mem: 13772
Epoch: [2]  [4440/4572]  eta: 0:00:02    time: 0.0194  data: 0.0175  max mem: 13772
Epoch: [2]  [4460/4572]  eta: 0:00:02    time: 0.0198  data: 0.0175  max mem: 13772
Epoch: [2]  [4480/4572]  eta: 0:00:01    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [2]  [4500/4572]  eta: 0:00:01    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [2]  [4520/4572]  eta: 0:00:01    time: 0.0196  data: 0.0177  max mem: 13772
Epoch: [2]  [4540/4572]  eta: 0:00:00    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [2]  [4560/4572]  eta: 0:00:00    time: 0.0196  data: 0.0177  max mem: 13772
Epoch: [2]  [4571/4572]  eta: 0:00:00    time: 0.0196  data: 0.0177  max mem: 13772
Epoch: [2] Total time: 0:01:29 (0.0197 s / it)
:::MLLOG {"namespace": "", "time_ms": 1715261896153, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1715261896154, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 203.44226122829198}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 3}}
:::MLLOG {"namespace": "", "time_ms": 1715261896154, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 344, "epoch_num": 3}}
Test:  [ 0/13]  eta: 0:00:03  model_time: 0.2311 (0.2311)  evaluator_time: 0.0026 (0.0026)  time: 0.2346  data: 0.0008  max mem: 13772
Test:  [12/13]  eta: 0:00:00  model_time: 0.2313 (0.2164)  evaluator_time: 0.0030 (0.0028)  time: 0.2201  data: 0.0007  max mem: 13772
Test: Total time: 0:00:02 (0.2201 s / it)
Averaged stats: model_time: 0.2313 (0.2186)  evaluator_time: 0.0030 (0.0059)
:::MLLOG {"namespace": "", "time_ms": 1715261899390, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 3}}
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
Epoch: [3]  [   0/4571]  eta: 0:01:31    time: 0.0200  data: 0.0007  max mem: 13772
Epoch: [3]  [  20/4571]  eta: 0:01:42    time: 0.0227  data: 0.0203  max mem: 13772
Epoch: [3]  [  40/4571]  eta: 0:01:35    time: 0.0198  data: 0.0178  max mem: 13772
Epoch: [3]  [  60/4571]  eta: 0:01:32    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [3]  [  80/4571]  eta: 0:01:31    time: 0.0199  data: 0.0180  max mem: 13772
Epoch: [3]  [ 100/4571]  eta: 0:01:31    time: 0.0204  data: 0.0186  max mem: 13772
Epoch: [3]  [ 120/4571]  eta: 0:01:30    time: 0.0195  data: 0.0177  max mem: 13772
Epoch: [3]  [ 140/4571]  eta: 0:01:29    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [3]  [ 160/4571]  eta: 0:01:28    time: 0.0198  data: 0.0172  max mem: 13772
Epoch: [3]  [ 180/4571]  eta: 0:01:27    time: 0.0195  data: 0.0174  max mem: 13772
Epoch: [3]  [ 200/4571]  eta: 0:01:27    time: 0.0194  data: 0.0173  max mem: 13772
Epoch: [3]  [ 220/4571]  eta: 0:01:26    time: 0.0194  data: 0.0169  max mem: 13772
:::MLLOG {"namespace": "", "time_ms": 1715261904136, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.32747675674837734, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 437, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1715261904137, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 438, "epoch_num": 3}}
Epoch: [3]  [ 240/4571]  eta: 0:01:26    time: 0.0194  data: 0.0169  max mem: 13772
Epoch: [3]  [ 260/4571]  eta: 0:01:25    time: 0.0194  data: 0.0169  max mem: 13772
Epoch: [3]  [ 280/4571]  eta: 0:01:25    time: 0.0194  data: 0.0169  max mem: 13772
Epoch: [3]  [ 300/4571]  eta: 0:01:25    time: 0.0222  data: 0.0202  max mem: 13772
Epoch: [3]  [ 320/4571]  eta: 0:01:24    time: 0.0194  data: 0.0174  max mem: 13772
Epoch: [3]  [ 340/4571]  eta: 0:01:24    time: 0.0194  data: 0.0169  max mem: 13772
Epoch: [3]  [ 360/4571]  eta: 0:01:24    time: 0.0227  data: 0.0202  max mem: 13772
Epoch: [3]  [ 380/4571]  eta: 0:01:23    time: 0.0196  data: 0.0172  max mem: 13772
Epoch: [3]  [ 400/4571]  eta: 0:01:23    time: 0.0194  data: 0.0169  max mem: 13772
Epoch: [3]  [ 420/4571]  eta: 0:01:23    time: 0.0202  data: 0.0183  max mem: 13772
Epoch: [3]  [ 440/4571]  eta: 0:01:22    time: 0.0201  data: 0.0177  max mem: 13772
Epoch: [3]  [ 460/4571]  eta: 0:01:22    time: 0.0196  data: 0.0177  max mem: 13772
Epoch: [3]  [ 480/4571]  eta: 0:01:21    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [3]  [ 500/4571]  eta: 0:01:21    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [3]  [ 520/4571]  eta: 0:01:20    time: 0.0198  data: 0.0172  max mem: 13772
Epoch: [3]  [ 540/4571]  eta: 0:01:20    time: 0.0203  data: 0.0179  max mem: 13772
Epoch: [3]  [ 560/4571]  eta: 0:01:20    time: 0.0216  data: 0.0193  max mem: 13772
Epoch: [3]  [ 580/4571]  eta: 0:01:19    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [3]  [ 600/4571]  eta: 0:01:19    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [3]  [ 620/4571]  eta: 0:01:18    time: 0.0197  data: 0.0173  max mem: 13772
Epoch: [3]  [ 640/4571]  eta: 0:01:18    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [3]  [ 660/4571]  eta: 0:01:18    time: 0.0202  data: 0.0179  max mem: 13772
Epoch: [3]  [ 680/4571]  eta: 0:01:17    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [3]  [ 700/4571]  eta: 0:01:17    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [3]  [ 720/4571]  eta: 0:01:16    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [3]  [ 740/4571]  eta: 0:01:16    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [3]  [ 760/4571]  eta: 0:01:15    time: 0.0199  data: 0.0175  max mem: 13772
Epoch: [3]  [ 780/4571]  eta: 0:01:15    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [3]  [ 800/4571]  eta: 0:01:15    time: 0.0198  data: 0.0174  max mem: 13772
Epoch: [3]  [ 820/4571]  eta: 0:01:14    time: 0.0195  data: 0.0170  max mem: 13772
Epoch: [3]  [ 840/4571]  eta: 0:01:14    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [3]  [ 860/4571]  eta: 0:01:13    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [3]  [ 880/4571]  eta: 0:01:13    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [3]  [ 900/4571]  eta: 0:01:12    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [3]  [ 920/4571]  eta: 0:01:12    time: 0.0194  data: 0.0175  max mem: 13772
Epoch: [3]  [ 940/4571]  eta: 0:01:12    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [3]  [ 960/4571]  eta: 0:01:11    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [3]  [ 980/4571]  eta: 0:01:11    time: 0.0196  data: 0.0172  max mem: 13772
Epoch: [3]  [1000/4571]  eta: 0:01:10    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [3]  [1020/4571]  eta: 0:01:10    time: 0.0196  data: 0.0170  max mem: 13772
Epoch: [3]  [1040/4571]  eta: 0:01:10    time: 0.0217  data: 0.0193  max mem: 13772
Epoch: [3]  [1060/4571]  eta: 0:01:09    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [3]  [1080/4571]  eta: 0:01:09    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [3]  [1100/4571]  eta: 0:01:08    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [3]  [1120/4571]  eta: 0:01:08    time: 0.0218  data: 0.0200  max mem: 13772
Epoch: [3]  [1140/4571]  eta: 0:01:08    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [3]  [1160/4571]  eta: 0:01:07    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [3]  [1180/4571]  eta: 0:01:07    time: 0.0194  data: 0.0172  max mem: 13772
Epoch: [3]  [1200/4571]  eta: 0:01:06    time: 0.0197  data: 0.0179  max mem: 13772
Epoch: [3]  [1220/4571]  eta: 0:01:06    time: 0.0221  data: 0.0198  max mem: 13772
Epoch: [3]  [1240/4571]  eta: 0:01:06    time: 0.0195  data: 0.0170  max mem: 13772
Epoch: [3]  [1260/4571]  eta: 0:01:05    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [3]  [1280/4571]  eta: 0:01:05    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [3]  [1300/4571]  eta: 0:01:04    time: 0.0198  data: 0.0180  max mem: 13772
Epoch: [3]  [1320/4571]  eta: 0:01:04    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [3]  [1340/4571]  eta: 0:01:04    time: 0.0195  data: 0.0181  max mem: 13772
Epoch: [3]  [1360/4571]  eta: 0:01:03    time: 0.0196  data: 0.0172  max mem: 13772
Epoch: [3]  [1380/4571]  eta: 0:01:03    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [3]  [1400/4571]  eta: 0:01:02    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [3]  [1420/4571]  eta: 0:01:02    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [3]  [1440/4571]  eta: 0:01:02    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [3]  [1460/4571]  eta: 0:01:01    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [3]  [1480/4571]  eta: 0:01:01    time: 0.0198  data: 0.0175  max mem: 13772
Epoch: [3]  [1500/4571]  eta: 0:01:00    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [3]  [1520/4571]  eta: 0:01:00    time: 0.0223  data: 0.0199  max mem: 13772
Epoch: [3]  [1540/4571]  eta: 0:01:00    time: 0.0199  data: 0.0176  max mem: 13772
Epoch: [3]  [1560/4571]  eta: 0:00:59    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [3]  [1580/4571]  eta: 0:00:59    time: 0.0221  data: 0.0198  max mem: 13772
Epoch: [3]  [1600/4571]  eta: 0:00:59    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [3]  [1620/4571]  eta: 0:00:58    time: 0.0198  data: 0.0179  max mem: 13772
Epoch: [3]  [1640/4571]  eta: 0:00:58    time: 0.0196  data: 0.0177  max mem: 13772
Epoch: [3]  [1660/4571]  eta: 0:00:57    time: 0.0200  data: 0.0181  max mem: 13772
Epoch: [3]  [1680/4571]  eta: 0:00:57    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [3]  [1700/4571]  eta: 0:00:56    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [3]  [1720/4571]  eta: 0:00:56    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [3]  [1740/4571]  eta: 0:00:56    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [3]  [1760/4571]  eta: 0:00:55    time: 0.0199  data: 0.0180  max mem: 13772
Epoch: [3]  [1780/4571]  eta: 0:00:55    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [3]  [1800/4571]  eta: 0:00:54    time: 0.0196  data: 0.0172  max mem: 13772
Epoch: [3]  [1820/4571]  eta: 0:00:54    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [3]  [1840/4571]  eta: 0:00:54    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [3]  [1860/4571]  eta: 0:00:53    time: 0.0221  data: 0.0197  max mem: 13772
Epoch: [3]  [1880/4571]  eta: 0:00:53    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [3]  [1900/4571]  eta: 0:00:53    time: 0.0200  data: 0.0176  max mem: 13772
Epoch: [3]  [1920/4571]  eta: 0:00:52    time: 0.0197  data: 0.0173  max mem: 13772
Epoch: [3]  [1940/4571]  eta: 0:00:52    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [3]  [1960/4571]  eta: 0:00:51    time: 0.0196  data: 0.0172  max mem: 13772
Epoch: [3]  [1980/4571]  eta: 0:00:51    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [3]  [2000/4571]  eta: 0:00:50    time: 0.0195  data: 0.0177  max mem: 13772
Epoch: [3]  [2020/4571]  eta: 0:00:50    time: 0.0196  data: 0.0171  max mem: 13772
Epoch: [3]  [2040/4571]  eta: 0:00:50    time: 0.0198  data: 0.0175  max mem: 13772
Epoch: [3]  [2060/4571]  eta: 0:00:49    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [3]  [2080/4571]  eta: 0:00:49    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [3]  [2100/4571]  eta: 0:00:48    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [3]  [2120/4571]  eta: 0:00:48    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [3]  [2140/4571]  eta: 0:00:48    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [3]  [2160/4571]  eta: 0:00:47    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [3]  [2180/4571]  eta: 0:00:47    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [3]  [2200/4571]  eta: 0:00:46    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [3]  [2220/4571]  eta: 0:00:46    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [3]  [2240/4571]  eta: 0:00:46    time: 0.0199  data: 0.0176  max mem: 13772
Epoch: [3]  [2260/4571]  eta: 0:00:45    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [3]  [2280/4571]  eta: 0:00:45    time: 0.0197  data: 0.0173  max mem: 13772
Epoch: [3]  [2300/4571]  eta: 0:00:44    time: 0.0199  data: 0.0175  max mem: 13772
Epoch: [3]  [2320/4571]  eta: 0:00:44    time: 0.0199  data: 0.0174  max mem: 13772
Epoch: [3]  [2340/4571]  eta: 0:00:44    time: 0.0198  data: 0.0180  max mem: 13772
Epoch: [3]  [2360/4571]  eta: 0:00:43    time: 0.0195  data: 0.0170  max mem: 13772
Epoch: [3]  [2380/4571]  eta: 0:00:43    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [3]  [2400/4571]  eta: 0:00:42    time: 0.0197  data: 0.0174  max mem: 13772
Epoch: [3]  [2420/4571]  eta: 0:00:42    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [3]  [2440/4571]  eta: 0:00:42    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [3]  [2460/4571]  eta: 0:00:41    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [3]  [2480/4571]  eta: 0:00:41    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [3]  [2500/4571]  eta: 0:00:40    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [3]  [2520/4571]  eta: 0:00:40    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [3]  [2540/4571]  eta: 0:00:40    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [3]  [2560/4571]  eta: 0:00:39    time: 0.0203  data: 0.0180  max mem: 13772
Epoch: [3]  [2580/4571]  eta: 0:00:39    time: 0.0201  data: 0.0177  max mem: 13772
Epoch: [3]  [2600/4571]  eta: 0:00:38    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [3]  [2620/4571]  eta: 0:00:38    time: 0.0194  data: 0.0175  max mem: 13772
Epoch: [3]  [2640/4571]  eta: 0:00:38    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [3]  [2660/4571]  eta: 0:00:37    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [3]  [2680/4571]  eta: 0:00:37    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [3]  [2700/4571]  eta: 0:00:36    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [3]  [2720/4571]  eta: 0:00:36    time: 0.0194  data: 0.0175  max mem: 13772
Epoch: [3]  [2740/4571]  eta: 0:00:36    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [3]  [2760/4571]  eta: 0:00:35    time: 0.0197  data: 0.0172  max mem: 13772
Epoch: [3]  [2780/4571]  eta: 0:00:35    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [3]  [2800/4571]  eta: 0:00:34    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [3]  [2820/4571]  eta: 0:00:34    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [3]  [2840/4571]  eta: 0:00:34    time: 0.0206  data: 0.0187  max mem: 13772
Epoch: [3]  [2860/4571]  eta: 0:00:33    time: 0.0194  data: 0.0175  max mem: 13772
Epoch: [3]  [2880/4571]  eta: 0:00:33    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [3]  [2900/4571]  eta: 0:00:33    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [3]  [2920/4571]  eta: 0:00:32    time: 0.0198  data: 0.0179  max mem: 13772
Epoch: [3]  [2940/4571]  eta: 0:00:32    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [3]  [2960/4571]  eta: 0:00:31    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [3]  [2980/4571]  eta: 0:00:31    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [3]  [3000/4571]  eta: 0:00:31    time: 0.0197  data: 0.0173  max mem: 13772
Epoch: [3]  [3020/4571]  eta: 0:00:30    time: 0.0199  data: 0.0176  max mem: 13772
Epoch: [3]  [3040/4571]  eta: 0:00:30    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [3]  [3060/4571]  eta: 0:00:29    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [3]  [3080/4571]  eta: 0:00:29    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [3]  [3100/4571]  eta: 0:00:29    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [3]  [3120/4571]  eta: 0:00:28    time: 0.0196  data: 0.0172  max mem: 13772
Epoch: [3]  [3140/4571]  eta: 0:00:28    time: 0.0199  data: 0.0176  max mem: 13772
Epoch: [3]  [3160/4571]  eta: 0:00:27    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [3]  [3180/4571]  eta: 0:00:27    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [3]  [3200/4571]  eta: 0:00:27    time: 0.0194  data: 0.0175  max mem: 13772
Epoch: [3]  [3220/4571]  eta: 0:00:26    time: 0.0194  data: 0.0175  max mem: 13772
Epoch: [3]  [3240/4571]  eta: 0:00:26    time: 0.0196  data: 0.0172  max mem: 13772
Epoch: [3]  [3260/4571]  eta: 0:00:25    time: 0.0196  data: 0.0171  max mem: 13772
Epoch: [3]  [3280/4571]  eta: 0:00:25    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [3]  [3300/4571]  eta: 0:00:25    time: 0.0198  data: 0.0172  max mem: 13772
Epoch: [3]  [3320/4571]  eta: 0:00:24    time: 0.0216  data: 0.0193  max mem: 13772
Epoch: [3]  [3340/4571]  eta: 0:00:24    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [3]  [3360/4571]  eta: 0:00:23    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [3]  [3380/4571]  eta: 0:00:23    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [3]  [3400/4571]  eta: 0:00:23    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [3]  [3420/4571]  eta: 0:00:22    time: 0.0196  data: 0.0178  max mem: 13772
Epoch: [3]  [3440/4571]  eta: 0:00:22    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [3]  [3460/4571]  eta: 0:00:21    time: 0.0194  data: 0.0175  max mem: 13772
Epoch: [3]  [3480/4571]  eta: 0:00:21    time: 0.0197  data: 0.0174  max mem: 13772
Epoch: [3]  [3500/4571]  eta: 0:00:21    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [3]  [3520/4571]  eta: 0:00:20    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [3]  [3540/4571]  eta: 0:00:20    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [3]  [3560/4571]  eta: 0:00:19    time: 0.0203  data: 0.0185  max mem: 13772
Epoch: [3]  [3580/4571]  eta: 0:00:19    time: 0.0197  data: 0.0174  max mem: 13772
Epoch: [3]  [3600/4571]  eta: 0:00:19    time: 0.0198  data: 0.0179  max mem: 13772
Epoch: [3]  [3620/4571]  eta: 0:00:18    time: 0.0221  data: 0.0197  max mem: 13772
Epoch: [3]  [3640/4571]  eta: 0:00:18    time: 0.0199  data: 0.0170  max mem: 13772
Epoch: [3]  [3660/4571]  eta: 0:00:17    time: 0.0195  data: 0.0177  max mem: 13772
Epoch: [3]  [3680/4571]  eta: 0:00:17    time: 0.0201  data: 0.0178  max mem: 13772
Epoch: [3]  [3700/4571]  eta: 0:00:17    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [3]  [3720/4571]  eta: 0:00:16    time: 0.0194  data: 0.0175  max mem: 13772
Epoch: [3]  [3740/4571]  eta: 0:00:16    time: 0.0196  data: 0.0172  max mem: 13772
Epoch: [3]  [3760/4571]  eta: 0:00:16    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [3]  [3780/4571]  eta: 0:00:15    time: 0.0197  data: 0.0174  max mem: 13772
Epoch: [3]  [3800/4571]  eta: 0:00:15    time: 0.0194  data: 0.0175  max mem: 13772
Epoch: [3]  [3820/4571]  eta: 0:00:14    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [3]  [3840/4571]  eta: 0:00:14    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [3]  [3860/4571]  eta: 0:00:14    time: 0.0200  data: 0.0177  max mem: 13772
Epoch: [3]  [3880/4571]  eta: 0:00:13    time: 0.0196  data: 0.0172  max mem: 13772
Epoch: [3]  [3900/4571]  eta: 0:00:13    time: 0.0195  data: 0.0170  max mem: 13772
Epoch: [3]  [3920/4571]  eta: 0:00:12    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [3]  [3940/4571]  eta: 0:00:12    time: 0.0196  data: 0.0172  max mem: 13772
Epoch: [3]  [3960/4571]  eta: 0:00:12    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [3]  [3980/4571]  eta: 0:00:11    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [3]  [4000/4571]  eta: 0:00:11    time: 0.0196  data: 0.0177  max mem: 13772
Epoch: [3]  [4020/4571]  eta: 0:00:10    time: 0.0196  data: 0.0172  max mem: 13772
Epoch: [3]  [4040/4571]  eta: 0:00:10    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [3]  [4060/4571]  eta: 0:00:10    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [3]  [4080/4571]  eta: 0:00:09    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [3]  [4100/4571]  eta: 0:00:09    time: 0.0194  data: 0.0175  max mem: 13772
Epoch: [3]  [4120/4571]  eta: 0:00:08    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [3]  [4140/4571]  eta: 0:00:08    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [3]  [4160/4571]  eta: 0:00:08    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [3]  [4180/4571]  eta: 0:00:07    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [3]  [4200/4571]  eta: 0:00:07    time: 0.0194  data: 0.0176  max mem: 13772
Epoch: [3]  [4220/4571]  eta: 0:00:06    time: 0.0194  data: 0.0175  max mem: 13772
Epoch: [3]  [4240/4571]  eta: 0:00:06    time: 0.0197  data: 0.0173  max mem: 13772
Epoch: [3]  [4260/4571]  eta: 0:00:06    time: 0.0203  data: 0.0180  max mem: 13772
Epoch: [3]  [4280/4571]  eta: 0:00:05    time: 0.0197  data: 0.0177  max mem: 13772
Epoch: [3]  [4300/4571]  eta: 0:00:05    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [3]  [4320/4571]  eta: 0:00:04    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [3]  [4340/4571]  eta: 0:00:04    time: 0.0207  data: 0.0183  max mem: 13772
Epoch: [3]  [4360/4571]  eta: 0:00:04    time: 0.0194  data: 0.0175  max mem: 13772
Epoch: [3]  [4380/4571]  eta: 0:00:03    time: 0.0196  data: 0.0177  max mem: 13772
Epoch: [3]  [4400/4571]  eta: 0:00:03    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [3]  [4420/4571]  eta: 0:00:02    time: 0.0197  data: 0.0178  max mem: 13772
Epoch: [3]  [4440/4571]  eta: 0:00:02    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [3]  [4460/4571]  eta: 0:00:02    time: 0.0195  data: 0.0171  max mem: 13772
Epoch: [3]  [4480/4571]  eta: 0:00:01    time: 0.0195  data: 0.0172  max mem: 13772
Epoch: [3]  [4500/4571]  eta: 0:00:01    time: 0.0195  data: 0.0176  max mem: 13772
Epoch: [3]  [4520/4571]  eta: 0:00:01    time: 0.0195  data: 0.0177  max mem: 13772
Epoch: [3]  [4540/4571]  eta: 0:00:00    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [3]  [4560/4571]  eta: 0:00:00    time: 0.0196  data: 0.0173  max mem: 13772
Epoch: [3]  [4570/4571]  eta: 0:00:00    time: 0.0201  data: 0.0177  max mem: 13772
Epoch: [3] Total time: 0:01:30 (0.0197 s / it)
:::MLLOG {"namespace": "", "time_ms": 1715261989555, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1715261989555, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 202.8491130956604}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 4}}
:::MLLOG {"namespace": "", "time_ms": 1715261989555, "event_type": "INTERVAL_START", "key": "eval_start", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 344, "epoch_num": 4}}
Test:  [ 0/13]  eta: 0:00:02  model_time: 0.2271 (0.2271)  evaluator_time: 0.0025 (0.0025)  time: 0.2305  data: 0.0007  max mem: 13772
Test:  [12/13]  eta: 0:00:00  model_time: 0.2224 (0.2084)  evaluator_time: 0.0029 (0.0027)  time: 0.2120  data: 0.0007  max mem: 13772
Test: Total time: 0:00:02 (0.2121 s / it)
Averaged stats: model_time: 0.2224 (0.2133)  evaluator_time: 0.0029 (0.0032)
:::MLLOG {"namespace": "", "time_ms": 1715261992683, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 4}}
Epoch: [4]  [   0/4572]  eta: 0:01:32    time: 0.0202  data: 0.0006  max mem: 13772
Epoch: [4]  [  20/4572]  eta: 0:01:28    time: 0.0194  data: 0.0171  max mem: 13772
Epoch: [4]  [  40/4572]  eta: 0:01:28    time: 0.0194  data: 0.0174  max mem: 13772
Epoch: [4]  [  60/4572]  eta: 0:01:27    time: 0.0194  data: 0.0168  max mem: 13772
Epoch: [4]  [  80/4572]  eta: 0:01:27    time: 0.0194  data: 0.0174  max mem: 13772
Epoch: [4]  [ 100/4572]  eta: 0:01:26    time: 0.0194  data: 0.0175  max mem: 13772
Epoch: [4]  [ 120/4572]  eta: 0:01:26    time: 0.0195  data: 0.0170  max mem: 13772
Epoch: [4]  [ 140/4572]  eta: 0:01:26    time: 0.0194  data: 0.0168  max mem: 13772
Epoch: [4]  [ 160/4572]  eta: 0:01:25    time: 0.0194  data: 0.0168  max mem: 13772
Epoch: [4]  [ 180/4572]  eta: 0:01:25    time: 0.0194  data: 0.0173  max mem: 13772
Epoch: [4]  [ 200/4572]  eta: 0:01:24    time: 0.0194  data: 0.0170  max mem: 13772
Epoch: [4]  [ 220/4572]  eta: 0:01:24    time: 0.0194  data: 0.0170  max mem: 13772
:::MLLOG {"namespace": "", "time_ms": 1715261997027, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.3464252588143982, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 437, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1715261997027, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 438, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1715261997377, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 315, "status": "success"}}
:::MLLOG {"namespace": "", "time_ms": 1715261997377, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 207.38456473586888}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 5}}
Run time 0:06:18
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
:::MLLOG {"namespace": "", "time_ms": 1715261997378, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 775}}
Loading annotations into memory...
Done (t=0.73s)
Creating index...
Done (t=1.04s)
Loading and preparing results...
DONE (t=3.30s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.85s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.19931
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.32497
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.20591
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00427
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.04675
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.22040
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.33277
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.48045
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.50152
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.01721
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.17226
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.54866
Loading and preparing results...
DONE (t=2.29s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.17s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.28676
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.42960
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.30999
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00623
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.07461
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.31653
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.37631
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.53763
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.56172
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.02967
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.23001
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.61083
Loading and preparing results...
DONE (t=2.42s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.18s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.32748
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.47204
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.35123
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00831
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.09465
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.36203
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.39738
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.56961
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.59576
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.03043
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.24684
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.64677
Loading and preparing results...
DONE (t=1.99s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.20s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.34643
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.49271
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.37437
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.01055
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.09423
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.38480
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.40718
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.57979
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.60641
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.04064
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.26096
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.65815
ENDING TIMING RUN AT 2024-05-09 09:40:04 PM
RESULT,SINGLE_STAGE_DETECTOR,,478,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:04 PM
RESULT,SINGLE_STAGE_DETECTOR,,478,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:04 PM
RESULT,SINGLE_STAGE_DETECTOR,,478,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:04 PM
RESULT,SINGLE_STAGE_DETECTOR,,478,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:04 PM
RESULT,SINGLE_STAGE_DETECTOR,,479,nvidia,2024-05-09 09:32:05 PM
ENDING TIMING RUN AT 2024-05-09 09:40:04 PM
RESULT,SINGLE_STAGE_DETECTOR,,478,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:04 PM
RESULT,SINGLE_STAGE_DETECTOR,,478,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:04 PM
RESULT,SINGLE_STAGE_DETECTOR,,478,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:04 PM
RESULT,SINGLE_STAGE_DETECTOR,,478,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:04 PM
RESULT,SINGLE_STAGE_DETECTOR,,478,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:04 PM
RESULT,SINGLE_STAGE_DETECTOR,,479,nvidia,2024-05-09 09:32:05 PM
ENDING TIMING RUN AT 2024-05-09 09:40:04 PM
RESULT,SINGLE_STAGE_DETECTOR,,478,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:04 PM
RESULT,SINGLE_STAGE_DETECTOR,,478,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:04 PM
RESULT,SINGLE_STAGE_DETECTOR,,478,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:04 PM
RESULT,SINGLE_STAGE_DETECTOR,,478,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:04 PM
RESULT,SINGLE_STAGE_DETECTOR,,478,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:05 PM
RESULT,SINGLE_STAGE_DETECTOR,,479,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:05 PM
RESULT,SINGLE_STAGE_DETECTOR,,479,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:05 PM
RESULT,SINGLE_STAGE_DETECTOR,,479,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:05 PM
RESULT,SINGLE_STAGE_DETECTOR,,480,nvidia,2024-05-09 09:32:05 PM
ENDING TIMING RUN AT 2024-05-09 09:40:05 PM
RESULT,SINGLE_STAGE_DETECTOR,,479,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:05 PM
RESULT,SINGLE_STAGE_DETECTOR,,479,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:05 PM
RESULT,SINGLE_STAGE_DETECTOR,,480,nvidia,2024-05-09 09:32:05 PM
ENDING TIMING RUN AT 2024-05-09 09:40:05 PM
RESULT,SINGLE_STAGE_DETECTOR,,479,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:05 PM
RESULT,SINGLE_STAGE_DETECTOR,,479,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:05 PM
RESULT,SINGLE_STAGE_DETECTOR,,479,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:05 PM
RESULT,SINGLE_STAGE_DETECTOR,,479,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:05 PM
RESULT,SINGLE_STAGE_DETECTOR,,480,nvidia,2024-05-09 09:32:05 PM
ENDING TIMING RUN AT 2024-05-09 09:40:05 PM
RESULT,SINGLE_STAGE_DETECTOR,,480,nvidia,2024-05-09 09:32:05 PM
ENDING TIMING RUN AT 2024-05-09 09:40:05 PM
RESULT,SINGLE_STAGE_DETECTOR,,480,nvidia,2024-05-09 09:32:05 PM
ENDING TIMING RUN AT 2024-05-09 09:40:05 PM
RESULT,SINGLE_STAGE_DETECTOR,,479,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:05 PM
RESULT,SINGLE_STAGE_DETECTOR,,479,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:05 PM
RESULT,SINGLE_STAGE_DETECTOR,,479,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:05 PM
RESULT,SINGLE_STAGE_DETECTOR,,479,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:05 PM
RESULT,SINGLE_STAGE_DETECTOR,,479,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:05 PM
RESULT,SINGLE_STAGE_DETECTOR,,480,nvidia,2024-05-09 09:32:05 PM
ENDING TIMING RUN AT 2024-05-09 09:40:05 PM
RESULT,SINGLE_STAGE_DETECTOR,,479,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:05 PM
RESULT,SINGLE_STAGE_DETECTOR,,480,nvidia,2024-05-09 09:32:05 PM
ENDING TIMING RUN AT 2024-05-09 09:40:05 PM
RESULT,SINGLE_STAGE_DETECTOR,,479,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:05 PM
RESULT,SINGLE_STAGE_DETECTOR,,479,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:05 PM
RESULT,SINGLE_STAGE_DETECTOR,,479,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:05 PM
RESULT,SINGLE_STAGE_DETECTOR,,480,nvidia,2024-05-09 09:32:05 PM
ENDING TIMING RUN AT 2024-05-09 09:40:05 PM
RESULT,SINGLE_STAGE_DETECTOR,,479,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:05 PM
RESULT,SINGLE_STAGE_DETECTOR,,480,nvidia,2024-05-09 09:32:05 PM
ENDING TIMING RUN AT 2024-05-09 09:40:06 PM
RESULT,SINGLE_STAGE_DETECTOR,,480,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:06 PM
RESULT,SINGLE_STAGE_DETECTOR,,480,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:06 PM
RESULT,SINGLE_STAGE_DETECTOR,,480,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:06 PM
RESULT,SINGLE_STAGE_DETECTOR,,480,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:06 PM
RESULT,SINGLE_STAGE_DETECTOR,,480,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:06 PM
RESULT,SINGLE_STAGE_DETECTOR,,481,nvidia,2024-05-09 09:32:05 PM
ENDING TIMING RUN AT 2024-05-09 09:40:06 PM
RESULT,SINGLE_STAGE_DETECTOR,,481,nvidia,2024-05-09 09:32:05 PM
ENDING TIMING RUN AT 2024-05-09 09:40:06 PM
RESULT,SINGLE_STAGE_DETECTOR,,480,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:06 PM
RESULT,SINGLE_STAGE_DETECTOR,,480,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:06 PM
RESULT,SINGLE_STAGE_DETECTOR,,480,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:06 PM
RESULT,SINGLE_STAGE_DETECTOR,,480,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:06 PM
RESULT,SINGLE_STAGE_DETECTOR,,480,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:06 PM
RESULT,SINGLE_STAGE_DETECTOR,,481,nvidia,2024-05-09 09:32:05 PM
ENDING TIMING RUN AT 2024-05-09 09:40:06 PM
RESULT,SINGLE_STAGE_DETECTOR,,480,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:06 PM
RESULT,SINGLE_STAGE_DETECTOR,,480,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:06 PM
RESULT,SINGLE_STAGE_DETECTOR,,480,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:06 PM
RESULT,SINGLE_STAGE_DETECTOR,,480,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:06 PM
RESULT,SINGLE_STAGE_DETECTOR,,480,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:06 PM
RESULT,SINGLE_STAGE_DETECTOR,,480,nvidia,2024-05-09 09:32:06 PM
ENDING TIMING RUN AT 2024-05-09 09:40:06 PM
RESULT,SINGLE_STAGE_DETECTOR,,481,nvidia,2024-05-09 09:32:05 PM
