+ srun --mpi=pmix --ntasks=16 --ntasks-per-node=8 --container-mounts=/home/ubuntu/ml-1cc/data/mlperf/llama2_70b_lora/data:/data:ro,/home/ubuntu/ml-1cc/data/mlperf/llama2_70b_lora/ckpt:/ckpt:ro,./results/1cc_2x8x4xtp4pp1cp2_24-07-16_18-24-51:/results:rw,/dev/infiniband/uverbs0:/dev/infiniband/uverbs0,/dev/infiniband/uverbs1:/dev/infiniband/uverbs1,/dev/infiniband/uverbs2:/dev/infiniband/uverbs2,/dev/infiniband/uverbs3:/dev/infiniband/uverbs3,/dev/infiniband/uverbs4:/dev/infiniband/uverbs4,/dev/infiniband/uverbs5:/dev/infiniband/uverbs5,/dev/infiniband/uverbs6:/dev/infiniband/uverbs6,/dev/infiniband/uverbs7:/dev/infiniband/uverbs7 --container-name=llama2_70b_lora_119 all_reduce_perf_mpi -b 62M -e 62M -d half
# nThread 1 nGpus 1 minBytes 65011712 maxBytes 65011712 step: 1048576(bytes) warmup iters: 5 iters: 20 agg iters: 1 validation: 1 graph: 0
#
# Using devices
#  Rank  0 Group  0 Pid 727233 on ml-512-node-061 device  0 [0x63] NVIDIA H100 80GB HBM3
#  Rank  1 Group  0 Pid 727234 on ml-512-node-061 device  1 [0x6b] NVIDIA H100 80GB HBM3
#  Rank  2 Group  0 Pid 727235 on ml-512-node-061 device  2 [0x71] NVIDIA H100 80GB HBM3
#  Rank  3 Group  0 Pid 727236 on ml-512-node-061 device  3 [0x79] NVIDIA H100 80GB HBM3
#  Rank  4 Group  0 Pid 727237 on ml-512-node-061 device  4 [0x7f] NVIDIA H100 80GB HBM3
#  Rank  5 Group  0 Pid 727238 on ml-512-node-061 device  5 [0x87] NVIDIA H100 80GB HBM3
#  Rank  6 Group  0 Pid 727239 on ml-512-node-061 device  6 [0x8d] NVIDIA H100 80GB HBM3
#  Rank  7 Group  0 Pid 727240 on ml-512-node-061 device  7 [0x95] NVIDIA H100 80GB HBM3
#  Rank  8 Group  0 Pid 1490353 on ml-512-node-062 device  0 [0x63] NVIDIA H100 80GB HBM3
#  Rank  9 Group  0 Pid 1490354 on ml-512-node-062 device  1 [0x6b] NVIDIA H100 80GB HBM3
#  Rank 10 Group  0 Pid 1490355 on ml-512-node-062 device  2 [0x71] NVIDIA H100 80GB HBM3
#  Rank 11 Group  0 Pid 1490356 on ml-512-node-062 device  3 [0x79] NVIDIA H100 80GB HBM3
#  Rank 12 Group  0 Pid 1490357 on ml-512-node-062 device  4 [0x7f] NVIDIA H100 80GB HBM3
#  Rank 13 Group  0 Pid 1490358 on ml-512-node-062 device  5 [0x87] NVIDIA H100 80GB HBM3
#  Rank 14 Group  0 Pid 1490359 on ml-512-node-062 device  6 [0x8d] NVIDIA H100 80GB HBM3
#  Rank 15 Group  0 Pid 1490360 on ml-512-node-062 device  7 [0x95] NVIDIA H100 80GB HBM3
NCCL version 2.21.5+cuda12.4
#
#                                                              out-of-place                       in-place          
#       size         count      type   redop    root     time   algbw   busbw #wrong     time   algbw   busbw #wrong
#        (B)    (elements)                               (us)  (GB/s)  (GB/s)            (us)  (GB/s)  (GB/s)       
    65011712      32505856      half     sum      -1    549.5  118.32  221.85      0    541.7  120.02  225.04      0
# Out of bounds values : 0 OK
# Avg bus bandwidth    : 223.445 
#
[1721154433.232225] [ml-512-node-061:727235:0]     ucc_context.c:906  UCC  WARN  tl ctx shm is still in use
[1721154433.232255] [ml-512-node-061:727235:0]     ucc_context.c:906  UCC  WARN  tl ctx ucp is still in use
[1721154433.232146] [ml-512-node-061:727237:0]     ucc_context.c:906  UCC  WARN  tl ctx shm is still in use
[1721154433.232189] [ml-512-node-061:727237:0]     ucc_context.c:906  UCC  WARN  tl ctx ucp is still in use
[1721154433.232410] [ml-512-node-061:727239:0]     ucc_context.c:906  UCC  WARN  tl ctx shm is still in use
[1721154433.232435] [ml-512-node-061:727239:0]     ucc_context.c:906  UCC  WARN  tl ctx ucp is still in use
[1721154433.232448] [ml-512-node-061:727234:0]     ucc_context.c:906  UCC  WARN  tl ctx shm is still in use
[1721154433.232480] [ml-512-node-061:727234:0]     ucc_context.c:906  UCC  WARN  tl ctx ucp is still in use
[1721154433.232468] [ml-512-node-061:727240:0]     ucc_context.c:906  UCC  WARN  tl ctx shm is still in use
[1721154433.232494] [ml-512-node-061:727240:0]     ucc_context.c:906  UCC  WARN  tl ctx ucp is still in use
[1721154433.232523] [ml-512-node-061:727236:0]     ucc_context.c:906  UCC  WARN  tl ctx shm is still in use
[1721154433.232551] [ml-512-node-061:727236:0]     ucc_context.c:906  UCC  WARN  tl ctx ucp is still in use
[1721154433.232509] [ml-512-node-061:727238:0]     ucc_context.c:906  UCC  WARN  tl ctx shm is still in use
[1721154433.232552] [ml-512-node-061:727238:0]     ucc_context.c:906  UCC  WARN  tl ctx ucp is still in use
[1721154433.232649] [ml-512-node-061:727233:0]     ucc_context.c:906  UCC  WARN  tl ctx shm is still in use
[1721154433.232671] [ml-512-node-061:727233:0]     ucc_context.c:906  UCC  WARN  tl ctx ucp is still in use
[1721154433.253337] [ml-512-node-062:1490353:0]     ucc_context.c:906  UCC  WARN  tl ctx shm is still in use
[1721154433.253375] [ml-512-node-062:1490353:0]     ucc_context.c:906  UCC  WARN  tl ctx ucp is still in use
[1721154433.253249] [ml-512-node-062:1490354:0]     ucc_context.c:906  UCC  WARN  tl ctx shm is still in use
[1721154433.253291] [ml-512-node-062:1490354:0]     ucc_context.c:906  UCC  WARN  tl ctx ucp is still in use
[1721154433.253322] [ml-512-node-062:1490355:0]     ucc_context.c:906  UCC  WARN  tl ctx shm is still in use
[1721154433.253355] [ml-512-node-062:1490355:0]     ucc_context.c:906  UCC  WARN  tl ctx ucp is still in use
[1721154433.253366] [ml-512-node-062:1490356:0]     ucc_context.c:906  UCC  WARN  tl ctx shm is still in use
[1721154433.253397] [ml-512-node-062:1490356:0]     ucc_context.c:906  UCC  WARN  tl ctx ucp is still in use
[1721154433.253403] [ml-512-node-062:1490357:0]     ucc_context.c:906  UCC  WARN  tl ctx shm is still in use
[1721154433.253428] [ml-512-node-062:1490357:0]     ucc_context.c:906  UCC  WARN  tl ctx ucp is still in use
[1721154433.253353] [ml-512-node-062:1490358:0]     ucc_context.c:906  UCC  WARN  tl ctx shm is still in use
[1721154433.253383] [ml-512-node-062:1490358:0]     ucc_context.c:906  UCC  WARN  tl ctx ucp is still in use
[1721154433.253392] [ml-512-node-062:1490359:0]     ucc_context.c:906  UCC  WARN  tl ctx shm is still in use
[1721154433.253418] [ml-512-node-062:1490359:0]     ucc_context.c:906  UCC  WARN  tl ctx ucp is still in use
[1721154433.253389] [ml-512-node-062:1490360:0]     ucc_context.c:906  UCC  WARN  tl ctx shm is still in use
[1721154433.253418] [ml-512-node-062:1490360:0]     ucc_context.c:906  UCC  WARN  tl ctx ucp is still in use

