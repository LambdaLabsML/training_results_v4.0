{
    "submitter": "Lambda",
    "division": "closed",
    "status": "Available on-cloud",
    "system_name": "1-Click-Cluster_n8",
    "number_of_nodes": "8",
    "host_processors_per_node": "2",
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processor_core_count": "52",
    "host_processor_vcpu_count": "",
    "host_processor_frequency": "",
    "host_processor_caches": "",
    "host_processor_interconnect": "",
    "host_memory_capacity": "2.0 TB",
    "host_storage_type": "Local NVMe + Shared File System",
    "host_storage_capacity": "24 TB Local NVMe, Unlmited Shared File System",
    "host_networking": "Compute: 8x NVIDIA Quantum-2 400Gb/s InfiniBand, Management: 2x100Gb/s Ethernet NIC",
    "host_networking_topology": "",
    "host_memory_configuration": "",
    "accelerators_per_node": "8",
    "accelerator_model_name": "NVIDIA H100-SXM5-80GB",
    "accelerator_host_interconnect": "",
    "accelerator_frequency": "",
    "accelerator_on-chip_memories": "",
    "accelerator_memory_configuration": "HBM3",
    "accelerator_memory_capacity": "81559 MiB",
    "accelerator_interconnect": "NVLINK Gen4 900 GB/s + NVSWITCH Gen3",
    "accelerator_interconnect_topology": "",
    "cooling": "",
    "hw_notes": "",
    "framework": "PyTorch NVIDIA Release 24.04",
    "framework_name": "ngc24.04_pytorch",
    "other_software_stack": {
        "cuda_version": "12.4.1.003",
        "cuda_driver_version": "550.90.07",
        "nccl_version": "2.21.5",
        "cublas_version": "12.4.5.8",
        "cudnn_version": "9.1.0.70",
        "trt_version": "8.6.3.1+cuda12.2.2.009",
        "dali_version": "1.36.0",
        "mofed_version": "5.4-rdmacore39.0",
        "openmpi_version": "4.1.7",
        "kernel_version": "Linux 5.15.0-88-generic",
        "nvidia_kernel_driver": "535.129.03"
    },
    "operating_system": "Ubuntu 22.04.4 LTS",
    "sw_notes": ""
}
